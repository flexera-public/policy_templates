name "Google Inefficient Instance Utilization using StackDriver"
rs_pt_ver 20180301
type "policy"
short_description "This checks inefficient instance utilization using provided CPU and Memory thresholds. Instances matching the criteria can be resized after user approval. See the [README](https://github.com/flexera/policy_templates/tree/master/cost/google/instances_stackdriver_utilization/) and [docs.rightscale.com/policies](https://docs.rightscale.com/policies/) to learn more."
long_description ""
severity "low"
category "Cost"
info(
      version: "2.5",
      provider: "GCE",
      service: "Compute",
      policy_set: "Inefficient Instance Usage"
    )

###############################################################################
# Parameters
###############################################################################

parameter "param_email" do
  type "list"
  label "Email addresses to notify"
  description "Email addresses of the recipients you wish to notify when new incidents are created"
end

parameter "param_avg_used_mem_percentage" do
  type "number"
  label "Average used memory percentage"
  description "Utilization below this percentage will raise an incident to tag the instance"
end

parameter "param_avg_used_cpu_percentage" do
  type "number"
  label "Average used CPU percentage"
  description "Utilization below this percentage will raise an incident to tag the instance"
end

parameter "param_exclude_tags" do
  type "string"
  label "Exclusion Tag Key"
  description "An google-native instance tag to ignore instances that you don't want to consider for downsizing. Only supply the tag key"
end

###############################################################################
# Authentication
###############################################################################

# authenticate with Google
credentials "auth_google" do
  schemes "oauth2"
  label "Google"
  description "Select the Google Cloud Credential from the list."
  tags "provider=gce"
end

###############################################################################
# Pagination
###############################################################################

pagination "google_pagination" do
  get_page_marker do
    body_path "nextPageToken"
  end
  set_page_marker do
    query "pageToken"
  end
end


###############################################################################
# Datasources
###############################################################################
datasource "ds_time" do
  run_script $js_time
end

#get all active google project
datasource "ds_google_project" do
  iterate $ds_time
  request do
    auth $auth_google
    pagination $google_pagination
    host "cloudresourcemanager.googleapis.com"
    path "/v1/projects/"
    query "filter", "lifecycleState=ACTIVE"
  end
  result do
    encoding "json"
    collect jmes_path(response, "projects[*]") do
      field "projectNumber", jmes_path(col_item,"projectNumber")
      field "projectId", jmes_path(col_item,"projectId")
      field "end_date", val(iter_item,"end_date")
      field "start_date", val(iter_item,"start_date")
    end
  end
end

datasource "ds_compute_utilization" do
  iterate $ds_google_project
  request do
    auth $auth_google
    pagination $google_pagination
    host "monitoring.googleapis.com"
    path join(["/v3/projects/",val(iter_item,"projectId"),"/timeSeries/"])
    query "filter", 'metric.type="compute.googleapis.com/instance/cpu/utilization"'
    query "interval.endTime", val(iter_item,"end_date")
    query "interval.startTime", val(iter_item,"start_date")
    ignore_status [403,404]
  end
  result do
    encoding "json"
    collect jmes_path(response, "timeSeries[*]") do
      field "label_instance_name", jmes_path(col_item, "metric.labels.instance_name")
      field "instance_id", jmes_path(col_item, "resource.labels.instance_id")
      field "zone", jmes_path(col_item, "resource.labels.zone")
      field "projectId", val(iter_item,"projectId")
      field "avg_cpu_points", jmes_path(col_item, "points[*].value.doubleValue | avg(@)")
      field "max_cpu_points", jmes_path(col_item, "points[*].value.doubleValue | max(@)")
      field "min_cpu_points", jmes_path(col_item, "points[*].value.doubleValue | min(@)")
    end
  end
end

datasource "ds_memory_utilization" do
  iterate $ds_google_project
  request do
    auth $auth_google
    pagination $google_pagination
    host "monitoring.googleapis.com"
    path join(["/v3/projects/",val(iter_item,"projectId"),"/timeSeries/"])
    query "filter", 'metric.type="agent.googleapis.com/memory/percent_used" AND metric.label.state=used'
    query "interval.endTime", val(iter_item,"end_date")
    query "interval.startTime", val(iter_item,"start_date")
    ignore_status [403,404]
  end
  result do
    encoding "json"
    collect jmes_path(response, "timeSeries[*]") do
      field "label_instance_name", jmes_path(col_item, "metric.labels.instance_name")
      field "instance_id", jmes_path(col_item, "resource.labels.instance_id")
      field "zone", jmes_path(col_item, "resource.labels.zone")
      field "mem_points", jmes_path(col_item, "points[*].value.doubleValue")
    end
  end
end

datasource "ds_disk_utilization" do
  iterate $ds_google_project
  request do
    auth $auth_google
    pagination $google_pagination
    host "monitoring.googleapis.com"
    path join(["/v3/projects/",val(iter_item,"projectId"),"/timeSeries/"])
    query "filter", 'metric.type="agent.googleapis.com/disk/percent_used" AND metric.label.state=used'
    query "interval.endTime", val(iter_item,"end_date")
    query "interval.startTime", val(iter_item,"start_date")
    ignore_status [403,404]
  end
  result do
    encoding "json"
    collect jmes_path(response, "timeSeries[*]") do
      field "label_instance_name", jmes_path(col_item, "metric.labels.instance_name")
      field "instance_id", jmes_path(col_item, "resource.labels.instance_id")
      field "zone", jmes_path(col_item, "resource.labels.zone")
      field "disk_points", jmes_path(col_item, "points[*].value.doubleValue")
    end
  end
end

datasource "ds_calculated_utilization" do
  run_script $js_calculated_utilization, $ds_compute_utilization, $ds_memory_utilization, $ds_disk_utilization
end

datasource "ds_add_instance_data" do
  iterate $ds_calculated_utilization
  request do
    run_script $js_add_instance_data, val(iter_item,"projectId"), val(iter_item,"zone"), val(iter_item,"instance_id")
  end
  result do
    encoding "json"
    collect jmes_path(response,"items[*]") do
      field "instance_id", val(iter_item, "instance_id")
      field "hostname", jmes_path(col_item,"name || instance_id")
      field "selfLink", jmes_path(col_item, "selfLink")
      field "machine_type", jmes_path(col_item, "machineType")
      field "instance_status", jmes_path(col_item, "status")
      field "label_instance_name",val(iter_item, "label_instance_name")
      field "zone", val(iter_item, "zone")
      field "points", val(iter_item, "points")
      field "cpu_average", val(iter_item, "cpu_average")
      field "cpu_maximum", val(iter_item, "cpu_maximum")
      field "cpu_minimum", val(iter_item, "cpu_minimum")
      field "mem_average", val(iter_item, "mem_average")
      field "mem_maximum", val(iter_item, "mem_maximum")
      field "mem_minimum", val(iter_item, "mem_minimum")
      field "disk_average", val(iter_item, "disk_average")
      field "disk_maximum", val(iter_item, "disk_maximum")
      field "disk_minimum", val(iter_item, "disk_minimum")
      field "projectId", val(iter_item,"projectId")
      field "tags", jmes_path(col_item, "tags")
    end
  end
end

# get google instance size map
datasource "ds_google_instance_size_map" do
  request do
    verb "GET"
    host "raw.githubusercontent.com"
    path "/rightscale/policy_templates/master/data/google/instance_types.json"
    header "User-Agent", "RS Policies"
    ignore_status [403,404]
  end
end

datasource "ds_filtered_instances" do
  run_script $js_filtered_instances, $ds_add_instance_data, $ds_google_instance_size_map, $param_avg_used_cpu_percentage, $param_avg_used_mem_percentage, $param_exclude_tags
end

###############################################################################
# Scripts
###############################################################################

script "js_filtered_instances", type: "javascript" do
  parameters "ds_add_instance_data", "ds_google_instance_size_map", "param_avg_used_cpu_percentage","param_avg_used_mem_percentage", "param_exclude_tags"
  result "results"
  code <<-EOS
    results = [];
    var param_exclude_tags_lower=[];
    for(var i=0; i < param_exclude_tags.length; i++){
      param_exclude_tags_lower[i]=param_exclude_tags[i].toString().toLowerCase();
    }
    _.each(ds_add_instance_data, function(instance_data){
      var tags = instance_data['tags'];
      var isTagMatched=false
      var tagKeyValue=""
      if(typeof(tags) !== "undefined"){
        var tagKeys = Object.keys(tags);
        for (var j = 0; j < tagKeys.length; j++){
          var tagKey = tagKeys[j];
          var tagValue = tags[tagKey];
          //Check, if the tag present in entered param_exclude_tags, ignore the google bucket object if the tag matches/present.
          if((param_exclude_tags_lower.indexOf(tagKey.toLowerCase()) !== -1) || (param_exclude_tags_lower.indexOf((tagKey+'='+tagValue).toLowerCase()) !== -1)){
            isTagMatched = true;
          }
          if(tagValue.length > 0){
            tagKeyValue = tagKeyValue + ', '+ tagKey+'='+tagValue
          }else{
            tagKeyValue = tagKeyValue + ', '+ tagKey
          }
        }
      }
      if(!isTagMatched && instance_data["instance_status"] === "RUNNING" && (null !== instance_data["machine_type"] && typeof instance_data["machine_type"] !== "undefined") && (instance_data["cpu_average"] < param_avg_used_cpu_percentage || instance_data["mem_average"] < param_avg_used_mem_percentage )){
        var res = instance_data["machine_type"].split("/");
        var current_instance=res[res.length-1].trim();
        if(current_instance != null && !_.contains(current_instance, "custom")){
          var next_instance_size = ds_google_instance_size_map[current_instance]["down"] ;
          var next_machine_type= instance_data["machine_type"].replace(current_instance, next_instance_size);
        }
        if(next_instance_size == null && typeof next_instance_size == "undefined" ){
          next_instance_size="N/A";
          next_machine_type="N/A";
        }

        var hostnameField = instance_data["hostname"]
        if(hostnameField === "" || hostnameField === " " || hostnameField === undefined){
          hostnameField = instance_data["instance_id"];  
		}

        results.push({
          id: instance_data["instance_id"],
          hostname: hostnameField,
          selfLink: instance_data["selfLink"],
          machine_type: current_instance,
          machine_type_url: instance_data["machine_type"],
          name: instance_data["label_instance_name"],
          zone: instance_data["zone"],
          points: instance_data["points"],
          cpu_average: instance_data["cpu_average"],
          cpu_maximum: instance_data["cpu_maximum"],
          cpu_minimum: instance_data["cpu_minimum"],
          mem_average: instance_data["mem_average"],
          mem_maximum: instance_data["mem_maximum"],
          mem_minimum: instance_data["mem_minimum"],
          disk_average: instance_data["disk_average"],
          disk_maximum: instance_data["disk_maximum"],
          disk_minimum: instance_data["disk_minimum"],
          projectId: instance_data["projectId"],
          next_instance_size: next_instance_size,
          next_machine_type: next_machine_type,
          tagKeyValue:(tagKeyValue.slice(2))
        })
      }
    })
    results = _.sortBy(results, 'zone');
	results= _.sortBy(results, 'projectId');
  EOS
end


script "js_time", type: "javascript" do
  result "time"
  code <<-EOF
    var time = [{
      "end_date":  new Date().toISOString(),
      "start_date": new Date(new Date().setDate(new Date().getDate() - 30)).toISOString()
    }]
EOF
end

script "js_calculated_utilization", type: "javascript" do
  result "results"
  parameters "ds_compute_utilization", "ds_memory_utilization", "ds_disk_utilization"
  code <<-EOS
    results = []
    for ( i =0; i < ds_compute_utilization.length; i++ ){
      var instance_id = ds_compute_utilization[i].instance_id
      var points = ds_compute_utilization[i].points
      var memory_record = _.find(ds_memory_utilization, function(record) { return record.instance_id == instance_id; })
      if (memory_record != null && memory_record !== undefined ) {
        var memory_maximum = parseFloat(Math.max(memory_record.mem_points)).toFixed(2)
        var memory_sum = _.reduce(memory_record.mem_points, function(memo, num){ return memo + num; }, 0);
        var memory_average = parseFloat(memory_sum/memory_record.mem_points.length).toFixed(2)
        var memory_minimum = parseFloat(Math.min(memory_record.mem_points)).toFixed(2)
      } else {
        var memory_maximum = "N/A"
        var memory_average = "N/A"
        var memory_minimum = "N/A"
      }

      var disk_record = _.find(ds_disk_utilization, function(record) { return record.instance_id == instance_id; })
      if (disk_record != null && disk_record !== undefined) {
        var disk_sum = _.reduce(disk_record.disk_points, function(memo, num){ return memo + num; }, 0);
        var disk_average = parseFloat(disk_sum/disk_record.disk_points.length).toFixed(2)
        var disk_maximum = parseFloat(Math.max(disk_record.disk_points)).toFixed(2)
        var disk_minimum = parseFloat(Math.min(disk_record.disk_points)).toFixed(2)
      } else {
        var disk_maximum = "N/A"
        var disk_average = "N/A"
        var disk_minimum = "N/A"
      }
      results.push(
        {
          zone: ds_compute_utilization[i].zone,
		  projectId: ds_compute_utilization[i].projectId,
          instance_id: instance_id,
          points: points,
          label_instance_name: ds_compute_utilization[i].label_instance_name,
          cpu_average: parseFloat(ds_compute_utilization[i].avg_cpu_points).toFixed(2),
          cpu_maximum: parseFloat(ds_compute_utilization[i].max_cpu_points).toFixed(2),
          cpu_minimum: parseFloat(ds_compute_utilization[i].min_cpu_points).toFixed(2),
          mem_average: memory_average,
          mem_maximum: memory_maximum,
          mem_minimum: memory_minimum,
          disk_average: disk_average,
          disk_maximum: disk_maximum,
          disk_minimum: disk_minimum
        }
      )
    }
  EOS
end

script "js_add_instance_data", type: "javascript" do
  result "request"
  parameters "project","zone", "instance_id"
  code <<-EOS
    request = {
      "auth": "auth_google",
      "host": "www.googleapis.com",
      "verb": "GET",
      "path": "/compute/v1/projects/"+project+"/zones/"+zone+"/instances",
      "headers": {
        "User-Agent": "RS Policies",
        "Content-Type": "application/json"
      },
      "query_params": {
        "filter": "id="+instance_id
      }
      "ignore_status": [403,404]
    }
  EOS
end
###############################################################################
# Policy
###############################################################################

policy "pol_utilization" do
  validate_each $ds_filtered_instances do
    summary_template "{{ rs_project_name }} (Account ID: {{ rs_project_id }}): {{ len data }} rows containing Google instance StackDriver Utilization data"
    check eq(0,1)
    escalate $email
    escalate $esc_downsize_instances
    export do
      resource_level true
      field "projectId" do
        label "Project Id"
      end
      field "zone" do
        label "Zone"
      end
      field "id" do
        label "Instance Id"
      end
      field "hostname" do
        label "Hostname"
      end
      field "machine_type" do
        label "Current Machine Type"
      end
      field "next_instance_size" do
        label "Machine Type To Downsize" 
      end
      field "cpu_maximum" do
        label "CPU Maximum %"
      end
      field "cpu_minimum" do
        label "CPU Minimum %"
      end
      field "cpu_average" do
        label "CPU Average %"
      end
      field "disk_maximum" do
        label "Disk Maximum %"
      end
      field "disk_minimum" do
        label "Disk Minimum %"
      end
      field "disk_average" do
        label "Disk Average %"
      end
      field "mem_maximum" do
        label "Memory Maximum %"
      end
      field "mem_minimum" do
        label "Memory Minimum %"
      end
      field "mem_average" do
        label "Memory Average %"
      end
      field "tagKeyValue" do
        label "Tags"
      end
    end
  end
end


###############################################################################
# Escalations
###############################################################################

escalation "email" do
  automatic true
  label "Send Mail"
  description "Sends incidents email"
  email $param_email
end

escalation "esc_downsize_instances" do
  automatic false
  label "Downsize Instances"
  description "Approval to downsize all selected instances"
  run "downsize_instances", data
end

###############################################################################
# Cloud Workflow
###############################################################################

# https://cloud.google.com/compute/docs/reference/rest/v1/instances/delete
define downsize_instances($data) return $all_responses do
  $status_code=''
  $go_next = true
  $param_google_project=''
  foreach $item in $data do
    if $item["next_machine_type"] != "N/A"
	$param_google_project = $item["projectId"]
    sub on_error: rollback($item, $param_google_project) do
        call stop_instances($item, $param_google_project) retrieve $status_code
        if($status_code == 200)
          call set_machine_type($item, $param_google_project) retrieve $status_code
        else
          call rollback($item, $param_google_project)
          $go_next = false
        end
        if($status_code == 200)
          call start_instances($item, $param_google_project) retrieve $status_code
        elsif ($go_next)
          call rollback($item, $param_google_project)
          $go_next = false
        end
        if($go_next && $status_code!= 200)
          call rollback($item, $param_google_project)
        end
      end
    end
  end
end

define stop_instances($item, $param_google_project) return $status_code do
  $status_code={}
  $response = {}
  sub on_error: retry, timeout: 20m, on_timeout: skip do
    $response = http_request(
      auth: $$auth_google,
      https: true,
      verb: "post",
      host: "compute.googleapis.com",
      href: join(["/compute/v1/projects/", $param_google_project, "/zones/", $item["zone"], "/instances/",$item["name"], "/stop"]),
      headers: {
        "cache-control": "no-cache",
        "content-type": "application/json"
      }
    )
  end
  call sys_log("inside stop_instances, status_code: ", to_s($response))
  $status_code=$response["code"]
  if($status_code == 200)
    $wake_condition = "/^(TERMINATED)$/"
    $state = ''
    $try_count = 0
    # to avoid infinite loop, limiting calls to max 100.
    while ($state !~ $wake_condition) && ($try_count < 100) do
      sub on_error: skip do
        call get_instance($item, $param_google_project) retrieve $status_response
        $state = to_s($status_response["status"])
        $try_count = $try_count+1
      end
    end
  end
end

define set_machine_type($item, $param_google_project) return $status_code do
  $response = {}
  $status_code = {}
  sub on_error: retry, timeout: 20m, on_timeout: skip do
    $response = http_request(
      auth: $$auth_google,
      verb: "post",
      host: "compute.googleapis.com",
      href: join(["/compute/v1/projects/", $param_google_project, "/zones/", $item["zone"], "/instances/",$item["name"], "/setMachineType"]),
      https: true,
      headers: {
        "cache-control": "no-cache",
        "content-type": "application/json"
      },
      body:{
        "machineType": $item["next_machine_type"]
      }
    )
  end
  call sys_log("inside set_machine_type, status_code: ", to_s($response))
  $status_code=$response["code"]
end

define start_instances($item, $param_google_project) return $status_code do
  $response = {}
  $status_code={}
  sub on_error: retry, timeout: 20m, on_timeout: skip do
    $response = http_request(
      auth: $$auth_google,
      verb: "post",
      host: "compute.googleapis.com",
      href: join(["/compute/v1/projects/", $param_google_project, "/zones/", $item["zone"], "/instances/",$item["name"], "/start"]),
      https: true,
      headers: {
        "cache-control": "no-cache",
        "content-type": "application/json"
      }
    )
  end
  call sys_log("inside start_instances, response: ", to_s($response))
  $status_code=$response["code"]
  if($status_code == 200)
    $wake_condition = "/^(RUNNING)$/"
    $state = ''
    $try_count = 0
    # to avoid infinite loop, limiting calls to max 100.
    while ($state !~ $wake_condition) && ($try_count < 100) do
      sub on_error: skip do
        call get_instance($item, $param_google_project) retrieve $status_response
        $state = to_s($status_response["status"])
        $try_count = $try_count+1
      end
    end
  end
end


define get_instance($item, $param_google_project) return $status_responses do
  $status_responses = {}
  sub on_error: retry, timeout: 20m, on_timeout: skip do
    $response = http_request(
      auth: $$auth_google,
      verb: "get",
      host: "compute.googleapis.com",
      href: join(["/compute/v1/projects/", $param_google_project, "/zones/", $item["zone"], "/instances/",$item["name"]]),
      https: true,
      headers: {
        "cache-control": "no-cache",
        "content-type": "application/json"
      }
    )
    $status_responses=$response["body"]
    call sys_log("inside get_instance status_responses: ", to_s($status_responses))
  end
end

define rollback($item, $param_google_project) do
  call sys_log("rollback Started for", to_s($item))
  call get_instance($item, $param_google_project) retrieve $status_response
  $state = $status_response["status"]
  if include?($status_response["machineType"], $item["machine_type"])
    # Instance is still the original size, just make sure it's running
    if $state != "RUNNING"
      # instance is not running, start it
      call start_instances($item, $param_google_project) retrieve $status_code
    else
      # instance is running nothing to do
    end
  else
    # Instance is the new size, roll back
    call stop_instances($item, $param_google_project)
    call rollback_machine_type($item, $item["machine_type_url"], $param_google_project)
    call start_instances($item, $param_google_project) retrieve $status_code
  end
  $_error_behavior = "skip"
  call sys_log("rollback End")
end

define rollback_machine_type($item, $machine_type, $param_google_project) do
  call sys_log("inside rollback_machine_type", to_s($item))
  sub on_error: skip do
    $response = http_request(
      auth: $$auth_google,
      verb: "post",
      host: "compute.googleapis.com",
      href: join(["/compute/v1/projects/", $param_google_project, "/zones/", $item["zone"], "/instances/",$item["name"], "/setMachineType"]),
      https: true,
      headers: {
        "cache-control": "no-cache",
        "content-type": "application/json"
      },
      body:{
        "machineType": $machine_type
      }
    )
  end
end

# logging to the Accounts Audit Entries
define sys_log($subject, $detail) do
  rs_cm.audit_entries.create(
    notify: "None",
    audit_entry: {
      auditee_href: @@account,
      summary: "Downsize Instance: "+ $subject,
      detail: $detail
    }
  )
end
