name "Google Idle Persistent Disk Recommender"
rs_pt_ver 20180301
type "policy"
short_description "This Policy finds Google Idle Persistent Disk Recommendations and reports when it finds them. See the [README](https://github.com/flexera-public/policy_templates/tree/master/cost/google/idle_persistent_disk_recommendations) and [docs.flexera.com/flexera/EN/Automation](https://docs.flexera.com/flexera/EN/Automation/AutomationGS.htm) to learn more."
category "Cost"
severity "low"
default_frequency "daily"
info(
  version: "2.8",
  provider:"Google",
  service: "Storage",
  policy_set: "Unused Volumes",
  recommendation_type: "Usage Reduction"
)

###############################################################################
# Parameters
###############################################################################

parameter "param_email" do
  type "list"
  label "Email addresses to notify"
  description "Email addresses of the recipients you wish to notify when new incidents are created"
end

parameter "param_zones" do
  type "list"
  label "Zones"
  description "Zones to query. Leave blank to query all available zones."
end

parameter "param_project_ids" do
  type "list"
  label "Project IDs"
  description "Google Projects to query. Leave blank to query all projects."
end

parameter "param_create_final_snapshot" do
  label "Create Final Snapshot"
  description "Boolean for whether or not to take a final snapshot before deleting"
  type "string"
  allowed_values "true", "false"
end

parameter "param_exclude_tags" do
  category "User Inputs"
  label "Tag to exclude (Key:Value)"
  description "Exclusion Tag."
  type "string"
  allowed_pattern /(^$)|([\w]?)+\:([\w]?)/
end

parameter "param_automatic_action" do
  type "list"
  label "Automatic Actions"
  description "When this value is set, this policy will automatically take the selected action(s)"
  allowed_values ["Delete Volumes"]
end

parameter "param_log_to_cm_audit_entries" do
  type "string"
  label "Log to CM Audit Entries"
  description "Boolean for whether or not to log any debugging information from actions to CM Audit Entries, this should be left set to No on Flexera EU"
  default "No"
  allowed_values "Yes", "No"
end

###############################################################################
# Authentication
###############################################################################

# authenticate with Google
credentials "auth_google" do
  schemes "oauth2"
  label "Google"
  description "Select the Google Cloud Credential from the list."
  tags "provider=gce"
end

###############################################################################
# Pagination
###############################################################################

pagination "google_pagination" do
  get_page_marker do
    body_path "nextPageToken"
  end
  set_page_marker do
    query "pageToken"
  end
end

###############################################################################
# Datasources & Scripts
###############################################################################

datasource "ds_currency_reference" do
  request do
    host "raw.githubusercontent.com"
    path "/rightscale/policy_templates/master/cost/scheduled_reports/currency_reference.json"
    header "User-Agent", "RS Policies"
  end
end

#GET LIST OF GCP PROJECTS (filtered by "lifecycleState:ACTIVE" and "param_project".)
datasource "ds_all_projects" do
  request do
    auth $auth_google
    pagination $google_pagination
    host "cloudresourcemanager.googleapis.com"
    path "/v1/projects/"
    query "filter", "lifecycleState:ACTIVE"
  end
  result do
    encoding "json"
    collect jmes_path(response, "projects[*]") do
      field "projectNumber", jmes_path(col_item,"projectNumber")
      field "accountID", jmes_path(col_item,"projectId")
      field "accountName", jmes_path(col_item,"name")
    end
  end
end

#FILTER PROJECTS USING PARAM_PROJECT_IDS PARAMETER (IF APPLICABLE)
datasource "ds_projects" do
  run_script $js_projects, $ds_all_projects, $param_project_ids
end

script "js_projects", type: "javascript" do
  parameters "ds_all_projects", "param_project_ids"
  result "projects"
  code <<-EOF
    var projects = ds_all_projects
    // Apply filter only if "param_project_ids" was set.
    if (param_project_ids.length > 0) {
        projects = _.filter(projects, function (p) {
            // Returns project only if its "accountID" (projectID) is in "param_project_ids".
            if (_.contains(param_project_ids, p.accountID)) {
                return p
            }
        })
    }
  EOF
end

#GET LIST OF DISKS FOR EACH PROJECT ID
datasource "ds_all_disks" do
  iterate $ds_projects
  request do
    run_script $js_aggregated_disks_call, val(iter_item, "accountID"), $param_exclude_tags
  end
  result do
    encoding "json"
    field "accountID", val(iter_item, "accountID")
    field "projectNumber", val(iter_item, "projectNumber")
    field "accountName", val(iter_item, "accountName")
    field "items", jq(response, ".items")
  end
end

script "js_aggregated_disks_call", type: "javascript" do
  parameters "accountID", "param_exclude_tags"
  result "request"
  code <<-EOF
    var filter = ""

    // Apply filter tags(labels) only if "param_exclude_tags" was set.
    if (param_exclude_tags.length != 0) {
        var label_key = param_exclude_tags.split(':')[0]
        var label_value = param_exclude_tags.split(':')[1]

        filter = "(NOT labels." + label_key + ":" + label_value + ")"
    }

    var request = {
        auth: "auth_google",
        pagination: "google_pagination",
        host: "compute.googleapis.com",
        ignore_status: [403, 404],
        path: "/compute/v1/projects/" + accountID + "/aggregated/disks",
        query_params: {
            "filter": filter
        }
    }
  EOF
end

#FILTER LIST OF VMS BY COMPUTE ZONES PARAMETER (IF APPLICABLE)
datasource "ds_disks" do
  run_script $js_disks, $ds_all_disks, $param_zones
end

script "js_disks", type: "javascript" do
  parameters "ds_all_disks", "param_zones"
  result "disks"
  code <<-EOF
    var disks = []

    var now = new Date()
    var one_day = 1000 * 60 * 60 * 24

    _.each(ds_all_disks, function (projectLocations) {
        // Disks of current project.
        var project_disks = []

        _.each(projectLocations.items, function (location, locationKey) {
            // All locations have this pattern: regions/[region_name] so, we separate them
            // and take value from position 1 that's actual region name.
            var region = locationKey.split("/")[1]

            // Adds disks only if current "location" has them and if "region" is in "param_zones" or if
            // "param_zones" is empty.
            if (location.disks && (_.contains(param_zones, region) || param_zones.length == 0)) {
                project_disks = _.union(project_disks, _.map(location.disks, function (disk) {
                    if (disk.selfLink != null && disk.selfLink !== undefined) {
                        var creationTime = new Date(disk.creationTimestamp)
                        var difference = now.getTime() - creationTime.getTime()
                        var daysOld = (difference / one_day).toFixed(2)

                        disk.region = region
                        disk.accountID = projectLocations.accountID
                        disk.projectNumber = projectLocations.projectNumber
                        disk.accountName = projectLocations.accountName
                        disk.resourceID = disk.id
                        disk.resourceName = disk.name
                        disk.resourceType = disk.kind
                        disk.diskSizeGb = disk.sizeGb
                        disk.tags = disk.labels
                        disk.daysOld = Math.round(daysOld)

                        return disk
                    }
                }))
            }
        })

        disks = _.union(disks, project_disks)
    })
  EOF
end

#CREATE LIST OF RECOMMENDER DETAILS FOR RECOMMENDER API CALL USING COMPUTE DISK DATA
datasource "ds_recommenders" do
  run_script $js_recommenders, $ds_disks
end

script "js_recommenders", type: "javascript" do
  parameters "ds_disks"
  result "recommenders"
  code <<-EOF
    var recommenders = []

    _.each(ds_disks, function (disk) {
        var objectToFind = { accountID: disk.accountID, region: disk.region }
        var found = _.findWhere(recommenders, objectToFind)
        // If record with same accountID-region was found we don't add it to recommenders,
        // it help us to prevent duplicates and avoid extra calls to Recommender API.
        if (!found) {
            recommenders.push(objectToFind)
        }
    })
  EOF
end

#GET LIST OF RECOMMENDATIONS
datasource "ds_recommendations" do
  iterate $ds_recommenders
  request do
    run_script $js_recommender_call, val(iter_item,"accountID"), val(iter_item, "region")
  end
  result do
    encoding "json"
    collect jmes_path(response, "recommendations[*]") do
      field "accountID", val(iter_item, "accountID")
      field "region", val(iter_item, "region")
      field "id", jmes_path(col_item, "name")
      field "description", jmes_path(col_item, "description")
      field "resourceLink", jmes_path(col_item, "content.overview.resource")
      field "resourceName", jmes_path(col_item, "content.overview.resourceName")
      field "primaryImpact", jmes_path(col_item, "primaryImpact")
      field "costUnits", jmes_path(col_item, "primaryImpact.costProjection.cost.units")
      field "costNanos", jmes_path(col_item, "primaryImpact.costProjection.cost.nanos")
      field "duration", jmes_path(col_item, "primaryImpact.costProjection.duration")
      field "currency", jmes_path(col_item, "primaryImpact.costProjection.cost.currencyCode")
      field "priority", jmes_path(col_item, "priority")
      field "recommenderSubtype", jmes_path(col_item, "recommenderSubtype")
      field "state", jmes_path(col_item, "stateInfo.state")
    end
  end
end

script "js_recommender_call", type: "javascript" do
  parameters "accountID", "region"
  result "request"
  code <<-EOF
    var now = new Date().getTime();
    var sleepDuration = 10000
    while(new Date().getTime() < now + sleepDuration){ /* Do nothing */ }
    var request = {
      auth: "auth_google",
      pagination: "google_pagination",
      host: "recommender.googleapis.com",
      ignore_status: 403,
      path: "/v1/projects/"+ accountID +"/locations/" + region + "/recommenders/google.compute.disk.IdleResourceRecommender/recommendations",
      query_strings: { alt: "json" }
    }
  EOF
end

#GET VM DISK COST MAPPING
datasource "ds_disk_cost_mapping" do
  run_script $js_disk_cost_mapping, $ds_disks, $ds_recommendations, $ds_currency_reference
end

script "js_disk_cost_mapping", type:"javascript" do
  result "result"
  parameters  "disks", "recommendations", "ds_currency_reference"
  code <<-EOS
    var instances = [];
    var result = {};
    var message = ''
    var count = 0;

    function formatNumber(number, separator) {
        var numString = number.toString();
        var values = numString.split(".");
        var result = ''
        while (values[0].length > 3) {
            var chunk = values[0].substr(-3)
            values[0] = values[0].substr(0, values[0].length - 3)
            result = separator + chunk + result
        }
        if (values[0].length > 0) {
            result = values[0] + result
        }
        if (values[1] == undefined) {
            return result;
        }
        return result + "." + values[1];
    }
    var total = 0
    var cur = ""

    _.each(disks, function(disk) {
      var resource_link = disk.selfLink.replace("https://www.googleapis.com/compute/v1/", "")
      disk["resourceLink"] = resource_link
    })

    _.each(recommendations, function (recommendation) {
      count++
      var rec_resource_link = recommendation.resourceLink.replace("//compute.googleapis.com/", "")
      var disk = _.find(disks, function(d) {
          return d.resourceLink == rec_resource_link
      })
      if (!(disk == undefined || disk == null)) {
        if (recommendation['currency'] !== undefined) {
          if (recommendation['costUnits'] == null) {
              recommendation['costUnits'] = 0
          }
          if (recommendation['costNanos'] == null) {
              recommendation['costNanos'] = 0
          }
          if (ds_currency_reference[recommendation['currency']] !== undefined) {
              cur = ds_currency_reference[recommendation['currency']]['symbol']
          } else {
              cur = "$"
          }
          disk['savingsCurrency'] = cur
        } else {
          cur = "$"
          var separator = ","
        }

        //Convert Costs from Negative to Positive and add Units and Nanos
        if (!(recommendation.costNanos == null || recommendation.costNanos == undefined)) {
          if (recommendation.costNanos != 0) {
            recommendation.costNanos = recommendation.costNanos * -1
          }
        } else {
          recommendation.costNanos = 0
        }

        if (!(recommendation.costUnits == null || recommendation.costUnits == undefined)) {
          if (recommendation.costUnits != 0) {
            recommendation.costUnits = recommendation.costUnits * -1
          }
        } else {
          recommendation.costUnits = 0
        }

        var cost_nano = recommendation.costNanos * Math.pow(10, -9)
        var combine = Number(recommendation.costUnits) + Number(parseFloat(cost_nano))

        var monthsDuration = 0
        if (!(recommendation.duration == null || recommendation.duration == undefined)) {
          monthsDuration = parseFloat(recommendation.duration.replace("s",""))/2628288
        }

        var monthlySavings = 0
        if ( monthsDuration != 0 ) {
          monthlySavings = combine / monthsDuration
        }
        total += monthlySavings

        disk['savings'] = (Math.round(monthlySavings * 1000) / 1000)
        disk['savingsCurrency'] = cur
        disk['description'] = recommendation['description']
        disk['priority'] = recommendation['priority']
        disk['primaryImpact'] = recommendation['primaryImpact']
        disk['recommenderSubtype'] = recommendation['recommenderSubtype']
        disk['state'] = recommendation['state']
        disk['service'] = "Storage"
        var tags = []
        if (disk['tags'] != null) {
          if (typeof disk['tags'] == 'object') {
            Object.keys(disk.tags).forEach(function (key) {
              if (disk.tags[key] == null || disk.tags[key] == "") {
                  disk.tags[key] = "null"
              }
              tags.push(String(key) + '=' + String(disk.tags[key]))
            });
          } else {
            tags.push(disk["tags"].replace(":", "=null"))
          }
        }
        disk['tags'] = tags
        instances.push(disk)
      }
    })

    if (instances.length != 0) {
      if (count) {
        total = cur + ' ' + formatNumber((Math.round(total * 100) / 100));
        message = "The total estimated monthly savings are " + total;
      } else {
          message = "The Flexera Optima system does not have any data to calculate savings for these resources";
      }
    } else {
      message = "unable to find resources between recommender and resource api";
    }
    result = {
      "instances": instances,
      "message": message
    };
    result.instances = _.sortBy(result.instances, "region");
    result.instances = _.sortBy(result.instances, "accountName");
  EOS
end

###############################################################################
# Policy
###############################################################################

policy "policy_recommendations" do
  validate $ds_disk_cost_mapping do
    summary_template "{{ rs_project_name }} (Account ID: {{ rs_project_id }}): {{ len data.instances }} rows found for Idle Persistent Disks(Unattached Volumes)"
    check eq(size(val(data, "instances")), 0)
    escalate $esc_email
    escalate $esc_approve_delete_volumes
    export "instances" do
      resource_level true
      field "accountID" do
        label "Project ID"
      end
      field "accountName" do
        label "Project Name"
      end
      field "projectNumber" do
        label "Project Number"
      end
      field "resourceID" do
        label "Resource ID"
      end
      field "resourceName" do
        label "Resource Name"
      end
      field "resourceType" do
        label "Resource Type"
      end
      field "region" do
        label "Zone"
      end
      field "daysOld" do
        label "Age In Days"
      end
      field "diskSizeGb" do
        label "Size"
      end
      field "tags" do
        label "Tags"
      end
      field "primaryImpactCategory" do
        label "Recommendation Primary Impact Category"
        path "primaryImpact.category"
      end
      field "description" do
        label "Description"
      end
      field "savings" do
        label "Estimated Monthly Savings"
      end
      field "savingsCurrency" do
        label "Currency"
      end
      field "priority" do
        label "Priority"
      end
      field "recommenderSubtype" do
        label "Sub Type"
      end
      field "state" do
        label "State"
      end
      field "status" do
        label "Status"
      end
      field "id" do
        label "ID"
        path "resourceID"
      end
      field "service" do
        label "Service"
      end
    end
  end
end

###############################################################################
# Escalations
###############################################################################

escalation "esc_email" do
  automatic true
  label "Send Email"
  description "Send incident email"
  email $param_email
end

escalation "esc_approve_delete_volumes" do
  automatic contains($param_automatic_action, "Delete Volumes")
  label "Delete Volumes"
  description "Approval to delete all selected volumes"
  run "delete_volumes", data, $param_create_final_snapshot, $param_log_to_cm_audit_entries, rs_optima_host
end

###############################################################################
# Cloud Workflow
###############################################################################

define delete_volumes($data,$param_create_final_snapshot,$param_log_to_cm_audit_entries, $$rs_optima_host) return $all_responses,$snapshot_responses do
  $$debug = $param_log_to_cm_audit_entries == "Yes"
  $snapshot_responses = []
  $all_responses = []
  $syslog_subject = "Google Idle Persistent Disk: "
  call sys_log(join([$syslog_subject, "Google volume"]),to_s($data))
  foreach $item in $data do
    if ($param_create_final_snapshot == "true")
      call create_snapshot($item) retrieve $response
      $snapshot_responses << $response
    end
    sub on_error: handle_error($response) do
      $response = http_delete(
        url: $item["selfLink"],
        auth: $$auth_google,
        headers: {
          "cache-control": "no-cache",
          "content-type": "application/json"
        }
      )
      $all_responses << $response
    end
  end
  call sys_log(join([$syslog_subject, "Responses"]),to_s($all_responses))
end

define create_snapshot($volume) return $response do
  $response = []
  $postResponse = {}

  sub on_error: handle_error($postResponse) do
    $postResponse = http_post(
      url: join([$item["selfLink"],"/createSnapshot"]),
      auth: $$auth_google,
      headers: {
        "cache-control": "no-cache",
        "content-type": "application/json"
      },
      body: {
        name: join([$item["name"], "-final-snapshot"])
      }
    )
  end
  $response << $postResponse

  call sys_log("Post Response", to_s($postResponse))
  sub on_error: handle_error($getResponse) do
    $getResponse = http_get(
      url: $postResponse["body"]["selfLink"],
      auth: $$auth_google,
      headers: {
        "cache-control": "no-cache",
        "content-type": "application/json"
      }
    )
    call sys_log("Get Response", to_s($getResponse))
    while $getResponse["body"]["status"] != "DONE" do
      sleep(1)
      $getResponse = http_get(
        url: $getResponse["body"]["selfLink"],
        auth: $$auth_google,
        headers: {
          "cache-control": "no-cache",
          "content-type": "application/json"
        }
      )
      call sys_log("Get Response", to_s($getResponse))
    end
    $response << $getResponse
  end

  sleep(10)
end

define handle_error($response) do
  $syslog_subject = "Google Persistent Disk Deletion Error: "
  call sys_log($syslog_subject,to_s($response))
  $_error_behavior = "skip"
end

define sys_log($subject, $detail) do
  # Create empty errors array if doesn't already exist
  if !$$errors
    $$errors = []
  end
  # Check if debug is enabled
  if $$debug
    # Append to global $$errors
    # This is the suggested way to capture errors
    $$errors << "Unexpected error for " + $subject + "\n  " + to_s($detail)
    # If Flexera NAM Zone, create audit_entries [to be deprecated]
    # This is the legacy method for capturing errors and only supported on Flexera NAM
    if $$rs_optima_host == "api.optima.flexeraeng.com"
      # skip_error_and_append is used to catch error if rs_cm.audit_entries.create fails unexpectedly
      $task_label = "Creating audit entry for " + $subject
      sub task_label: $task, on_error: skip_error_and_append($task) do
        rs_cm.audit_entries.create(
          notify: "None",
          audit_entry: {
            auditee_href: @@account,
            summary: $subject,
            detail: $detail
          }
        )
      end # End sub on_error
    end # End if rs_optima_host
  end # End if debug is enabled
end

define skip_error_and_append($subject) do
  $$errors << "Unexpected error for " + $subject + "\n  " + to_s($_error)
  $_error_behavior = "skip"
end
