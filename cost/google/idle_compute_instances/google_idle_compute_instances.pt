name "Google Idle Compute Instances"
rs_pt_ver 20180301
type "policy"
short_description "Checks for Google Compute instances that are idle for the last 30 days and terminates them after approval.. See the [README](https://github.com/flexera-public/policy_templates/tree/master/cost/google/idle_compute_instances/) and [docs.flexera.com/flexera/EN/Automation](https://docs.flexera.com/flexera/EN/Automation/AutomationGS.htm) to learn more."
long_description ""
severity "low"
category "Cost"
default_frequency "daily"
info(
  version: "2.11",
  provider: "GCE",
  service: "Compute",
  policy_set: "Idle Compute Instances"
)

###############################################################################
# Parameters
###############################################################################

parameter "param_email" do
  type "list"
  label "Email addresses to notify"
  description "Email addresses of the recipients you wish to notify when new incidents are created"
end

parameter "param_avg_used_memory" do
  type "number"
  label "Average used memory percentage"
  description "Set to -1 to ignore memory utilization"
  default -1
  min_value -1
  max_value 100
end

parameter "param_avg_cpu" do
  type "number"
  label "Average used CPU percentage"
  description "Set to -1 to ignore CPU utilization"
  default -1
  min_value -1
  max_value 100
end

parameter "param_exclusion_tag_key" do
  category "User Inputs"
  label "Exclusion Label Key:Value"
  description "Cloud native label to ignore instances. Format: Key:Value"
  type "string"
  allowed_pattern /(^$)|([\w]?)+\:([\w]?)+/
end

parameter "param_automatic_action" do
  type "list"
  label "Automatic Actions"
  description "When this value is set, this policy will automatically take the selected action(s)"
  allowed_values ["Terminate Instances"]
end

parameter "param_log_to_cm_audit_entries" do
  type "string"
  label "Log to CM Audit Entries"
  description "Boolean for whether or not to log any debugging information from actions to CM Audit Entries, this should be left set to No on Flexera EU"
  default "No"
  allowed_values "Yes", "No"
end

###############################################################################
# Authentication
###############################################################################

# authenticate with Google
credentials "auth_google" do
  schemes "oauth2"
  label "Google"
  description "Select the Google Cloud Credential from the list."
  tags "provider=gce"
end

###############################################################################
# Datasources & Scripts
###############################################################################

pagination "google_pagination" do
  get_page_marker do
    body_path "nextPageToken"
  end
  set_page_marker do
    query "pageToken"
  end
end

# GET START DATE AND END DATE TO RETRIEVE THE DATA
datasource "ds_time" do
  run_script $js_time
end

script "js_time", type: "javascript" do
  result "time"
  code <<-EOF
    var time = [{
      "end_date":  new Date().toISOString(),
      "start_date": new Date(new Date().setDate(new Date().getDate() - 30)).toISOString()
    }]
EOF
end

# GET ALL ACTIVE GOOGLE PROJECT
datasource "ds_google_project" do
  iterate $ds_time
  request do
    auth $auth_google
    pagination $google_pagination
    host "cloudresourcemanager.googleapis.com"
    path "/v1/projects/"
    query "filter", "lifecycleState=ACTIVE"
  end
  result do
    encoding "json"
    collect jmes_path(response, "projects[*]") do
      field "projectNumber", jmes_path(col_item,"projectNumber")
      field "projectId", jmes_path(col_item,"projectId")
      field "end_date", val(iter_item,"end_date")
      field "start_date", val(iter_item,"start_date")
    end
  end
end

# RETRIEVE THE CPU UTILIZATION OF GCP INSTANCES
datasource "ds_compute_utilization" do
  iterate $ds_google_project
  request do
    auth $auth_google
    host "monitoring.googleapis.com"
    verb "POST"
    path join(["/v3/projects/", val(iter_item,"projectId"), "/timeSeries:query"])
    body_field "query", "fetch gce_instance | metric compute.googleapis.com/instance/cpu/utilization | within 30d | { group_by sliding(30d), .mean ; group_by sliding(30d), .max  ; group_by sliding(30d), . min } | join"
    ignore_status [403, 404]
  end
  result do
    encoding "json"
    collect jmes_path(response, "timeSeriesData[*]") do
      field "label_instance_name", jmes_path(col_item, "labelValues[3].stringValue")
      field "instance_id", jmes_path(col_item, "labelValues[2].stringValue")
      field "zone", jmes_path(col_item, "labelValues[1].stringValue")
      field "projectId", val(iter_item,"projectId")
      field "cpu_average", prod(jmes_path(col_item, "pointData[0].values[0].doubleValue"), 100)
      field "cpu_maximum", prod(jmes_path(col_item, "pointData[0].values[1].doubleValue"), 100)
      field "cpu_minimum", prod(jmes_path(col_item, "pointData[0].values[2].doubleValue"), 100)
    end
  end
end

# RETRIEVE THE MEMORY UTILIZATION OF GCP INSTANCES
datasource "ds_memory_utilization" do
  iterate $ds_google_project
  request do
    auth $auth_google
    host "monitoring.googleapis.com"
    verb "POST"
    path join(["/v3/projects/", val(iter_item,"projectId"), "/timeSeries:query"])
    body_field "query", "fetch gce_instance | metric agent.googleapis.com/memory/percent_used | filter state == 'used' | within 30d | { group_by sliding(30d), .mean ; group_by sliding(30d), .max  ; group_by sliding(30d), . min } | join"
    ignore_status [403, 404]
  end
  result do
    encoding "json"
    collect jmes_path(response, "timeSeriesData[*]") do
      field "label_instance_name", jmes_path(col_item, "labelValues[3].stringValue")
      field "instance_id", jmes_path(col_item, "labelValues[2].stringValue")
      field "zone", jmes_path(col_item, "labelValues[1].stringValue")
      field "mem_average", jmes_path(col_item, "pointData[0].values[0].doubleValue")
      field "mem_maximum", jmes_path(col_item, "pointData[0].values[1].doubleValue")
      field "mem_minimum", jmes_path(col_item, "pointData[0].values[2].doubleValue")
    end
  end
end

# PREPARE THE CPU AND MEMORY UTILIZATION TO BE SHOWN IN THE INCIDENT REPORT
datasource "ds_calculated_utilization" do
  run_script $js_calculated_utilization, $ds_compute_utilization, $ds_memory_utilization
end

script "js_calculated_utilization", type: "javascript" do
  result "results"
  parameters "ds_compute_utilization", "ds_memory_utilization"
  code <<-EOS
  var results = []
  _.each(ds_compute_utilization, function(cu) {
    var instance_id = cu.instance_id
    if (instance_id !== null && instance_id !== undefined) {
      var memory_record = _.find(ds_memory_utilization, function(record) { return record.instance_id == instance_id; })
      var mem_average = "101"
      var mem_maximum = "101"
      var mem_minimum = "101"
      if (memory_record !== null && memory_record !== undefined) {
        mem_average = memory_record.mem_average
        mem_maximum = memory_record.mem_maximum
        mem_minimum = memory_record.mem_minimum
      }
      results.push({
        zone: cu.zone,
        projectId: cu.projectId,
        instance_id: instance_id,
        cpu_average: cu.cpu_average,
        cpu_maximum: cu.cpu_maximum,
        cpu_minimum: cu.cpu_minimum,
        mem_average: mem_average,
        mem_maximum: mem_maximum,
        mem_minimum: mem_minimum
      })
    }
  })
EOS
end

# GET A LIST OF UNIQUE PROJECT IDS TO REDUCE THE NUMBER OF CALLS WE NEED TO DO TO API TO GET VM DATA
datasource "ds_grouped_project_ids" do
  run_script $js_grouped_project_ids, $ds_calculated_utilization
end

script "js_grouped_project_ids", type: "javascript" do
  result "grouped_project_ids"
  parameters "ds_calculated_utilization"
  code <<-EOS
  var grouped_project_ids = _.keys(_.groupBy(ds_calculated_utilization, "projectId"))
  EOS
end

# GET A LIST OF THE INSTANCES OF EVERY ACCOUNT ID IN EVERY ZONE
datasource "ds_instances" do
  iterate $ds_grouped_project_ids
  request do
    auth $auth_google
    host "compute.googleapis.com"
    verb "GET"
    path join(["/compute/v1/projects/", iter_item, "/aggregated/instances"])
    ignore_status [403, 404]
    header "User-Agent", "RS Policies"
    header "Content-Type", "application/json"
  end
  result do
    encoding "json"
    field "instances", jq(response, "[ .items | to_entries | map_values(.value) | map(select(has(\"instances\"))) | .[].instances | .[] | {id,name,hostname,selfLink,status,labels,zone,kind}]")
  end
end

# FLATTEN THE ARRAY OF GCP INSTANCES
datasource "ds_collected_instances" do
  run_script $js_collected_instances, $ds_instances
end

script "js_collected_instances", type: "javascript" do
  result "collected_instances"
  parameters "ds_instances"
  code <<-EOS
  var collected_instances = []
  _.each(ds_instances, function(instance_list) {
    _.each(instance_list.instances, function(instance) {
      collected_instances.push(instance)
    })
  })
  EOS
end

# COMBINE INSTANCE DATA AND CPU/MEMORY UTILIZATION DATA
datasource "ds_add_instance_data" do
  run_script $js_add_instance_data, $ds_collected_instances, $ds_calculated_utilization
end

script "js_add_instance_data", type: "javascript" do
  parameters "ds_collected_instances", "ds_calculated_utilization"
  result "instances_with_data"
  code <<-EOS
  var instances_with_data = []
  _.each(ds_calculated_utilization, function(cu) {
    var instance_id = cu.instance_id
    var data_record = _.find(ds_collected_instances, function(record) { return record.id === instance_id })
    if (data_record === null || data_record === undefined) {
      instances_with_data.push({
        id: instance_id,
        hostname: "",
        selfLink: "",
        label_instance_name: cu.label_instance_name,
        status: "",
        zone: cu.zone,
        labels: {},
        cpu_average: parseFloat(cu.cpu_average).toFixed(2),
        cpu_maximum: parseFloat(cu.cpu_maximum).toFixed(2),
        cpu_minimum: parseFloat(cu.cpu_minimum).toFixed(2),
        mem_average: parseFloat(cu.mem_average).toFixed(2),
        mem_maximum: parseFloat(cu.mem_maximum).toFixed(2),
        mem_minimum: parseFloat(cu.mem_minimum).toFixed(2),
        projectId: cu.projectId
      })
    } else {
      instances_with_data.push({
        id: instance_id,
        hostname: data_record.name || data_record.id,
        selfLink: data_record.selfLink,
        label_instance_name: cu.label_instance_name,
        status: data_record.status,
        zone: cu.zone,
        labels: data_record.labels,
        cpu_average: parseFloat(cu.cpu_average).toFixed(2),
        cpu_maximum: parseFloat(cu.cpu_maximum).toFixed(2),
        cpu_minimum: parseFloat(cu.cpu_minimum).toFixed(2),
        mem_average: parseFloat(cu.mem_average).toFixed(2),
        mem_maximum: parseFloat(cu.mem_maximum).toFixed(2),
        mem_minimum: parseFloat(cu.mem_minimum).toFixed(2),
        projectId: cu.projectId
      })
    }
  })
  EOS
end

# FILTER INSTANCES BY THE PARAMETERS PROVIDED
datasource "ds_clean_instance_data" do
  run_script $js_clean_instance_data, $ds_add_instance_data, $param_exclusion_tag_key
end

script "js_clean_instance_data", type: "javascript" do
  result "results"
  parameters "ds_add_instance_data", "param_exclusion_tag_key"
  code <<-EOS
  tag_key = param_exclusion_tag_key.split(':')[0]
  tag_value = param_exclusion_tag_key.split(':')[1]

  results = _.filter(ds_add_instance_data, function (data) {
    if (data.status == "RUNNING") {
      if (data.labels != null && data.labels !== undefined) {
        if (data.labels[tag_key] != null && data.labels[tag_key] !== undefined) {
          if (data.labels[tag_key] != tag_value) {
            var labelsList = "";
            for (var prop in data.labels) {
              labelsList = labelsList + prop + ":" + data.labels[prop] + ", ";
            }
            if (labelsList.length > 0) {
              data.labels = labelsList.substring(0, labelsList.length - 2);
            } else {
              data.labels = "< No Value >";
            }
            if (data.hostname == undefined) {
              data.hostname = data.id;
            }
            return data
          }
        } else {
          var labelsList = "";
          for (var prop in data.labels) {
            labelsList = labelsList + prop + ":" + data.labels[prop] + ", ";
          }
          if (labelsList.length > 0) {
            data.labels = labelsList.substring(0, labelsList.length - 2);
          } else {
            data.labels = "< No Value >";
          }
          if (data.hostname == undefined) {
            data.hostname = data.id;
          }
          return data
        }
      } else {
        var labelsList = "";
        for (var prop in data.labels) {
          labelsList = labelsList + prop + ":" + data.labels[prop] + ", ";
        }
        if (labelsList.length > 0) {
          data.labels = labelsList.substring(0, labelsList.length - 2);
        } else {
          data.labels = "< No Value >";
        }
        if (data.hostname == undefined) {
          data.hostname = data.id;
        }
        return data
      }
    }
  })
  results = _.sortBy(results, 'zone');
  results = _.sortBy(results, 'projectId');
EOS
end

###############################################################################
# Policy
###############################################################################

policy "pol_utilization" do
  validate_each $ds_clean_instance_data do
    summary_template "{{ rs_project_name }} (Account ID: {{ rs_project_id }}): {{ len data }} rows containing Google instance StackDriver Utilization data"
    check logic_or(eq($param_avg_used_memory, -1), gt(to_n(val(item,"mem_average")), $param_avg_used_memory))
    check logic_or(eq($param_avg_cpu, -1), gt(to_n(val(item,"cpu_average")),$param_avg_cpu))
    escalate $email
    escalate $terminate_resources
    export do
      resource_level true
      field "projectId" do
        label "Project ID"
      end
      field "zone" do
        label "Region"
      end
      field "id" do
        label "Instance ID"
      end
      field "hostname" do
        label "Hostname"
      end
      field "cpu_maximum" do
        label "CPU Maximum %"
      end
      field "cpu_minimum" do
        label "CPU Minimum %"
      end
      field "cpu_average" do
        label "CPU Average %"
      end
      field "mem_maximum" do
        label "Memory Maximum %"
      end
      field "mem_minimum" do
        label "Memory Minimum %"
      end
      field "mem_average" do
        label "Memory Average %"
      end
      field "labels" do
        label "Labels"
      end
      field "selfLink" do
        label "Self Link"
      end
    end
  end
end


###############################################################################
# Escalations
###############################################################################

escalation "email" do
  automatic true
  label "Send Email"
  description "Send incident email"
  email $param_email
end

escalation "terminate_resources" do
  automatic contains($param_automatic_action, "Terminate Instances")
  label "Terminate Instances"
  description "Approval to terminate all selected instances"
  run "terminate_resources", data, $param_log_to_cm_audit_entries, rs_optima_host
end

###############################################################################
# Cloud Workflow
###############################################################################

define terminate_resources($data,$param_log_to_cm_audit_entries, $$rs_optima_host) return $all_responses do
  $$debug = $param_log_to_cm_audit_entries == "Yes"
  $$log = []
  $all_responses = []
  $syslog_subject = "Google Idle Compute: "
  call sys_log(join([$syslog_subject, "Identified Instances"]),to_s($data))
  foreach $item in $data do
    sub on_error: handle_error($response) do
      $response = http_delete(
        url: $item["selfLink"],
        auth: $$auth_google,
        headers: {
          "cache-control": "no-cache",
          "content-type": "application/json"
        }
      )
      $all_responses << $response
    end
  end
  call sys_log(join([$syslog_subject, "Responses"]),to_s($all_responses))
end

define handle_error($response) do
  $status_code = $response["code"]
  $syslog_subject = "Google Idle Compute Termination Error: "
  call sys_log(join([$syslog_subject, $status_code]),to_s($response))
  $_error_behavior = "skip"
end

define sys_log($subject, $detail) do
  # Create empty errors array if doesn't already exist
  if !$$errors
    $$errors = []
  end
  # Check if debug is enabled
  if $$debug
    # Append to global $$errors
    # This is the suggested way to capture errors
    $$errors << "Unexpected error for " + $subject + "\n  " + to_s($detail)
    # If Flexera NAM Zone, create audit_entries [to be deprecated]
    # This is the legacy method for capturing errors and only supported on Flexera NAM
    if $$rs_optima_host == "api.optima.flexeraeng.com"
      # skip_error_and_append is used to catch error if rs_cm.audit_entries.create fails unexpectedly
      $task_label = "Creating audit entry for " + $subject
      sub task_label: $task, on_error: skip_error_and_append($task) do
        rs_cm.audit_entries.create(
          notify: "None",
          audit_entry: {
            auditee_href: @@account,
            summary: $subject,
            detail: $detail
          }
        )
      end # End sub on_error
    end # End if rs_optima_host
  end # End if debug is enabled
end

define skip_error_and_append($subject) do
  $$errors << "Unexpected error for " + $subject + "\n  " + to_s($_error)
  $_error_behavior = "skip"
end
