name "Azure Rightsize Compute Instances"
rs_pt_ver 20180301
type "policy"
short_description "Checks for instances that have inefficient utilization for the last 30 days and downsizes or deletes them after approval. \n See the [README](https://github.com/flexera-public/policy_templates/tree/master/cost/azure/rightsize_compute_instances/) and [docs.flexera.com/flexera/EN/Automation](https://docs.flexera.com/flexera/EN/Automation/AutomationGS.htm) to learn more."
long_description ""
category "Cost"
severity "low"
default_frequency "weekly"
info(
  version: "6.0.5",
  provider: "Azure",
  service: "Compute",
  policy_set: "Rightsize Compute Instances",
  recommendation_type: "Usage Reduction",
  hide_skip_approvals: "true"
)

###############################################################################
# Parameters
###############################################################################

parameter "param_email" do
  type "list"
  category "Policy Settings"
  label "Email Addresses"
  description "A list of email addresses to notify."
  default []
end

parameter "param_azure_endpoint" do
  type "string"
  category "Policy Settings"
  label "Azure Endpoint"
  description "Select the API endpoint to use for Azure. Use default value of management.azure.com unless using Azure China."
  allowed_values "management.azure.com", "management.chinacloudapi.cn"
  default "management.azure.com"
end

parameter "param_min_savings" do
  type "number"
  category "Policy Settings"
  label "Minimum Savings Threshold"
  description "Minimum potential savings required to generate a recommendation"
  min_value 0
  default 0
end

parameter "param_exclusion_tags" do
  type "list"
  category "Filters"
  label "Exclusion Tags"
  description "Cloud native tags to ignore resources that you don't want to produce recommendations for. Enter the Key name to filter resources with a specific Key, regardless of Value, and enter Key==Value to filter resources with a specific Key:Value pair. Other operators and regex are supported; please see the README for more details."
  default []
end

parameter "param_exclusion_tags_boolean" do
  type "string"
  category "Filters"
  label "Exclusion Tags: Any / All"
  description "Whether to filter instances containing any of the specified tags or only those that contain all of them. Only applicable if more than one value is entered in the 'Exclusion Tags' field."
  allowed_values "Any", "All"
  default "Any"
end

parameter "param_subscriptions_allow_or_deny" do
  type "string"
  category "Filters"
  label "Allow/Deny Subscriptions"
  description "Allow or Deny entered Subscriptions. See the README for more details."
  allowed_values "Allow", "Deny"
  default "Allow"
end

parameter "param_subscriptions_list" do
  type "list"
  category "Filters"
  label "Allow/Deny Subscriptions List"
  description "A list of allowed or denied Subscription IDs/names. See the README for more details."
  default []
end

parameter "param_regions_allow_or_deny" do
  type "string"
  category "Filters"
  label "Allow/Deny Regions"
  description "Allow or Deny entered regions. See the README for more details."
  allowed_values "Allow", "Deny"
  default "Allow"
end

parameter "param_regions_list" do
  type "list"
  category "Filters"
  label "Allow/Deny Regions List"
  description "A list of allowed or denied regions. See the README for more details."
  default []
end

parameter "param_exclude_stopped" do
  type "string"
  category "Filters"
  label "Exclude Stopped Virtual Machines"
  description "Whether or not to filter stopped virtual machines from the results. If set to \"Yes\", only running virtual machines will be included in the results."
  allowed_values "Yes", "No"
  default "No"
end

parameter "param_exclude_databricks" do
  type "string"
  category "Filters"
  label "Exclude Databricks"
  description "Whether or not to filter virtual machines used for Azure Databricks from the results. If set to \"Yes\", virtual machines for Azure Databricks will not be included in the results."
  allowed_values "Yes", "No"
  default "No"
end

parameter "param_stats_idle_threshold_cpu_value" do
  type "number"
  category "Statistics"
  label "Idle Instance CPU Threshold (%)"
  description "The CPU threshold at which to consider an instance to be 'idle' and therefore be flagged for termination. Set to -1 to ignore CPU utilization"
  min_value -1
  max_value 100
  default 5
end

parameter "param_stats_idle_threshold_mem_value" do
  type "number"
  category "Statistics"
  label "Idle Instance Memory Threshold (%)"
  description "The Memory threshold at which to consider an instance to be 'idle' and therefore be flagged for termination. Set to -1 to ignore memory utilization"
  min_value -1
  max_value 100
  default 5
end

parameter "param_stats_underutil_threshold_cpu_value" do
  type "number"
  category "Statistics"
  label "Underutilized Instance CPU Threshold (%)"
  description "The CPU threshold at which to consider an instance to be 'underutilized' and therefore be flagged for downsizing. Set to -1 to ignore CPU utilization"
  min_value -1
  max_value 100
  default 40
end

parameter "param_stats_underutil_threshold_mem_value" do
  type "number"
  category "Statistics"
  label "Underutilized Instance Memory Threshold (%)"
  description "The Memory threshold at which to consider an instance to be 'underutilized' and therefore be flagged for downsizing. Set to -1 to ignore memory utilization"
  min_value -1
  max_value 100
  default 40
end

parameter "param_stats_check_both" do
  type "string"
  category "Statistics"
  label "Idle/Utilized for both CPU/Memory or either"
  description "Set whether an instance should be considered idle and/or underutilized only if both CPU and memory are under the thresholds or if either CPU or memory are under. Note: this parameter is only valid when at least one Memory Utilization threshold and one CPU Utilization threshold is NOT set to -1"
  allowed_values "Both CPU and Memory", "Either CPU or Memory"
  default "Either CPU or Memory"
end

parameter "param_stats_threshold" do
  type "string"
  category "Statistics"
  label "Threshold Statistic"
  description "Statistic to use when determining if an instance is idle/underutilized."
  allowed_values "Average", "Maximum", "p99", "p95", "p90"
  default "Average"
end

parameter "param_stats_interval" do
  type "string"
  category "Statistics"
  label "Statistic Interval"
  description "The interval to use when gathering Azure metrics data. Smaller intervals produce more accurate results at the expense of policy memory usage and completion time due to larger data sets."
  allowed_values "1 Minute", "5 Minutes", "15 Minutes", "30 Minutes", "1 Hour", "6 Hours", "12 Hours", "1 Day"
  default "15 Minutes"
end

parameter "param_stats_lookback" do
  type "number"
  category "Statistics"
  label "Statistic Lookback Period"
  description "How many days back to look at CPU and/or memory data for instances. This value cannot be set higher than 90 because Azure does not retain metrics for longer than 90 days."
  min_value 1
  max_value 90
  default 30
end

parameter "param_downsize_multiple" do
  type "string"
  category "Policy Settings"
  label "Skip Instance Sizes"
  description "Whether to recommend downsizing multiple sizes. When set to 'No', only the next smaller size will ever be recommended for downsizing. When set to 'Yes', more aggressive downsizing recommendations will be made when appropriate."
  allowed_values "Yes", "No"
  default "No"
end

parameter "param_automatic_action" do
  type "list"
  category "Actions"
  label "Automatic Actions"
  description "When this value is set, this policy will automatically take the selected action."
  allowed_values ["Downsize Underutilized Instances", "Power Off Idle Instances", "Delete Idle Instances"]
  default []
end

parameter "param_skipshutdown" do
  type "string"
  category "Actions"
  label "Power Off Type"
  description "Whether to perform a graceful shutdown or a forced shutdown when powering off idle instances. Only applicable when taking action against instances."
  allowed_values "Graceful", "Forced"
  default "Graceful"
end

###############################################################################
# Authentication
###############################################################################

credentials "auth_azure" do
  schemes "oauth2"
  label "Azure"
  description "Select the Azure Resource Manager Credential from the list."
  tags "provider=azure_rm"
end

credentials "auth_flexera" do
  schemes "oauth2"
  label "Flexera"
  description "Select Flexera One OAuth2 credentials"
  tags "provider=flexera"
end

###############################################################################
# Pagination
###############################################################################

pagination "pagination_azure" do
  get_page_marker do
    body_path "nextLink"
  end
  set_page_marker do
    uri true
  end
end

###############################################################################
# Datasources & Scripts
###############################################################################

# Get applied policy metadata for use later
datasource "ds_applied_policy" do
  request do
    auth $auth_flexera
    host rs_governance_host
    path join(["/api/governance/projects/", rs_project_id, "/applied_policies/", policy_id])
    header "Api-Version", "1.0"
  end
end

datasource "ds_billing_centers" do
  request do
    auth $auth_flexera
    host rs_optima_host
    path join(["/analytics/orgs/", rs_org_id, "/billing_centers"])
    header "Api-Version", "1.0"
    header "User-Agent", "RS Policies"
    ignore_status [403]
  end
  result do
    encoding "json"
    collect jmes_path(response, "[*]") do
      field "href", jmes_path(col_item, "href")
      field "id", jmes_path(col_item, "id")
      field "name", jmes_path(col_item, "name")
      field "parent_id", jmes_path(col_item, "parent_id")
    end
  end
end

# Gather top level billing center IDs for when we pull cost data
datasource "ds_top_level_bcs" do
  run_script $js_top_level_bcs, $ds_billing_centers
end

script "js_top_level_bcs", type: "javascript" do
  parameters "ds_billing_centers"
  result "result"
  code <<-EOS
  filtered_bcs = _.filter(ds_billing_centers, function(bc) {
    return bc['parent_id'] == null || bc['parent_id'] == undefined
  })

  result = _.compact(_.pluck(filtered_bcs, 'id'))
EOS
end

datasource "ds_currency_reference" do
  request do
    host "raw.githubusercontent.com"
    path "/flexera-public/policy_templates/master/data/currency/currency_reference.json"
    header "User-Agent", "RS Policies"
  end
end

datasource "ds_currency_code" do
  request do
    auth $auth_flexera
    host rs_optima_host
    path join(["/bill-analysis/orgs/", rs_org_id, "/settings/currency_code"])
    header "Api-Version", "0.1"
    header "User-Agent", "RS Policies"
    ignore_status [403]
  end
  result do
    encoding "json"
    field "id", jmes_path(response, "id")
    field "value", jmes_path(response, "value")
  end
end

datasource "ds_currency" do
  run_script $js_currency, $ds_currency_reference, $ds_currency_code
end

script "js_currency", type:"javascript" do
  parameters "ds_currency_reference", "ds_currency_code"
  result "result"
  code <<-EOS
  symbol = "$"
  separator = ","

  if (ds_currency_code['value'] != undefined) {
    if (ds_currency_reference[ds_currency_code['value']] != undefined) {
      symbol = ds_currency_reference[ds_currency_code['value']]['symbol']

      if (ds_currency_reference[ds_currency_code['value']]['t_separator'] != undefined) {
        separator = ds_currency_reference[ds_currency_code['value']]['t_separator']
      } else {
        separator = ""
      }
    }
  }

  result = {
    symbol: symbol,
    separator: separator
  }
EOS
end

datasource "ds_stats_interval" do
  run_script $js_stats_interval, $param_stats_interval
end

script "js_stats_interval", type: "javascript" do
  parameters "param_stats_interval"
  result "result"
  code <<-EOS
  // Tables to convert human-readable parameter values to their API equivalents
  interval_table = {
    "1 Minute": "PT1M",
    "5 Minutes": "PT5M",
    "15 Minutes": "PT15M",
    "30 Minutes": "PT30M",
    "1 Hour": "PT1H",
    "6 Hours": "PT6H",
    "12 Hours": "PT12H",
    "1 Day": "P1D"
  }

  result = {
    pretty: param_stats_interval,
    api: interval_table[param_stats_interval]
  }
EOS
end

datasource "ds_azure_subscriptions" do
  request do
    auth $auth_azure
    pagination $pagination_azure
    host $param_azure_endpoint
    path "/subscriptions/"
    query "api-version", "2020-01-01"
    header "User-Agent", "RS Policies"
    # Header X-Meta-Flexera has no affect on datasource query, but is required for Meta Policies
    # Forces `ds_is_deleted` datasource to run first during policy execution
    header "Meta-Flexera", val($ds_is_deleted, "path")
    # Ignore status 400, 403, and 404 which can be returned in certain (legacy) types of Azure Subscriptions
    ignore_status [400, 403, 404]
  end
  result do
    encoding "json"
    collect jmes_path(response, "value[*]") do
      field "id", jmes_path(col_item, "subscriptionId")
      field "name", jmes_path(col_item, "displayName")
      field "state", jmes_path(col_item, "state")
    end
  end
end

datasource "ds_azure_subscriptions_filtered" do
  run_script $js_azure_subscriptions_filtered, $ds_azure_subscriptions, $param_subscriptions_allow_or_deny, $param_subscriptions_list
end

script "js_azure_subscriptions_filtered", type: "javascript" do
  parameters "ds_azure_subscriptions", "param_subscriptions_allow_or_deny", "param_subscriptions_list"
  result "result"
  code <<-EOS
  if (param_subscriptions_list.length > 0) {
    result = _.filter(ds_azure_subscriptions, function(subscription) {
      include_subscription = _.contains(param_subscriptions_list, subscription['id']) || _.contains(param_subscriptions_list, subscription['name'])

      if (param_subscriptions_allow_or_deny == "Deny") {
        include_subscription = !include_subscription
      }

      return include_subscription
    })
  } else {
    result = ds_azure_subscriptions
  }
EOS
end

datasource "ds_azure_instances" do
  iterate $ds_azure_subscriptions_filtered
  request do
    auth $auth_azure
    pagination $pagination_azure
    host $param_azure_endpoint
    path join(["/subscriptions/", val(iter_item, "id"), "/providers/Microsoft.Compute/virtualMachines"])
    query "api-version", "2024-07-01"
    header "User-Agent", "RS Policies"
    # Ignore status 400, 403, and 404 which can be returned in certain (legacy) types of Azure Subscriptions
    ignore_status [400, 403, 404]
  end
  result do
    encoding "json"
    collect jmes_path(response, "value[*]") do
      field "resourceID", jmes_path(col_item, "id")
      field "resourceGroup", get(4, split(jmes_path(col_item, "id"), '/'))
      field "resourceKind", jmes_path(col_item, "type")
      field "name", jmes_path(col_item, "name")
      field "region", jmes_path(col_item, "location")
      field "imagePublisher", jmes_path(col_item, "properties.storageProfile.imageReference.publisher")
      field "imageOffer", jmes_path(col_item, "properties.storageProfile.imageReference.offer")
      field "imageSKU", jmes_path(col_item, "properties.storageProfile.imageReference.sku")
      field "osType", jmes_path(col_item, "properties.storageProfile.osDisk.osType")
      field "dataDisks", jmes_path(col_item, "properties.storageProfile.dataDisks")
      field "resourceType", jmes_path(col_item, "properties.hardwareProfile.vmSize")
      field "tags", jmes_path(col_item, "tags")
      field "subscriptionId", val(iter_item, "id")
      field "subscriptionName", val(iter_item, "name")
    end
  end
end

datasource "ds_azure_instance_statuses" do
  iterate $ds_azure_subscriptions_filtered
  request do
    auth $auth_azure
    pagination $pagination_azure
    host $param_azure_endpoint
    path join(["/subscriptions/", val(iter_item, "id"), "/providers/Microsoft.Compute/virtualMachines"])
    query "api-version", "2024-03-01"
    query "statusOnly", "true"
    header "User-Agent", "RS Policies"
    # Ignore status 400, 403, and 404 which can be returned in certain (legacy) types of Azure Subscriptions
    ignore_status [400, 403, 404]
  end
  result do
    encoding "json"
    collect jmes_path(response, "value[*]") do
      field "resourceID", jmes_path(col_item, "id")
      field "statuses", jmes_path(col_item, "properties.instanceView.statuses")
    end
  end
end

datasource "ds_azure_instances_with_status" do
  run_script $js_azure_instances_with_status, $ds_azure_instances, $ds_azure_instance_statuses
end

script "js_azure_instances_with_status", type: "javascript" do
  parameters "ds_azure_instances", "ds_azure_instance_statuses"
  result "result"
  code <<-EOS
  status_object = {}

  _.each(ds_azure_instance_statuses, function(item) {
    status_object[item['resourceID']] = item['statuses']
  })

  result = _.map(ds_azure_instances, function(vm) {
    dataDiskCount = 0
    if (vm['dataDisks']) { dataDiskCount = vm['dataDisks'].length }

    return {
      resourceID: vm["resourceID"],
      resourceGroup: vm["resourceGroup"],
      resourceKind: vm["resourceKind"],
      name: vm["name"],
      region: vm["region"],
      imagePublisher: vm["imagePublisher"],
      imageOffer: vm["imageOffer"],
      imageSKU: vm["imageSKU"],
      osType: vm["osType"],
      dataDiskCount: dataDiskCount,
      resourceType: vm["resourceType"],
      tags: vm["tags"],
      subscriptionId: vm["subscriptionId"],
      subscriptionName: vm["subscriptionName"],
      statuses: status_object[vm["resourceID"]]
    }
  })
EOS
end

datasource "ds_azure_instances_tag_filtered" do
  run_script $js_azure_instances_tag_filtered, $ds_azure_instances_with_status, $param_exclusion_tags, $param_exclusion_tags_boolean
end

script "js_azure_instances_tag_filtered", type: "javascript" do
  parameters "ds_azure_instances_with_status", "param_exclusion_tags", "param_exclusion_tags_boolean"
  result "result"
  code <<-EOS
  comparators = _.map(param_exclusion_tags, function(item) {
    if (item.indexOf('==') != -1) {
      return { comparison: '==', key: item.split('==')[0], value: item.split('==')[1], string: item }
    }

    if (item.indexOf('!=') != -1) {
      return { comparison: '!=', key: item.split('!=')[0], value: item.split('!=')[1], string: item }
    }

    if (item.indexOf('=~') != -1) {
      value = item.split('=~')[1]
      regex = new RegExp(value.slice(1, value.length - 1))
      return { comparison: '=~', key: item.split('=~')[0], value: regex, string: item }
    }

    if (item.indexOf('!~') != -1) {
      value = item.split('!~')[1]
      regex = new RegExp(value.slice(1, value.length - 1))
      return { comparison: '!~', key: item.split('!~')[0], value: regex, string: item }
    }

    // If = is present but none of the above are, assume user error and that the user intended ==
    if (item.indexOf('=') != -1) {
      return { comparison: '==', key: item.split('=')[0], value: item.split('=')[1], string: item }
    }

    // Assume we're just testing for a key if none of the comparators are found
    return { comparison: 'key', key: item, value: null, string: item }
  })

  if (param_exclusion_tags.length > 0) {
    result = _.reject(ds_azure_instances_with_status, function(resource) {
      resource_tags = {}
      if (typeof(resource['tags']) == 'object') { resource_tags = resource['tags'] }

      // Store a list of found tags
      found_tags = []

      _.each(comparators, function(comparator) {
        comparison = comparator['comparison']
        value = comparator['value']
        string = comparator['string']
        resource_tag = resource_tags[comparator['key']]

        if (comparison == 'key' && resource_tag != undefined) { found_tags.push(string) }
        if (comparison == '==' && resource_tag == value) { found_tags.push(string) }
        if (comparison == '!=' && resource_tag != value) { found_tags.push(string) }

        if (comparison == '=~') {
          if (resource_tag != undefined && value.test(resource_tag)) { found_tags.push(string) }
        }

        if (comparison == '!~') {
          if (resource_tag == undefined) { found_tags.push(string) }
          if (resource_tag != undefined && value.test(resource_tag)) { found_tags.push(string) }
        }
      })

      all_tags_found = found_tags.length == comparators.length
      any_tags_found = found_tags.length > 0 && param_exclusion_tags_boolean == 'Any'

      return all_tags_found || any_tags_found
    })
  } else {
    result = ds_azure_instances_with_status
  }
EOS
end

datasource "ds_azure_instances_region_filtered" do
  run_script $js_azure_instances_region_filtered, $ds_azure_instances_tag_filtered, $param_regions_allow_or_deny, $param_regions_list
end

script "js_azure_instances_region_filtered", type: "javascript" do
  parameters "ds_azure_instances_tag_filtered", "param_regions_allow_or_deny", "param_regions_list"
  result "result"
  code <<-EOS
  if (param_regions_list.length > 0) {
    result = _.filter(ds_azure_instances_tag_filtered, function(vm) {
      include_vm = _.contains(param_regions_list, vm['region'])
      if (param_regions_allow_or_deny == "Deny") { include_vm = !include_vm }
      return include_vm
    })
  } else {
    result = ds_azure_instances_tag_filtered
  }
EOS
end

datasource "ds_azure_instances_databricks_filtered" do
  run_script $js_azure_instances_databricks_filtered, $ds_azure_instances_region_filtered, $param_exclude_databricks
end

script "js_azure_instances_databricks_filtered", type: "javascript" do
  parameters "ds_azure_instances_region_filtered", "param_exclude_databricks"
  result "result"
  code <<-EOS
  if (param_exclude_databricks == "Yes") {
    result = _.filter(ds_azure_instances_region_filtered, function(vm) {
      imageOffer = ""
      if (typeof(vm['imageOffer']) == 'string') { imageOffer = vm['imageOffer'] }

      imagePublisher = ""
      if (typeof(vm['imagePublisher']) == 'string') { imagePublisher = vm['imagePublisher'] }

      return imageOffer.toLowerCase().indexOf('databricks') == -1 && imagePublisher.toLowerCase().indexOf('databricks') == -1
    })
  } else {
    result = ds_azure_instances_region_filtered
  }
EOS
end

datasource "ds_azure_instances_status_filtered" do
  run_script $js_azure_instances_status_filtered, $ds_azure_instances_databricks_filtered, $param_exclude_stopped
end

script "js_azure_instances_status_filtered", type: "javascript" do
  parameters "ds_azure_instances_databricks_filtered", "param_exclude_stopped"
  result "result"
  code <<-EOS
  if (param_exclude_stopped == "Yes") {
    result = _.filter(ds_azure_instances_databricks_filtered, function(vm) {
      status_codes = _.pluck(vm['statuses'], 'code')
      return _.contains(status_codes, 'PowerState/running')
    })
  } else {
    result = ds_azure_instances_databricks_filtered
  }
EOS
end

datasource "ds_azure_instances_metrics" do
  iterate $ds_azure_instances_status_filtered
  request do
    run_script $js_azure_instances_metrics, val(iter_item, "resourceID"), $ds_stats_interval, $param_azure_endpoint, $param_stats_lookback
  end
  result do
    encoding "json"
    field "value", val(response, "value")
    field "resourceName", val(iter_item, "name")
    field "resourceGroup", val(iter_item, "resourceGroup")
    field "resourceID", val(iter_item, "resourceID")
    field "resourceKind", val(iter_item, "resourceKind")
    field "region", val(iter_item, "region")
    field "tags", val(iter_item, "tags")
    field "statuses", val(iter_item, "statuses")
    field "imagePublisher", val(iter_item, "imagePublisher")
    field "imageOffer", val(iter_item, "imageOffer")
    field "imageSKU", val(iter_item, "imageSKU")
    field "osType", val(iter_item, "osType")
    field "dataDiskCount", val(iter_item, "dataDiskCount")
    field "resourceType", val(iter_item, "resourceType")
    field "subscriptionId", val(iter_item, "subscriptionId")
    field "subscriptionName", val(iter_item, "subscriptionName")
  end
end

script "js_azure_instances_metrics", type: "javascript" do
  parameters "resourceID", "ds_stats_interval", "param_azure_endpoint", "param_stats_lookback"
  result "request"
  code <<-EOS
  end_date = new Date()
  end_date.setMilliseconds(999)
  end_date.setSeconds(59)
  end_date.setMinutes(59)
  end_date.setHours(23)

  start_date = new Date()
  start_date.setDate(start_date.getDate() - param_stats_lookback)
  start_date.setMilliseconds(0)
  start_date.setSeconds(0)
  start_date.setMinutes(0)

  timespan = start_date.toISOString() + "/" + end_date.toISOString()

  var request = {
    auth: "auth_azure",
    pagination: "pagination_azure",
    host: param_azure_endpoint,
    path: resourceID + "/providers/microsoft.insights/metrics",
    query_params: {
      "api-version": "2018-01-01",
      "timespan": timespan,
      "interval": ds_stats_interval["api"],
      "metricnames": "Percentage CPU,Available Memory Percentage",
      "aggregation": "average,maximum,minimum"
    },
    headers: {
      "User-Agent": "RS Policies"
    },
    // Ignore status 400, 403, and 404 which can be returned in certain (legacy) types of Azure Subscriptions
    ignore_status: [400, 403, 404]
  }
EOS
end

datasource "ds_azure_instances_metrics_organized" do
  run_script $js_azure_instances_metrics_organized, $ds_azure_instances_metrics
end

script "js_azure_instances_metrics_organized", type: "javascript" do
  parameters "ds_azure_instances_metrics"
  result "result"
  code <<-EOS
  // Function to calculate percentiles from metrics
  function percentile(arr, p) {
    // array needs to be sorted to select based on percentile
    arr.sort(function(a, b) { return a - b })

    // Get the index using desired percentile and array length
    index = (p / 100) * arr.length

    // Round index value to nearest integer and return the value of that element in sorted array arr
    return arr[Math.ceil(index) - 1]
  }

  result = []

  _.each(ds_azure_instances_metrics, function(vm) {
    cpu_stats = null
    mem_stats = null

    _.each(vm['value'], function(stat) {
      if (stat["timeseries"][0] != undefined) {
        if (stat['name']['value'] == "Percentage CPU") {
          cpu_stats = stat["timeseries"][0]["data"]
        }

        if (stat['name']['value'] == "Available Memory Percentage") {
          mem_stats = stat["timeseries"][0]["data"]
        }
      }
    })

    // Default to 0 in case there are no stats because instance is not powered on
    // Minimum defaults to "null" to ensure comparisons work. It's adjusted to 0 later if needed.
    cpu_min = null
    cpu_max = 0
    cpu_avg = 0
    cpu_p90 = 0
    cpu_p95 = 0
    cpu_p99 = 0
    cpu_avg_count = 0
    cpu_all_stats = []

    if (cpu_stats != null && cpu_stats != undefined) {
      _.each(cpu_stats, function(item) {
        if (item["average"] != undefined && item["average"] != null) {
          cpu_all_stats.push(item["average"])
          cpu_avg += item["average"]
          cpu_avg_count += 1
        }

        if (item["minimum"] != undefined && item["minimum"] != null) {
          cpu_all_stats.push(item["minimum"])
          if (item["minimum"] < cpu_min || cpu_min == null) { cpu_min = item["minimum"] }
        }

        if (item["maximum"] != undefined && item["maximum"] != null) {
          cpu_all_stats.push(item["maximum"])
          if (item["maximum"] > cpu_max) { cpu_max = item["maximum"] }
        }
      })
    }

    if (cpu_min == null) { cpu_min = 0 }
    if (cpu_avg_count != 0) { cpu_avg = cpu_avg / cpu_avg_count }

    if (cpu_all_stats.length > 0) {
      cpu_p90 = percentile(cpu_all_stats, 90)
      cpu_p95 = percentile(cpu_all_stats, 95)
      cpu_p99 = percentile(cpu_all_stats, 99)
    }

    // Default to 0 in case there are no stats because instance is not powered on
    // Minimum defaults to "null" to ensure comparisons work. It's adjusted to 0 later if needed.
    mem_min = null
    mem_max = 0
    mem_avg = 0
    mem_p90 = 0
    mem_p95 = 0
    mem_p99 = 0
    mem_avg_count = 0
    mem_all_stats = []

    if (mem_stats != null && mem_stats != undefined) {
      _.each(mem_stats, function(item) {
        // Note: The switch between min and max is intentional because
        // the maximum available memory is equivalent to the minimum
        // memory used.
        if (item["average"] != undefined && item["average"] != null) {
          mem_all_stats.push(item["average"])
          mem_avg += item["average"]
          mem_avg_count += 1
        }

        if (item["minimum"] != undefined && item["minimum"] != null) {
          var maximum = 100 - item["minimum"]
          mem_all_stats.push(maximum)
          if (maximum > mem_max) { mem_max = maximum }
        }

        if (item["maximum"] != undefined && item["maximum"] != null) {
          var minimum = 100 - item["maximum"]
          mem_all_stats.push(minimum)
          if (minimum < mem_min || mem_min == null) { mem_min = minimum }
        }
      })
    }

    if (mem_min == null) { mem_min = 0 }
    if (mem_avg_count != 0) { mem_avg = mem_avg / mem_avg_count }

    if (mem_all_stats.length > 0) {
      mem_p90 = percentile(mem_all_stats, 90)
      mem_p95 = percentile(mem_all_stats, 95)
      mem_p99 = percentile(mem_all_stats, 99)
    }

    vm_tags = []

    if (typeof(vm['tags']) == 'object') {
      _.each(Object.keys(vm['tags']), function(key) {
        vm_tags.push(key + '=' + vm['tags'][key])
      })
    }

    status_codes = _.pluck(vm['statuses'], 'code')
    powerstate = _.find(status_codes, function(code) { return code.indexOf('PowerState') == 0 })
    state = powerstate.split('/')[1]

    result.push({
      resourceName: vm['resourceName'],
      resourceGroup: vm['resourceGroup'],
      resourceID: vm['resourceID'],
      resourceKind: vm['resourceKind'],
      region: vm['region'],
      imagePublisher: vm['imagePublisher'],
      imageOffer: vm['imageOffer'],
      imageSKU: vm['imageSKU'],
      osType: vm['osType'],
      dataDiskCount: vm['dataDiskCount'],
      resourceType: vm['resourceType'],
      accountID: vm['subscriptionId'],
      accountName: vm['subscriptionName'],
      tags: vm_tags.join(', '),
      state: state,
      cpu_minimum: Math.round(cpu_min * 100) / 100,
      cpu_maximum: Math.round(cpu_max * 100) / 100,
      cpu_average: Math.round(cpu_avg * 100) / 100,
      cpu_p90: Math.round(cpu_p90 * 100) / 100,
      cpu_p95: Math.round(cpu_p95 * 100) / 100,
      cpu_p99: Math.round(cpu_p99 * 100) / 100,
      mem_minimum: Math.round(mem_min * 100) / 100,
      mem_maximum: Math.round(mem_max * 100) / 100,
      mem_average: Math.round(mem_avg * 100) / 100,
      mem_p90: Math.round(mem_p90 * 100) / 100,
      mem_p95: Math.round(mem_p95 * 100) / 100,
      mem_p99: Math.round(mem_p99 * 100) / 100,
      service: "Microsoft.Compute",
      underutil_message: "",
      idle_message: "",
      underutil_total_savings: "",
      idle_total_savings: ""
    })
  })
EOS
end

datasource "ds_instance_costs" do
  iterate $ds_azure_subscriptions_filtered
  request do
    run_script $js_instance_costs, val(iter_item, 'id'), $ds_top_level_bcs, rs_org_id, rs_optima_host
  end
  result do
    encoding "json"
    collect jmes_path(response, "rows[*]") do
      field "resourceID", jmes_path(col_item, "dimensions.resource_id")
      field "cost", jmes_path(col_item, "metrics.cost_amortized_unblended_adj")
    end
  end
end

script "js_instance_costs", type: "javascript" do
  parameters "subscription_id", "ds_top_level_bcs", "rs_org_id", "rs_optima_host"
  result "request"
  code <<-EOS
  end_date = new Date()
  end_date.setDate(end_date.getDate() - 2)
  end_date = end_date.toISOString().split('T')[0]

  start_date = new Date()
  start_date.setDate(start_date.getDate() - 3)
  start_date = start_date.toISOString().split('T')[0]

  var request = {
    auth: "auth_flexera",
    host: rs_optima_host,
    verb: "POST",
    path: "/bill-analysis/orgs/" + rs_org_id + "/costs/select",
    body_fields: {
      dimensions: ["resource_id"],
      granularity: "day",
      start_at: start_date,
      end_at: end_date,
      metrics: ["cost_amortized_unblended_adj"],
      billing_center_ids: ds_top_level_bcs,
      limit: 100000,
      filter: {
        "type": "and",
        "expressions": [
          {
            "type": "or",
            "expressions": [
              {
                "dimension": "service",
                "type": "equal",
                "value": "Microsoft.Compute"
              },
              {
                "dimension": "service",
                "type": "equal",
                "value": "microsoft.compute"
              }
            ]
          },
          {
            "dimension": "vendor_account",
            "type": "equal",
            "value": subscription_id
          },
          {
            "type": "not",
            "expression": {
              "dimension": "adjustment_name",
              "type": "substring",
              "substring": "Shared"
            }
          }
        ]
      }
    },
    headers: {
      'User-Agent': "RS Policies",
      'Api-Version': "1.0"
    },
    ignore_status: [400]
  }
EOS
end

datasource "ds_instance_costs_grouped" do
  run_script $js_instance_costs_grouped, $ds_instance_costs
end

script "js_instance_costs_grouped", type: "javascript" do
  parameters "ds_instance_costs"
  result "result"
  code <<-EOS
  // Multiple a single day's cost by the average number of days in a month.
  // The 0.25 is to account for leap years for extra precision.
  cost_multiplier = 365.25 / 12

  // Group cost data by resourceId for later use
  result = {}

  _.each(ds_instance_costs, function(item) {
    id = item['resourceID'].toLowerCase()

    if (result[id] == undefined) { result[id] = 0.0 }
    result[id] += item['cost'] * cost_multiplier
  })
EOS
end

datasource "ds_azure_instance_size_map" do
  request do
    host "raw.githubusercontent.com"
    path "/flexera-public/policy_templates/master/data/azure/instance_types.json"
    header "User-Agent", "RS Policies"
  end
end

datasource "ds_azure_regions_for_instance_sizes" do
  run_script $js_azure_regions_for_instance_sizes, $ds_azure_instances_metrics_organized
end

script "js_azure_regions_for_instance_sizes", type: "javascript" do
  parameters "ds_azure_instances_metrics_organized"
  result "result"
  code <<-EOS
  result = []

  if (ds_azure_instances_metrics_organized.length > 0) {
    regions = _.uniq(_.compact(_.pluck(ds_azure_instances_metrics_organized, "region")))

    result = _.map(regions, function(region) {
      return {
        subscriptionId: ds_azure_instances_metrics_organized[0]['accountID'],
        region: region
      }
    })
  }
EOS
end

datasource "ds_azure_instance_size_details" do
  iterate $ds_azure_regions_for_instance_sizes
  request do
    auth $auth_azure
    pagination $pagination_azure
    host $param_azure_endpoint
    path join(["/subscriptions/", val(iter_item, "subscriptionId"), "/providers/Microsoft.Compute/locations/", val(iter_item, "region"), "/vmSizes"])
    query "api-version", "2024-07-01"
    header "User-Agent", "RS Policies"
    # Ignore status 400, 403, and 404 which can be returned in certain (legacy) types of Azure Subscriptions
    ignore_status [400, 403, 404]
  end
  result do
    encoding "json"
    collect jmes_path(response, "value[*]") do
      field "name", jmes_path(col_item, "name")
      field "maxDataDiskCount", jmes_path(col_item, "maxDataDiskCount")
    end
  end
end

datasource "ds_azure_disk_count_table" do
  run_script $js_azure_disk_count_table, $ds_azure_instance_size_details
end

script "js_azure_disk_count_table", type: "javascript" do
  parameters "ds_azure_instance_size_details"
  result "result"
  code <<-EOS
  result = {}
  _.each(ds_azure_instance_size_details, function(size) { result[size['name']] = size['maxDataDiskCount'] })
EOS
end

datasource "ds_idle_and_underutil_instances" do
  run_script $js_idle_and_underutil_instances, $ds_azure_instances_region_filtered, $ds_azure_instances_metrics_organized, $ds_instance_costs_grouped, $ds_azure_instance_size_map, $ds_stats_interval, $ds_azure_disk_count_table, $ds_currency, $ds_applied_policy, $param_stats_idle_threshold_cpu_value, $param_stats_idle_threshold_mem_value, $param_stats_underutil_threshold_cpu_value, $param_stats_underutil_threshold_mem_value, $param_stats_check_both, $param_stats_threshold, $param_min_savings, $param_stats_lookback, $param_exclude_databricks, $param_downsize_multiple
end

script "js_idle_and_underutil_instances", type:"javascript" do
  parameters "ds_azure_instances_region_filtered", "ds_azure_instances_metrics_organized", "ds_instance_costs_grouped", "ds_azure_instance_size_map", "ds_stats_interval", "ds_azure_disk_count_table", "ds_currency", "ds_applied_policy", "param_stats_idle_threshold_cpu_value", "param_stats_idle_threshold_mem_value", "param_stats_underutil_threshold_cpu_value", "param_stats_underutil_threshold_mem_value", "param_stats_check_both", "param_stats_threshold", "param_min_savings", "param_stats_lookback", "param_exclude_databricks", "param_downsize_multiple"
  result "result"
  code <<-'EOS'
  // Used for formatting numbers to look pretty
  function formatNumber(number, separator) {
    formatted_number = "0"

    if (number) {
      formatted_number = (Math.round(number * 100) / 100).toString().split(".")[0]

      if (separator) {
        withSeparator = ""

        for (var i = 0; i < formatted_number.length; i++) {
          if (i > 0 && (formatted_number.length - i) % 3 == 0) { withSeparator += separator }
          withSeparator += formatted_number[i]
        }

        formatted_number = withSeparator
      }

      decimal = (Math.round(number * 100) / 100).toString().split(".")[1]
      if (decimal) { formatted_number += "." + decimal }
    }

    return formatted_number
  }

  // The key name is lowercase, param value needs to be lowercase.
  threshold_statistic = param_stats_threshold.toLowerCase()

  // Determine whether we're checking for CPU, memory, or both
  checking_cpu = param_stats_underutil_threshold_cpu_value != -1 || param_stats_idle_threshold_cpu_value != -1
  checking_mem = param_stats_underutil_threshold_mem_value != -1 || param_stats_idle_threshold_mem_value != -1

  underutil_total_savings = 0.0
  idle_total_savings = 0.0

  underutil_list = []
  idle_list = []

  // Only bother doing anything if we're checking at least one metric
  if (checking_cpu || checking_mem) {
    // Loop through metrics data, appending cost data
    _.each(ds_azure_instances_metrics_organized, function(instance) {
      id = instance['resourceID'].toLowerCase()

      // Assume cost is 0 unless we have cost data for the instance
      total_cost = 0.0
      if (ds_instance_costs_grouped[id] != undefined) { total_cost = ds_instance_costs_grouped[id] }

      // Add baked-in values
      instance['savingsCurrency'] = ds_currency['symbol']
      instance['lookbackPeriod'] = param_stats_lookback
      instance['thresholdType'] = param_stats_threshold

      // Store relevant CPU and memory stats into these variables for later use
      cpu_value = instance['cpu_' + threshold_statistic]
      mem_value = instance['mem_' + threshold_statistic]

      // Test for whether to consider the instance idle or underutilized.
      // Assume instance is not idle or underutilized by default.
      is_idle = false
      is_underutil = false

      // Determine if the instance is idle or underutilized for each category.
      // Store boolean result for later use.
      is_idle_cpu = cpu_value < param_stats_idle_threshold_cpu_value
      is_underutil_cpu = cpu_value < param_stats_underutil_threshold_cpu_value
      is_idle_mem = mem_value < param_stats_idle_threshold_mem_value
      is_underutil_mem = mem_value < param_stats_underutil_threshold_mem_value

      // If we're only checking CPU, simply set is_idle/is_underutil to their CPU equivalents
      if (!checking_mem) { is_idle = is_idle_cpu }
      if (!checking_mem) { is_underutil = is_underutil_cpu }

      // If we're only checking memory, simply set is_idle/is_underutil to their memory equivalents
      if (!checking_cpu) { is_idle = is_idle_mem }
      if (!checking_cpu) { is_underutil = is_underutil_mem }

      // If we're checking both, do an 'and' or an 'or' depending on the value of param_stats_check_both
      if (checking_cpu && checking_mem) {
        if (param_stats_check_both == "Both CPU and Memory") {
          is_idle = is_idle_cpu && is_idle_mem
          is_underutil = is_underutil_cpu && is_underutil_mem
        } else {
          is_idle = is_idle_cpu || is_idle_mem
          is_underutil = is_underutil_cpu || is_underutil_mem
        }
      }

      instance["newResourceType"] = null

      // Set appropriate values based on whether instance is idle or underutilized
      // and then add it to the appropriate list
      if (is_idle) {
        instance["savings"] = parseFloat(parseFloat(total_cost).toFixed(3))
        instance["recommendationType"] = "Delete"
        instance["threshold"] = param_stats_idle_threshold_cpu_value
        instance["memoryThreshold"] = param_stats_idle_threshold_mem_value
        instance["newResourceType"] = "Delete Virtual Machine"

        recommendationDetails = [
          "Delete Azure virtual machine ", instance["resourceName"], " ",
          "in Azure Subscription ", instance["accountName"], " ",
          "(", instance["accountID"], ")"
        ]

        instance["recommendationDetails"] = recommendationDetails.join('')

        if (instance['savings'] >= param_min_savings) {
          idle_total_savings += total_cost
          idle_list.push(instance)
        }
      } else if (is_underutil) {
        savingsMultiplier = 1

        instance["recommendationType"] = "Downsize"
        instance["threshold"] = param_stats_underutil_threshold_cpu_value
        instance["memoryThreshold"] = param_stats_underutil_threshold_mem_value

        if (ds_azure_instance_size_map[instance['resourceType']] && ds_azure_instance_size_map[instance['resourceType']]['down'] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['resourceType']]['down']] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['resourceType']]['down']] >= instance["dataDiskCount"]) {
          instance["newResourceType"] = ds_azure_instance_size_map[instance['resourceType']]['down']
        }

        if (instance["newResourceType"] && param_downsize_multiple == "Yes") {
          if (checking_cpu && checking_mem && param_stats_check_both == "Both CPU and Memory") {
            while (ds_azure_instance_size_map[instance['newResourceType']]['down'] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['newResourceType']]['down']] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['newResourceType']]['down']] >= instance["dataDiskCount"] && cpu_value * 2 < param_stats_underutil_threshold_cpu_value && mem_value * 2 < param_stats_underutil_threshold_mem_value) {
              cpu_value = cpu_value * 2
              mem_value = mem_value * 2
              instance["newResourceType"] = ds_azure_instance_size_map[instance['newResourceType']]['down']
              savingsMultiplier += 1
            }
          }

          if (checking_cpu && checking_mem && param_stats_check_both == "Either CPU or Memory") {
            while (ds_azure_instance_size_map[instance['newResourceType']]['down'] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['newResourceType']]['down']] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['newResourceType']]['down']] >= instance["dataDiskCount"] && (cpu_value * 2 < param_stats_underutil_threshold_cpu_value || mem_value * 2 < param_stats_underutil_threshold_mem_value)) {
              cpu_value = cpu_value * 2
              mem_value = mem_value * 2
              instance["newResourceType"] = ds_azure_instance_size_map[instance['newResourceType']]['down']
              savingsMultiplier += 1
            }
          }

          if (checking_cpu && !checking_mem) {
            while (ds_azure_instance_size_map[instance['newResourceType']]['down'] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['newResourceType']]['down']] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['newResourceType']]['down']] >= instance["dataDiskCount"] && cpu_value * 2 < param_stats_underutil_threshold_cpu_value) {
              cpu_value = cpu_value * 2
              instance["newResourceType"] = ds_azure_instance_size_map[instance['newResourceType']]['down']
              savingsMultiplier += 1
            }
          }

          if (!checking_cpu && checking_mem) {
            while (ds_azure_instance_size_map[instance['newResourceType']]['down'] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['newResourceType']]['down']] && ds_azure_disk_count_table[ds_azure_instance_size_map[instance['newResourceType']]['down']] >= instance["dataDiskCount"] && mem_value * 2 < param_stats_underutil_threshold_mem_value) {
              mem_value = mem_value * 2
              instance["newResourceType"] = ds_azure_instance_size_map[instance['newResourceType']]['down']
              savingsMultiplier += 1
            }
          }
        }

        savings = total_cost - (total_cost / (2 * savingsMultiplier))
        instance["savings"] = Math.round(savings * 1000) / 1000

        recommendationDetails = [
          "Resize Azure virtual machine ", instance["resourceName"], " ",
          "in Azure Subscription ", instance["accountName"], " ",
          "(", instance["accountID"], ") ",
          "from ", instance["resourceType"], " ",
          "to ", instance["newResourceType"]
        ]

        instance["recommendationDetails"] = recommendationDetails.join('')

        if (instance["newResourceType"] != null && instance["newResourceType"] != undefined) {
          if (savings >= param_min_savings) {
            underutil_total_savings += savings
            underutil_list.push(instance)
          }
        }
      }
    })
  }

  // Build out the detail_template for the incidents
  if (checking_cpu || checking_mem) {
    instances_total = ds_azure_instances_region_filtered.length.toString()
    underutil_instances_total = underutil_list.length.toString()
    underutil_instances_percentage = (underutil_instances_total / instances_total * 100).toFixed(2).toString() + '%'
    idle_instances_total = idle_list.length.toString()
    idle_instances_percentage = (idle_instances_total / instances_total * 100).toFixed(2).toString() + '%'

    underutil_total_savings = ds_currency['symbol'] + ' ' + formatNumber(parseFloat(underutil_total_savings).toFixed(2), ds_currency['separator'])
    idle_total_savings = ds_currency['symbol'] + ' ' + formatNumber(parseFloat(idle_total_savings).toFixed(2), ds_currency['separator'])

    underutil_verb = "are"
    if (underutil_instances_total == 1) { underutil_verb = "is" }

    idle_verb = "are"
    if (idle_instances_total == 1) { idle_verb = "is" }

    underutil_findings = [
      "Out of ", instances_total, " Azure virtual machines analyzed, ",
      underutil_instances_total, " (", underutil_instances_percentage,
      ") ", underutil_verb, " underutilized and recommended for downsizing. "
    ].join('')

    idle_findings = [
      "Out of ", instances_total, " Azure virtual machines analyzed, ",
      idle_instances_total, " (", idle_instances_percentage,
      ") ", idle_verb, " idle and recommended for termination. "
    ].join('')

    if (checking_cpu && checking_mem) {
      message_boolean = "or"

      if (param_stats_check_both == "Both CPU and Memory") {
        message_boolean = "and"
      }

      underutil_analysis_message = [
        "A virtual machine is considered underutilized if its CPU usage (",
        param_stats_threshold.toLowerCase(), ") is below ",
        param_stats_underutil_threshold_cpu_value, "% ", message_boolean,
        " its memory usage (", param_stats_threshold.toLowerCase(),
        ") is below ", param_stats_underutil_threshold_mem_value,
        "% but its CPU usage is still above or equal to ",
        param_stats_idle_threshold_cpu_value, "% ", message_boolean,
        " its memory usage is still above or equal to ",
        param_stats_idle_threshold_mem_value, "%. "
      ].join('')

      idle_analysis_message = [
        "A virtual machine is considered idle if its CPU usage (",
        param_stats_threshold.toLowerCase(), ") is below ",
        param_stats_idle_threshold_cpu_value, "% ", message_boolean,
        " its memory usage (", param_stats_threshold.toLowerCase(),
        ") is below ", param_stats_idle_threshold_mem_value, "%. "
      ].join('')

      lookback_message = [
        "CPU and memory usage was analyzed over the last ",
        param_stats_lookback.toString(), " days. ",
        "These metrics were gathered at a granularity of '",
        ds_stats_interval['pretty'], "'.\n\n"
      ].join('')
    }

    if (checking_cpu && !checking_mem) {
      underutil_analysis_message = [
        "A virtual machine is considered underutilized if its CPU usage (",
        param_stats_threshold.toLowerCase(), ") is below ",
        param_stats_underutil_threshold_cpu_value,
        "% but its CPU usage is still above or equal to ",
        param_stats_idle_threshold_cpu_value, "%. "
      ].join('')

      idle_analysis_message = [
        "A virtual machine is considered idle if its CPU usage (",
        param_stats_threshold.toLowerCase(), ") is below ",
        param_stats_idle_threshold_cpu_value, "%. "
      ].join('')

      lookback_message = [
        "CPU usage was analyzed over the last ",
        param_stats_lookback.toString() + " days. ",
        "CPU metrics were gathered at a granularity of '",
        ds_stats_interval['pretty'], "'.\n\n"
      ].join('')
    }

    if (!checking_cpu && checking_mem) {
      underutil_analysis_message = [
        "A virtual machine is considered underutilized if its memory usage (",
        param_stats_threshold.toLowerCase(), ") is below ",
        param_stats_underutil_threshold_mem_value,
        "% but its memory usage is still above or equal to ",
        param_stats_idle_threshold_mem_value, "%. "
      ].join('')

      idle_analysis_message = [
        "A virtual machine is considered idle if its memory usage (",
        param_stats_threshold.toLowerCase(), ") is below ",
        param_stats_idle_threshold_mem_value, "%. "
      ].join('')

      lookback_message = [
        "Memory usage was analyzed over the last ",
        param_stats_lookback.toString() + " days. ",
        "Memory metrics were gathered at a granularity of '",
        ds_stats_interval['pretty'], "'.\n\n"
      ].join('')
    }

    disclaimer = "The above settings can be modified by editing the applied policy and changing the appropriate parameters."

    if (param_exclude_databricks == "No") {
      disclaimer += "\n\nNote: Recommendations for Azure Databricks VMs may be invalid because not all instance sizes are available for Databricks. Please set the \"Exclude Databricks\" to \"Yes\" to exclude these VMs if desired."
    }

    underutil_message = underutil_findings + underutil_analysis_message + lookback_message + disclaimer
    idle_message = idle_findings + idle_analysis_message + lookback_message + disclaimer
  } else {
    underutil_message = "No results were found because all CPU and memory parameters were set to -1 when this policy was applied. Please terminate and reapply this policy with one of these settings enabled."
    idle_message = underutil_message
  }

  // Sort by descending order of savings value
  idle_list = _.sortBy(idle_list, function(item) { return item['savings'] * -1 })
  underutil_list = _.sortBy(underutil_list, function(item) { return item['savings'] * -1 })

  // Add these to both lists to ensure the first item that fails validation for each
  // contains the necessary data for the summary and detail templates
  if (idle_list.length > 0) {
    idle_list[0]['idle_message'] = idle_message
    idle_list[0]['idle_total_savings'] = idle_total_savings
    idle_list[0]['policy_name'] = ds_applied_policy['name']
  }

  if (underutil_list.length > 0) {
    underutil_list[0]['underutil_message'] = underutil_message
    underutil_list[0]['underutil_total_savings'] = underutil_total_savings
    underutil_list[0]['policy_name'] = ds_applied_policy['name']
  }

  result = {
    idle_list: idle_list,
    underutil_list: underutil_list
  }
EOS
end

datasource "ds_underutilized_instances" do
  run_script $js_underutilized_instances, $ds_idle_and_underutil_instances
end

script "js_underutilized_instances", type: "javascript" do
  parameters "ds_idle_and_underutil_instances"
  result "result"
  code <<-EOS
  result = [{
    "resourceID": "",
    "recommendationType": "",
    "underutil_message": "",
    "idle_message": "",
    "underutil_total_savings": "",
    "idle_total_savings": "",
    "tags": "",
    "savings": "",
    "savingsCurrency": "",
    "cpu_maximum": "",
    "cpu_minimum": "",
    "cpu_average": "",
    "mem_maximum": "",
    "mem_minimum": "",
    "mem_average": ""
  }]

  result = ds_idle_and_underutil_instances["underutil_list"].concat(result)
EOS
end

datasource "ds_idle_instances" do
  run_script $js_idle_instances, $ds_idle_and_underutil_instances
end

script "js_idle_instances", type: "javascript" do
  parameters "ds_idle_and_underutil_instances"
  result "result"
  code <<-EOS
  result = [{
    "resourceID": "",
    "recommendationType": "",
    "underutil_message": "",
    "idle_message": "",
    "underutil_total_savings": "",
    "idle_total_savings": "",
    "tags": "",
    "savings": "",
    "savingsCurrency": "",
    "cpu_maximum": "",
    "cpu_minimum": "",
    "cpu_average": "",
    "mem_maximum": "",
    "mem_minimum": "",
    "mem_average": ""
  }]

  result = ds_idle_and_underutil_instances["idle_list"].concat(result)
EOS
end

###############################################################################
# Policy
###############################################################################

policy "pol_utilization" do
  validate_each $ds_underutilized_instances do
    summary_template "{{ with index data 0 }}{{ .policy_name }}{{ end }}: {{ len data }} Azure Underutilized Virtual Machines Found"
    detail_template <<-'EOS'
    **Potential Monthly Savings:** {{ with index data 0 }}{{ .underutil_total_savings }}{{ end }}

    {{ with index data 0 }}{{ .underutil_message }}{{ end }}
    EOS
    # Policy check fails and incident is created only if data is not empty and the Parent Policy has not been terminated
    check logic_or($ds_parent_policy_terminated, eq(val(item, "resourceID"), ""))
    escalate $esc_email
    escalate $esc_downsize_instances
    hash_exclude "underutil_message", "idle_message", "underutil_total_savings", "idle_total_savings", "tags", "savings", "savingsCurrency", "cpu_maximum", "cpu_minimum", "cpu_average", "mem_maximum", "mem_minimum", "mem_average"
    export do
      resource_level true
      field "accountID" do
        label "Subscription ID"
      end
      field "accountName" do
        label "Subscription Name"
      end
      field "resourceGroup" do
        label "Resource Group"
      end
      field "resourceName" do
        label "Resource Name"
      end
      field "resourceID" do
        label "Resource ID"
      end
      field "tags" do
        label "Resource Tags"
      end
      field "recommendationDetails" do
        label "Recommendation"
      end
      field "resourceType" do
        label "Instance Size"
      end
      field "newResourceType" do
        label "Recommended Instance Size"
      end
      field "resourceKind" do
        label "Resource Kind"
      end
      field "region" do
        label "Region"
      end
      field "osType" do
        label "Operating System"
      end
      field "dataDiskCount" do
        label "Attached Disks (#)"
      end
      field "imagePublisher" do
        label "Image Publisher"
      end
      field "imageOffer" do
        label "Image Offer"
      end
      field "imageSKU" do
        label "Image SKU"
      end
      field "state" do
        label "Power State"
      end
      field "savings" do
        label "Estimated Monthly Savings"
      end
      field "savingsCurrency" do
        label "Savings Currency"
      end
      field "cpuMaximum" do
        label "CPU Maximum %"
        path "cpu_maximum"
      end
      field "cpuMinimum" do
        label "CPU Minimum %"
        path "cpu_minimum"
      end
      field "cpuAverage" do
        label "CPU Average %"
        path "cpu_average"
      end
      field "cpuP90" do
        label "CPU p90"
        path "cpu_p90"
      end
      field "cpuP95" do
        label "CPU p95"
        path "cpu_p95"
      end
      field "cpuP99" do
        label "CPU p99"
        path "cpu_p99"
      end
      field "memMaximum" do
        label "Memory Maximum %"
        path "mem_maximum"
      end
      field "memMinimum" do
        label "Memory Minimum %"
        path "mem_minimum"
      end
      field "memAverage" do
        label "Memory Average %"
        path "mem_average"
      end
      field "memP90" do
        label "Memory p90"
        path "mem_p90"
      end
      field "memP95" do
        label "Memory p95"
        path "mem_p95"
      end
      field "memP99" do
        label "Memory p99"
        path "mem_p99"
      end
      field "thresholdType" do
        label "Threshold Statistic"
      end
      field "threshold" do
        label "CPU Threshold"
      end
      field "memoryThreshold" do
        label "Memory Threshold"
      end
      field "lookbackPeriod" do
        label "Look Back Period (Days)"
      end
      field "service" do
        label "Service"
      end
      field "id" do
        label "ID"
        path "resourceID"
      end
    end
  end
  validate_each $ds_idle_instances do
    summary_template "{{ with index data 0 }}{{ .policy_name }}{{ end }}: {{ len data }} Azure Idle Virtual Machines Found"
    detail_template <<-'EOS'
    **Potential Monthly Savings:** {{ with index data 0 }}{{ .idle_total_savings }}{{ end }}

    {{ with index data 0 }}{{ .idle_message }}{{ end }}
    EOS
    # Policy check fails and incident is created only if data is not empty and the Parent Policy has not been terminated
    check logic_or($ds_parent_policy_terminated, eq(val(item, "resourceID"), ""))
    escalate $esc_email
    escalate $esc_poweroff_instances
    escalate $esc_delete_instances
    hash_exclude "underutil_message", "idle_message", "underutil_total_savings", "idle_total_savings", "tags", "savings", "savingsCurrency", "cpu_maximum", "cpu_minimum", "cpu_average", "mem_maximum", "mem_minimum", "mem_average"
    export do
      resource_level true
      field "accountID" do
        label "Subscription ID"
      end
      field "accountName" do
        label "Subscription Name"
      end
      field "resourceGroup" do
        label "Resource Group"
      end
      field "resourceName" do
        label "Resource Name"
      end
      field "resourceID" do
        label "Resource ID"
      end
      field "tags" do
        label "Resource Tags"
      end
      field "recommendationDetails" do
        label "Recommendation"
      end
      field "resourceType" do
        label "Instance Size"
      end
      field "newResourceType" do
        label "Recommended Instance Size"
      end
      field "resourceKind" do
        label "Resource Kind"
      end
      field "region" do
        label "Region"
      end
      field "osType" do
        label "Operating System"
      end
      field "dataDiskCount" do
        label "Attached Disks (#)"
      end
      field "imagePublisher" do
        label "Image Publisher"
      end
      field "imageOffer" do
        label "Image Offer"
      end
      field "imageSKU" do
        label "Image SKU"
      end
      field "state" do
        label "Power State"
      end
      field "savings" do
        label "Estimated Monthly Savings"
      end
      field "savingsCurrency" do
        label "Savings Currency"
      end
      field "cpuMaximum" do
        label "CPU Maximum %"
        path "cpu_maximum"
      end
      field "cpuMinimum" do
        label "CPU Minimum %"
        path "cpu_minimum"
      end
      field "cpuAverage" do
        label "CPU Average %"
        path "cpu_average"
      end
      field "cpuP90" do
        label "CPU p90"
        path "cpu_p90"
      end
      field "cpuP95" do
        label "CPU p95"
        path "cpu_p95"
      end
      field "cpuP99" do
        label "CPU p99"
        path "cpu_p99"
      end
      field "memMaximum" do
        label "Memory Maximum %"
        path "mem_maximum"
      end
      field "memMinimum" do
        label "Memory Minimum %"
        path "mem_minimum"
      end
      field "memAverage" do
        label "Memory Average %"
        path "mem_average"
      end
      field "memP90" do
        label "Memory p90"
        path "mem_p90"
      end
      field "memP95" do
        label "Memory p95"
        path "mem_p95"
      end
      field "memP99" do
        label "Memory p99"
        path "mem_p99"
      end
      field "thresholdType" do
        label "Threshold Statistic"
      end
      field "threshold" do
        label "CPU Threshold"
      end
      field "memoryThreshold" do
        label "Memory Threshold"
      end
      field "lookbackPeriod" do
        label "Look Back Period (Days)"
      end
      field "service" do
        label "Service"
      end
      field "id" do
        label "ID"
        path "resourceID"
      end
    end
  end
end

###############################################################################
# Escalations
###############################################################################

escalation "esc_email" do
  automatic true
  label "Send Email"
  description "Send incident email"
  email $param_email
end

escalation "esc_downsize_instances" do
  automatic contains($param_automatic_action, "Downsize Underutilized Instances")
  label "Downsize Underutilized Instances"
  description "Approval to downsize all selected instances"
  run "downsize_instances", data, $param_azure_endpoint
end

escalation "esc_poweroff_instances" do
  automatic contains($param_automatic_action, "Power Off Idle Instances")
  label "Power Off Idle Instances"
  description "Approval to power off all selected instances"
  run "poweroff_instances", data, $param_azure_endpoint, $param_skipshutdown
end

escalation "esc_delete_instances" do
  automatic contains($param_automatic_action, "Delete Idle Instances")
  label "Delete Idle Instances"
  description "Approval to delete all selected instances"
  run "delete_instances", data, $param_azure_endpoint
end

###############################################################################
# Cloud Workflow
###############################################################################

define downsize_instances($data, $param_azure_endpoint) return $all_responses do
  $$all_responses = []

  foreach $instance in $data do
    sub on_error: handle_error() do
      if $instance["newResourceType"] != "Delete Virtual Machine"
        call downsize_instance($instance, $param_azure_endpoint) retrieve $downsize_response
      end
    end
  end

  if inspect($$errors) != "null"
    raise join($$errors, "\n")
  end
end

define downsize_instance($instance, $param_azure_endpoint) return $response do
  $host = $param_azure_endpoint
  $href = $instance["id"]
  $params = "?api-version=2023-07-01"
  $url = $host + $href + $params
  task_label("PATCH " + $url)

  $response = http_request(
    auth: $$auth_azure,
    https: true,
    verb: "patch",
    host: $host,
    href: $href,
    query_strings: { "api-version": "2023-07-01" },
    body: {
      "properties":{
        "hardwareProfile": {
          "vmSize": $instance["newResourceType"]
        }
      }
    }
  )

  task_label("Patch Azure VM instance response: " + $instance["id"] + " " + to_json($response))
  $$all_responses << to_json({"req": "DELETE " + $url, "resp": $response})

  if $response["code"] != 204 && $response["code"] != 202 && $response["code"] != 200
    raise "Unexpected response patching Azure VM instance: "+ $instance["id"] + " " + to_json($response)
  else
    task_label("Patch Azure VM instance successful: " + $instance["id"])
  end
end

define poweroff_instances($data, $param_azure_endpoint, $param_skipshutdown) return $all_responses do
  $$all_responses = []

  foreach $instance in $data do
    sub on_error: handle_error() do
      call poweroff_instance($instance, $param_azure_endpoint, $param_skipshutdown) retrieve $poweroff_response
    end
  end

  if inspect($$errors) != "null"
    raise join($$errors, "\n")
  end
end

define poweroff_instance($instance, $param_azure_endpoint, $param_skipshutdown) return $response do
  $host = $param_azure_endpoint
  $href = $instance["id"] + "/powerOff"
  $params = "?api-version=2023-07-01"
  $url = $host + $href + $params
  task_label("POST " + $url)

  $query_strings = { "api-version": "2023-07-01" }

  if $param_skipshutdown == "Forced"
    $query_strings["skipShutdown"] = "true"
    $params = $params + "&skipShutdown=true"
  end

  $response = http_request(
    auth: $$auth_azure,
    https: true,
    verb: "post",
    host: $host,
    href: $href,
    query_strings: $query_strings
  )

  task_label("Power off Azure VM instance response: " + $instance["id"] + " " + to_json($response))
  $$all_responses << to_json({"req": "POST " + $url, "resp": $response})

  if $response["code"] != 204 && $response["code"] != 202 && $response["code"] != 200
    raise "Unexpected response powering off Azure VM instance: "+ $instance["id"] + " " + to_json($response)
  else
    task_label("Power off Azure VM instance successful: " + $instance["id"])
  end
end

define delete_instances($data, $param_azure_endpoint) return $all_responses do
  $$all_responses = []

  foreach $instance in $data do
    sub on_error: handle_error() do
      call delete_instance($instance, $param_azure_endpoint) retrieve $delete_response
    end
  end

  if inspect($$errors) != "null"
    raise join($$errors, "\n")
  end
end

define delete_instance($instance, $param_azure_endpoint) return $response do
  $host = $param_azure_endpoint
  $href = $instance["id"]
  $params = "?api-version=2023-07-01"
  $url = $host + $href + $params
  task_label("DELETE " + $url)

  $response = http_request(
    auth: $$auth_azure,
    https: true,
    verb: "delete",
    host: $host,
    href: $href,
    query_strings: { "api-version": "2023-07-01" }
  )

  task_label("Delete Azure VM instance response: " + $instance["id"] + " " + to_json($response))
  $$all_responses << to_json({"req": "DELETE " + $url, "resp": $response})

  if $response["code"] != 204 && $response["code"] != 202 && $response["code"] != 200
    raise "Unexpected response deleting Azure VM instance: "+ $instance["id"] + " " + to_json($response)
  else
    task_label("Delete Azure VM instance successful: " + $instance["id"])
  end
end

define handle_error() do
  if !$$errors
    $$errors = []
  end
  $$errors << $_error["type"] + ": " + $_error["message"]
  # We check for errors at the end, and raise them all together
  # Skip errors handled by this definition
  $_error_behavior = "skip"
end

###############################################################################
# Meta Policy [alpha]
# Not intended to be modified or used by policy developers
###############################################################################

# If the meta_parent_policy_id is not set it will evaluate to an empty string and we will look for the policy itself,
# if it is set we will look for the parent policy.
datasource "ds_get_policy" do
  request do
    auth $auth_flexera
    host rs_governance_host
    ignore_status [404]
    path join(["/api/governance/projects/", rs_project_id, "/applied_policies/", switch(ne(meta_parent_policy_id, ""), meta_parent_policy_id, policy_id)])
    header "Api-Version", "1.0"
  end
  result do
    encoding "json"
    field "id", jmes_path(response, "id")
  end
end

datasource "ds_parent_policy_terminated" do
  run_script $js_decide_if_self_terminate, $ds_get_policy, policy_id, meta_parent_policy_id
end

# If the policy was applied by a meta_parent_policy we confirm it exists if it doesn't we confirm we are deleting
# This information is used in two places:
# - determining whether or not we make a delete call
# - determining if we should create an incident (we don't want to create an incident on the run where we terminate)
script "js_decide_if_self_terminate", type: "javascript" do
  parameters "found", "self_policy_id", "meta_parent_policy_id"
  result "result"
  code <<-EOS
  var result
  if (meta_parent_policy_id != "" && found.id == undefined) {
    result = true
  } else {
    result = false
  }
  EOS
end

# Two potentials ways to set this up:
# - this way and make a unneeded 'get' request when not deleting
# - make the delete request an interate and have it iterate over an empty array when not deleting and an array with one item when deleting
script "js_make_terminate_request", type: "javascript" do
  parameters "should_delete", "policy_id", "rs_project_id", "rs_governance_host"
  result "request"
  code <<-EOS

  var request = {
    auth:  'auth_flexera',
    host: rs_governance_host,
    path: "/api/governance/projects/" + rs_project_id + "/applied_policies/" + policy_id,
    headers: {
      "API-Version": "1.0",
      "Content-Type":"application/json"
    },
  }

  if (should_delete) {
    request.verb = 'DELETE'
  }
  EOS
end

datasource "ds_terminate_self" do
  request do
    run_script $js_make_terminate_request, $ds_parent_policy_terminated, policy_id, rs_project_id, rs_governance_host
  end
end

datasource "ds_is_deleted" do
  run_script $js_check_deleted, $ds_terminate_self
end

# This is just a way to have the check delete request connect to the farthest leaf from policy.
# We want the delete check to the first thing the policy does to avoid the policy erroring before it can decide whether or not it needs to self terminate
# Example a customer deletes a credential and then terminates the parent policy. We still want the children to self terminate
# The only way I could see this not happening is if the user who applied the parent_meta_policy was offboarded or lost policy access, the policies who are impersonating the user
# would not have access to self-terminate
# It may be useful for the backend to enable a mass terminate at some point for all meta_child_policies associated with an id.
script "js_check_deleted", type: "javascript" do
  parameters "response"
  result "result"
  code <<-EOS
  result = {"path":"/"}
  EOS
end
