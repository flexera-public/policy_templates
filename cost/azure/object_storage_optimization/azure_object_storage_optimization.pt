name "Azure Blob Storage Optimization"
rs_pt_ver 20180301
type "policy"
short_description "Checks Azure Blob Storage for old blobs and moves said blobs to the Cool or Archive tier after user approval. See the [README](https://github.com/flexera-public/policy_templates/tree/master/cost/azure/blob_storage_optimization) and [docs.flexera.com/flexera/EN/Automation](https://docs.flexera.com/flexera/EN/Automation/AutomationGS.htm) to learn more."
long_description ""
severity "low"
category "Cost"
default_frequency "weekly"
info(
  version: "3.0",
  provider: "Azure",
  service: "Storage",
  policy_set: "Object Store Optimization"
)

###############################################################################
# Parameters
###############################################################################

parameter "param_email" do
  type "list"
  category "Policy Settings"
  label "Email Addresses"
  description "A list of email addresses to notify."
  default []
end

parameter "param_azure_endpoint" do
  type "string"
  category "Policy Settings"
  label "Azure Endpoint"
  description "Select the API endpoint to use for Azure. Use default value of management.azure.com unless using Azure China."
  allowed_values "management.azure.com", "management.chinacloudapi.cn"
  default "management.azure.com"
end

parameter "param_storage_account_list" do
  type "list"
  category "Filters"
  label "Storage Account List"
  description "A list of Azure Storage Accounts to assess blobs in. Leave blank to assess all accounts."
  default []
end

parameter "param_subscriptions_allow_or_deny" do
  type "string"
  category "Filters"
  label "Allow/Deny Subscriptions"
  description "Allow or Deny entered Subscriptions. See the README for more details."
  allowed_values "Allow", "Deny"
  default "Allow"
end

parameter "param_subscriptions_list" do
  type "list"
  category "Filters"
  label "Allow/Deny Subscriptions List"
  description "A list of allowed or denied Subscription IDs/names. See the README for more details."
  default []
end

parameter "param_regions_allow_or_deny" do
  type "string"
  category "Filters"
  label "Allow/Deny Regions"
  description "Allow or Deny entered regions. See the README for more details."
  allowed_values "Allow", "Deny"
  default "Allow"
end

parameter "param_regions_list" do
  type "list"
  category "Filters"
  label "Allow/Deny Regions List"
  description "A list of allowed or denied regions. See the README for more details."
  default []
end

parameter "param_exclusion_tags" do
  type "list"
  category "Filters"
  label "Exclusion Tags (Key:Value)"
  description "Cloud native tags to ignore storage accounts that you don't want to produce recommendations for. Use Key:Value format for specific tag key/value pairs, and Key:* format to match any resource with a particular key, regardless of value. Examples: env:production, DO_NOT_DELETE:*"
  allowed_pattern /(^$)|[\w]*\:.*/
  default []
end

parameter "param_new_storage_tier" do
  type "string"
  category "Actions"
  label "New Storage Tier"
  description "Whether to move blobs to Cool or Archive if they meet the specified age thresholds. Select 'Both' to consider moving blobs to either one based on the specified age thresholds"
  default "Both"
  allowed_values "Both", "Cool", "Archive"
end

parameter "param_cool_tier_days" do
  type "number"
  category "Actions"
  label "Cool Tier Age Threshold (Days)"
  description "Time in days since blob was last modified to change storage tier to Cool. Not applicable if 'Archive' is selected for New Storage Tier"
  default 30
  min_value 1
end

parameter "param_archive_tier_days" do
  type "number"
  category "Actions"
  label "Archive Tier Age Threshold (Days)"
  description "Time in days since blob was last modified to change storage tier to Archive. Not applicable if 'Cool' is selected for New Storage Tier"
  default 90
  min_value 1
end

parameter "param_automatic_action" do
  type "list"
  category "Actions"
  label "Automatic Actions"
  description "When this value is set, this policy will automatically take the selected action."
  allowed_values ["Update Blob Storage Tier"]
  default []
end

###############################################################################
# Authentication
###############################################################################

credentials "auth_azure" do
  schemes "oauth2"
  label "Azure"
  description "Select the Azure Resource Manager Credential from the list."
  tags "provider=azure_rm"
end

credentials "auth_flexera" do
  schemes "oauth2"
  label "Flexera"
  description "Select Flexera One OAuth2 credentials"
  tags "provider=flexera"
end

###############################################################################
# Pagination
###############################################################################

pagination "pagination_azure" do
  get_page_marker do
    body_path "nextLink"
  end
  set_page_marker do
    uri true
  end
end

pagination "pagination_azure_xml" do
  get_page_marker do
    body_path "//EnumerationResults/NextMarker"
  end
  set_page_marker do
    query "marker"
  end
end

###############################################################################
# Datasources & Scripts
###############################################################################

# Get applied policy metadata for use later
datasource "ds_applied_policy" do
  request do
    auth $auth_flexera
    host rs_governance_host
    path join(["/api/governance/projects/", rs_project_id, "/applied_policies/", policy_id])
    header "Api-Version", "1.0"
  end
end

datasource "ds_azure_subscriptions" do
  request do
    auth $auth_azure
    pagination $pagination_azure
    host $param_azure_endpoint
    path "/subscriptions/"
    query "api-version","2020-01-01"
    header "User-Agent", "RS Policies"
    # Header X-Meta-Flexera has no affect on datasource query, but is required for Meta Policies
    # Forces `ds_is_deleted` datasource to run first during policy execution
    header "Meta-Flexera", val($ds_is_deleted, "path")
  end
  result do
    encoding "json"
    collect jmes_path(response, "value[*]") do
      field "id", jmes_path(col_item, "subscriptionId")
      field "name", jmes_path(col_item, "displayName")
      field "state", jmes_path(col_item, "state")
    end
  end
end

datasource "ds_azure_subscriptions_filtered" do
  run_script $js_azure_subscriptions_filtered, $ds_azure_subscriptions, $param_subscriptions_allow_or_deny, $param_subscriptions_list
end

script "js_azure_subscriptions_filtered", type: "javascript" do
  parameters "ds_azure_subscriptions", "param_subscriptions_allow_or_deny", "param_subscriptions_list"
  result "result"
  code <<-EOS
  if (param_subscriptions_list.length > 0) {
    result = _.filter(ds_azure_subscriptions, function(subscription) {
      include_subscription = _.contains(param_subscriptions_list, subscription['id']) || _.contains(param_subscriptions_list, subscription['name'])

      if (param_subscriptions_allow_or_deny == "Deny") {
        include_subscription = !include_subscription
      }

      return include_subscription
    })
  } else {
    result = ds_azure_subscriptions
  }
EOS
end

datasource "ds_azure_storage_accounts" do
  iterate $ds_azure_subscriptions_filtered
  request do
    auth $auth_azure
    pagination $pagination_azure
    host $param_azure_endpoint
    path join(["/subscriptions/", val(iter_item, 'id'), "/providers/Microsoft.Storage/storageAccounts"])
    header "User-Agent", "RS Policies"
    query "api-version", "2023-01-01"
  end
  result do
    encoding "json"
    collect jmes_path(response, "value[*]") do
      field "id", jmes_path(col_item, "id")
      field "kind", jmes_path(col_item, "kind")
      field "region", jmes_path(col_item, "location")
      field "name", jmes_path(col_item, "name")
      field "tags", jmes_path(col_item, "tags")
      field "blob_endpoint", jmes_path(col_item, "properties.primaryEndpoints.blob")
      field "subscriptionID", val(iter_item, "id")
      field "subscriptionName", val(iter_item, "name")
    end
  end
end

datasource "ds_azure_storage_accounts_tag_filtered" do
  run_script $js_azure_storage_accounts_tag_filtered, $ds_azure_storage_accounts, $param_exclusion_tags
end

script "js_azure_storage_accounts_tag_filtered", type: "javascript" do
  parameters "ds_azure_storage_accounts", "param_exclusion_tags"
  result "result"
  code <<-EOS
  if (param_exclusion_tags.length > 0) {
    result = _.reject(ds_azure_storage_accounts, function(account) {
      tags = []

      if (typeof(account['tags']) == 'object') {
        _.each(Object.keys(account['tags']), function(key) {
          tags.push([key, ":", account['tags'][key]].join(''))
          tags.push([key, ":*"].join(''))
        })
      }

      exclude_account = false

      _.each(param_exclusion_tags, function(exclusion_tag) {
        if (_.contains(tags, exclusion_tag)) {
          exclude_account = true
        }
      })

      return exclude_account
    })
  } else {
    result = ds_azure_storage_accounts
  }
EOS
end

datasource "ds_azure_storage_accounts_region_filtered" do
  run_script $js_azure_storage_accounts_region_filtered, $ds_azure_storage_accounts_tag_filtered, $param_regions_allow_or_deny, $param_regions_list
end

script "js_azure_storage_accounts_region_filtered", type: "javascript" do
  parameters "ds_azure_storage_accounts_tag_filtered", "param_regions_allow_or_deny", "param_regions_list"
  result "result"
  code <<-EOS
  if (param_regions_list.length > 0) {
    result = _.filter(ds_azure_storage_accounts_tag_filtered, function(account) {
      include_account = _.contains(param_regions_list, account['region'])

      if (param_regions_allow_or_deny == "Deny") {
        include_account = !include_account
      }

      return include_account && typeof(account['blob_endpoint']) == 'string' && account['blob_endpoint'] != ''
    })
  } else {
    result = _.filter(ds_azure_storage_accounts_tag_filtered, function(account) {
      return typeof(account['blob_endpoint']) == 'string' && account['blob_endpoint'] != ''
    })
  }
EOS
end

datasource "ds_azure_storage_accounts_name_filtered" do
  run_script $js_azure_storage_accounts_name_filtered, $ds_azure_storage_accounts_region_filtered, $param_storage_account_list
end

script "js_azure_storage_accounts_name_filtered", type: "javascript" do
  parameters "ds_azure_storage_accounts_region_filtered", "param_storage_account_list"
  result "result"
  code <<-EOS
  if (param_storage_account_list.length > 0) {
    result = _.filter(ds_azure_storage_accounts_region_filtered, function(account) {
      return _.contains(param_storage_account_list, account['name'])
    })
  } else {
    result = ds_azure_storage_accounts_region_filtered
  }
EOS
end

datasource "ds_azure_containers" do
  iterate $ds_azure_storage_accounts_name_filtered
  request do
    auth $auth_azure
    pagination $pagination_azure_xml
    host join([val(iter_item, 'name'), ".blob.core.windows.net"])
    path "/"
    query "comp", "list"
    header "User-Agent", "RS Policies"
    header "x-ms-version", "2018-11-09"
  end
  result do
    encoding "xml"
    collect xpath(response, "//EnumerationResults/Containers/Container", "array") do
      field "container", xpath(col_item, "Name")
      field "region", val(iter_item, "region")
      field "subscriptionID", val(iter_item, "subscriptionID")
      field "subscriptionName", val(iter_item, "subscriptionName")
      field "sa_id", val(iter_item, "id")
      field "sa_kind", val(iter_item, "kind")
      field "sa_name", val(iter_item, "name")
      field "sa_tags", val(iter_item, "tags")
    end
  end
end

datasource "ds_azure_blobs" do
  iterate $ds_azure_containers
  request do
    auth $auth_azure
    pagination $pagination_azure_xml
    host join([val(iter_item, 'sa_name'), ".blob.core.windows.net"])
    path join(["/", val(iter_item, "container")])
    query "restype", "container"
    query "comp", "list"
    header "User-Agent", "RS Policies"
    header "x-ms-version", "2018-03-28"
  end
  result do
    encoding "xml"
    collect xpath(response, "//EnumerationResults/Blobs/Blob", "array") do
      field "name", xpath(col_item, "Name")
      field "last_modified", xpath(col_item, "Properties/Last-Modified")
      field "creation_time", xpath(col_item, "Properties/Creation-Time")
      field "content_type", xpath(col_item, "Properties/Content-Type")
      field "lease_state", xpath(col_item, "Properties/LeaseState")
      field "access_tier", xpath(col_item, "Properties/AccessTier")
      field "blob_type", xpath(col_item, "Properties/BlobType")
      field "container", xpath(col_item, "Name")
      field "region", val(iter_item, "region")
      field "subscriptionID", val(iter_item, "subscriptionID")
      field "subscriptionName", val(iter_item, "subscriptionName")
      field "sa_id", val(iter_item, "id")
      field "sa_kind", val(iter_item, "kind")
      field "sa_name", val(iter_item, "name")
      field "sa_tags", val(iter_item, "tags")
    end
  end
end

datasource "ds_azure_blobs_with_tier" do
  run_script $js_azure_blobs_with_tier, $ds_azure_blobs, $param_cool_tier_days, $param_archive_tier_days, $param_new_storage_tier
end

script "js_azure_blobs_with_tier", type: "javascript" do
  parameters "ds_azure_blobs", "param_cool_tier_days", "param_archive_tier_days", "param_new_storage_tier"
  result "result"
  code <<-EOS
  result = _.map(ds_azure_blobs, function(blob) {
    sa_tags = []

    if (typeof(blob['sa_tags']) == 'blob') {
      _.each(Object.keys(blob['sa_tags']), function(key) {
        sa_tags.push([key, "=", blob['sa_tags'][key]].join(''))
      })
    }

    last_modified_date = new Date(blob['last_modified'])
    creation_time_date = new Date(blob['creation_time'])
    cool_date = new Date(new Date() - (1000 * 60 * 60 * 24 * param_cool_tier_days))
    archive_date = new Date(new Date() - (1000 * 60 * 60 * 24 * param_archive_tier_days))
    new_storage_tier = null

    if (blob['access_tier'] != "Cool" && blob['access_tier'] != "Archive") {
      if (last_modified_date <= cool_date && param_new_storage_class != 'Archive') {
        new_storage_tier = "Cool"
      }

      if (last_modified_date <= archive_date && param_new_storage_class != 'Cool') {
        new_storage_tier = "Archive"
      }
    }

    return {
      name: blob['name'],
      content_type: blob['content_type'],
      lease_state: blob['lease_state'],
      access_tier: blob['access_tier'],
      blob_type: blob['blob_type'],
      container: blob['container'],
      region: blob['region'],
      subscriptionID: blob['subscriptionID'],
      subscriptionName: blob['subscriptionName'],
      sa_id: blob['sa_id'],
      sa_kind: blob['sa_kind'],
      sa_name: blob['sa_name'],
      sa_tags: sa_tags.join(', '),
      creation_time: creation_time_date.toISOString(),
      last_modified: last_modified_date.toISOString(),
      new_storage_tier: new_storage_tier
    }
  })
EOS
end


datasource "ds_azure_blobs_incident" do
  run_script $js_azure_blobs_incident, $ds_azure_blobs_with_tier, $ds_applied_policy, $param_cool_tier_days, $param_archive_tier_days, $param_new_storage_tier
end

script "js_aws_s3_blobs_incident", type: "javascript" do
  parameters "ds_azure_blobs_with_tier", "ds_applied_policy", "param_cool_tier_days", "param_archive_tier_days", "param_new_storage_tier"
  result "result"
  code <<-'EOS'
  blobs_to_change = _.reject(ds_azure_blobs_with_tier, function(blob) {
    return blob['new_storage_tier'] == null
  })

  result = _.map(blobs_to_change, function(blob) {
    recommendationDetails = [
      "Change storage class of Azure Blob ", blob['name'],
      " in Container ", blob['container'],
      " in Storage Account ", blob['sa_name'],
      " in Azure Subscription ", blob['subscriptionName'], " (", blob['subscriptionID'], ")",
      " from ", blob['access_tier'], " to ", blob['new_storage_tier']
    ].join('')

    return {
      accountID: blob['subscriptionID'],
      accountName: blob['subscriptionName'],
      resourceID: blob['name'],
      resourceType: blob['access_tier'],
      newResourceType: blob['new_storage_tier'],
      content_type: blob['content_type'],
      lease_state: blob['lease_state'],
      blob_type: blob['blob_type'],
      container: blob['container'],
      region: blob['region'],
      sa_id: blob['sa_id'],
      sa_kind: blob['sa_kind'],
      sa_name: blob['sa_name'],
      tags: blob['sa_tags'],
      creation_time: blob['creation_time'],
      last_modified: blob['last_modified'],
      policy_name: ds_applied_policy['name'],
      recommendationDetails: recommendationDetails,
      service: "Microsoft.Storage",
      message: ''
    }
  })

  blobs_total = ds_azure_blobs_with_tier.length.toString()
  blobs_to_change_total = result.length.toString()
  blobs_to_change_percentage = (blobs_to_change_total / blobs_total * 100).toFixed(2).toString() + '%'

  blob_noun = "blobs"
  if (blobs_total == 1) { blob_noun = "blob" }

  blob_verb = "are"
  if (blobs_to_change_total == 1) { blob_verb = "is" }

  findings = [
    "Out of ", blobs_total, " Azure ", blob_noun, " analyzed, ",
    blobs_to_change_total, " (", blobs_to_change_percentage,
    ") ", blob_verb, " recommended for a change in storage tier. "
  ].join('')

  analysis = ''

  if (param_new_storage_class != 'Archive') {
    cool_day_noun = "days ago"
    if (param_cool_tier_days == 1) { cool_day_noun = "day ago" }

    analysis += [
      "An Azure Blob is recommended for a change to the Cool storage class ",
      "if it was last modified at least ", param_cool_days, " ", cool_day_noun, ". "
    ].join('')
  }

  if (param_new_storage_class != 'Cool') {
    archive_day_noun = "days ago"
    if (param_archive_tier_days == 1) { archive_day_noun = "day ago" }

    analysis += [
      "An Azure Blob is recommended for a change to the Archive storage class ",
      "if it was last modified at least ", param_deep_archive_days, " ", archive_day_noun, "."
    ].join('')
  }

  analysis += "\n\n"

  disclaimer = "The above settings can be modified by editing the applied policy and changing the appropriate parameters."

  // Dummy entry to ensure validation runs at least once
  result.push({ resourceID: "", policy_name: "", message: "", tags: "" })

  result[0]['message'] = findings + analysis + disclaimer
EOS
end


###############################################################################
# Policy
###############################################################################

policy "policy_azure_blobs_list" do
  validate $ds_azure_filtered_blobs do
    summary_template "{{ rs_project_name }} (Account ID: {{ rs_project_id }}): Azure Object Storage Optimization."
    escalate $modify_accesstier_approval
    escalate $report_blobs_list
    check eq(size(data),0)
    export do
      resource_level true
      field "id" do
        label "Blob Name"
        path "blobname"
      end
      field "containername" do
        label "Container Name"
      end
      field "accesstier" do
        label "Current Access Tier"
      end
      field "blobtype" do
        label "Blob Type"
      end
      field "lastmodified" do
        label "Last Modified Date"
      end
      field "modify_accesstier_to" do
        label "Move Access Tier To"
      end
      field "contenttype" do
        label "Content Type"
      end
    end
  end
end

###############################################################################
# Escalation
###############################################################################

escalation "report_blobs_list" do
  automatic true
  label "Send Email"
  description "Send incident email"
  email $param_email
end

escalation "modify_accesstier_approval" do
  automatic contains($param_automatic_action, "Update Blob Storage Tier")
  label "Update Blob Storage Tier"
  description "Update Storage tier on selected blog storage"
  run "update_accesstier_blobs", data, $param_azure_storage_account, rs_optima_host
end

###############################################################################
# Cloud Workflow
###############################################################################

define update_accesstier_blobs($data, $param_azure_storage_account, $$rs_optima_host) return $all_responses do
  $$debug=true
  $all_responses = []
  foreach $item in $data do
    sub on_error: skip do
      call url_encode($item['id']) retrieve $blob_name
      $response = http_request(
        verb: "put",
        host: $param_azure_storage_account,
        auth: $$auth_azure,
        https: true,
        href: join([".blob.core.windows.net/", $item['containername'], "/", $blob_name, "?comp=tier"]),
        headers: {
          "x-ms-version": "2019-02-02",
          "content-type": "application/json",
          "x-ms-access-tier": $item['modify_accesstier_to']
        }
      )
      $all_responses << $response
      call sys_log('Azure blob storage optimization ',to_s($response))
    end
  end
end

define sys_log($subject, $detail) do
  # Create empty errors array if doesn't already exist
  if !$$errors
    $$errors = []
  end
  # Check if debug is enabled
  if $$debug
    # Append to global $$errors
    # This is the suggested way to capture errors
    $$errors << "Unexpected error for " + $subject + "\n  " + to_s($detail)
    # If Flexera NAM Zone, create audit_entries [to be deprecated]
    # This is the legacy method for capturing errors and only supported on Flexera NAM
    if $$rs_optima_host == "api.optima.flexeraeng.com"
      # skip_error_and_append is used to catch error if rs_cm.audit_entries.create fails unexpectedly
      $task_label = "Creating audit entry for " + $subject
      sub task_label: $task, on_error: skip_error_and_append($task) do
        rs_cm.audit_entries.create(
          notify: "None",
          audit_entry: {
            auditee_href: @@account,
            summary: $subject,
            detail: $detail
          }
        )
      end # End sub on_error
    end # End if rs_optima_host
  end # End if debug is enabled
end

define skip_error_and_append($subject) do
  $$errors << "Unexpected error for " + $subject + "\n  " + to_s($_error)
  $_error_behavior = "skip"
end

define url_encode($string) return $encoded_string do
  $encoded_string = $string
  $encoded_string = gsub($encoded_string, " ", "%20")
  $encoded_string = gsub($encoded_string, "!", "%21")
  $encoded_string = gsub($encoded_string, "#", "%23")
  $encoded_string = gsub($encoded_string, "$", "%24")
  $encoded_string = gsub($encoded_string, "&", "%26")
  $encoded_string = gsub($encoded_string, "'", "%27")
  $encoded_string = gsub($encoded_string, "(", "%28")
  $encoded_string = gsub($encoded_string, ")", "%29")
  $encoded_string = gsub($encoded_string, "*", "%2A")
  $encoded_string = gsub($encoded_string, "+", "%2B")
  $encoded_string = gsub($encoded_string, ",", "%2C")
  $encoded_string = gsub($encoded_string, "/", "%2F")
  $encoded_string = gsub($encoded_string, ":", "%3A")
  $encoded_string = gsub($encoded_string, ";", "%3B")
  $encoded_string = gsub($encoded_string, "=", "%3D")
  $encoded_string = gsub($encoded_string, "?", "%3F")
  $encoded_string = gsub($encoded_string, "@", "%40")
  $encoded_string = gsub($encoded_string, "[", "%5B")
  $encoded_string = gsub($encoded_string, "]", "%5D")
end
