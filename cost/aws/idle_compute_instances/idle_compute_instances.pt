name "AWS Idle Compute Instances"
rs_pt_ver 20180301
type "policy"
short_description "**Deprecated: This policy is no longer being updated. Please see [README](https://github.com/flexera-public/policy_templates/tree/master/cost/aws/idle_compute_instances/) for more details.**  Check for instances that are idle for the last 30 days and terminates them after approval. See the [README](https://github.com/flexera-public/policy_templates/tree/master/cost/aws/idle_compute_instances/) and [docs.flexera.com/flexera/EN/Automation](https://docs.flexera.com/flexera/EN/Automation/AutomationGS.htm) to learn more."
long_description ""
severity "low"
category "Cost"
default_frequency "daily"
info(
  version: "5.6",
  provider: "AWS",
  service: "Compute",
  policy_set: "Idle Compute Instances",
  recommendation_type: "Usage Reduction"
)

###############################################################################
# Parameters
###############################################################################

parameter "param_aws_account_number" do
  type "string"
  category "Policy Settings"
  label "Account Number"
  description "Leave blank; this is for automated use with Meta Policies. See README for more details."
  default ""
end

parameter "param_email" do
  type "list"
  label "Email addresses to notify"
  description "Email addresses of the recipients you wish to notify when new incidents are created"
end

parameter "param_avg_cpu" do
  type "number"
  label "Used CPU Threshold"
  description "The threshold at which to consider an instance to be 'idle'. Set to -1 to ignore CPU utilization"
  default -1
  min_value -1
  max_value 100
end

parameter "param_avg_used_memory" do
  type "number"
  label "Used Memory Threshold"
  description "The threshold at which to consider an instance to be 'idle'. Set to -1 to ignore memory utilization"
  default -1
  min_value -1
  max_value 100
end

parameter "param_check_both" do
  type "string"
  label "Idle for both CPU/Memory or either"
  description "Whether an instance should be considered idle only if both CPU and memory are under the thresholds or if either CPU or memory are under."
  default "Either CPU or Memory"
  allowed_values "Both CPU and Memory", "Either CPU or Memory"
end

parameter "param_threshold_statistic" do
  type "string"
  label "Threshold Statistic"
  description "Statistic to use for the metric threshold"
  default "Average"
  allowed_values "Average", "p99", "p95", "p90"
end

parameter "param_allowed_regions_allow_or_deny" do
  type "string"
  label "Allow/Deny Regions"
  description "Allow or Deny entered regions. See the README for more details"
  allowed_values "Allow", "Deny"
  default "Allow"
end

parameter "param_allowed_regions" do
  type "list"
  label "Regions"
  allowed_pattern /^([a-zA-Z-_]+-[a-zA-Z0-9-_]+-[0-9-_]+,*|)+$/
  description "A list of allowed or denied regions. See the README for more details"
end

parameter "param_exclusion_tag_key" do
  category "User Inputs"
  label "Exclusion Tag Key:Value"
  description "Cloud native tag to ignore instances. Format: Key:Value"
  type "string"
  allowed_pattern /(^$)|([\w]?)+\:([\w]?)+/
  default ""
end

parameter "param_automatic_action" do
  type "list"
  label "Automatic Actions"
  description "When this value is set, this policy will automatically take the selected action(s)"
  allowed_values ["Terminate Instances"]
  default []
end

parameter "param_api_wait" do
  type "number"
  label "CloudWatch API Wait Time"
  description "Amount of time to wait between CloudWatch API requests to avoid throttling (seconds)"
  default 5
  min_value 1
  max_value 60
end

parameter "param_log_to_cm_audit_entries" do
  type "string"
  label "Log to CM Audit Entries"
  description "Boolean for whether or not to log any debugging information from actions to CM Audit Entries, this should be left set to No on Flexera EU"
  default "No"
  allowed_values "Yes", "No"
end

###############################################################################
# Authentication
###############################################################################

#authenticate with AWS
credentials "auth_aws" do
  schemes "aws","aws_sts"
  label "AWS"
  description "Select the AWS Credential from the list"
  tags "provider=aws"
  aws_account_number $param_aws_account_number
end

credentials "auth_flexera" do
  schemes "oauth2"
  label "flexera"
  description "Select Flexera One OAuth2 credentials"
  tags "provider=flexera"
end

###############################################################################
# Datasources
###############################################################################

datasource "ds_currency_reference" do
  request do
    host "raw.githubusercontent.com"
    path "/flexera-public/policy_templates/master/data/currency/currency_reference.json"
    header "User-Agent", "RS Policies"
  end
end

datasource "ds_currency_code" do
  request do
    auth $auth_flexera
    host rs_optima_host
    path join(["/bill-analysis/orgs/",rs_org_id,"/settings/currency_code"])
    header "Api-Version", "0.1"
    header "User-Agent", "RS Policies"
    ignore_status [403]
  end
  result do
    encoding "json"
    field "id", jmes_path(response,"id")
    field "value", jmes_path(response,"value")
  end
end

# Create a simple object containing the currency code and number separator for later usage
datasource "ds_currency" do
  run_script $js_currency, $ds_currency_reference, $ds_currency_code
end

# Get the AWS account number to filter requests to just the account being checked
datasource "ds_get_caller_identity" do
  request do
    auth $auth_aws
    verb "GET"
    host "sts.amazonaws.com"
    path "/"
    header "User-Agent", "RS Policies"
    query "Action", "GetCallerIdentity"
    query "Version", "2011-06-15"
  end
  result do
    encoding "xml"
    collect xpath(response, "//GetCallerIdentityResponse/GetCallerIdentityResult") do
      field "account", xpath(col_item, "Account")
    end
  end
end

datasource "ds_aws_account" do
  run_script $js_aws_account, $ds_get_caller_identity
end

# ds_region_list is a list of regions that are opted-in or opt-in-not-required
datasource "ds_regions_list" do
  # https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeRegions.html
  request do
    auth $auth_aws
    verb "GET"
    host "ec2.amazonaws.com"
    path "/"
    query "Action", "DescribeRegions"
    query "Version", "2016-11-15"
    query "Filter.1.Name", "opt-in-status"
    query "Filter.1.Value.1", "opt-in-not-required"
    query "Filter.1.Value.2", "opted-in"
    # Header X-Meta-Flexera has no affect on datasource query, but is required for Meta Policies
    # Forces `ds_is_deleted` datasource to run first during policy execution
    header "Meta-Flexera", val($ds_is_deleted, "path")
  end
  result do
    encoding "xml"
    collect xpath(response, "//DescribeRegionsResponse/regionInfo/item", "array") do
      field "region", xpath(col_item, "regionName")
    end
  end
end

# Filter the regions list by just the regions allowed by the parameter
datasource "ds_regions" do
  run_script $js_regions, $param_allowed_regions, $ds_regions_list, $param_allowed_regions_allow_or_deny
end

datasource "ds_instances_set" do
  iterate $ds_regions
  request do
    auth $auth_aws
    host join(['ec2.', val(iter_item, 'region'), '.amazonaws.com'])
    path '/'
    header 'User-Agent', 'RS Policies'
    header 'Content-Type', 'text/xml'
    query 'Action', 'DescribeInstances'
    query 'Version', '2016-11-15'
    query 'Filter.1.Name', 'instance-state-name'
    query 'Filter.1.Value.1', 'running'
  end
  result do
    encoding "xml"
    collect xpath(response, "//DescribeInstancesResponse/reservationSet/item", "array") do
      field "instances_set" do
        collect xpath(col_item,"instancesSet/item","array") do
          field "region",val(iter_item, "region")
          field "instanceId", xpath(col_item,"instanceId")
          field "imageId", xpath(col_item,"imageId")
          field "resourceType", xpath(col_item, "instanceType")
          field "platform", xpath(col_item, "platformDetails")
          field "privateDnsName", xpath(col_item, "privateDnsName")
          field "launchTime", xpath(col_item, "launchTime")
          field "tags" do
            collect xpath(col_item,"tagSet/item","array") do
              field "key", xpath(col_item, "key")
              field "value", xpath(col_item, "value")
            end
          end
        end
      end
    end
  end
end

# Filter the instances list by just the regions allowed by the parameter
datasource "ds_instances" do
  run_script $js_instances, $ds_instances_set, $param_exclusion_tag_key
end

# Build out a list of queries to send into Cloudwatch for the above instances
datasource "ds_instances_queries" do
  run_script $js_instances_queries, $ds_instances, $param_avg_cpu, $param_avg_used_memory
end

# Combine the above queries into discrete requests of 500 or fewer queries to
# send into the API
datasource "ds_instances_requests" do
  run_script $js_instances_requests, $ds_instances_queries
end

datasource "ds_cloudwatch_data" do
  iterate $ds_instances_requests
  request do
    run_script $js_cloudwatch_data, val(iter_item, "region"), val(iter_item, "body"), $param_api_wait
  end
  result do
    encoding "json"
    collect jmes_path(response, "MetricDataResults[*]") do
      field "region", val(iter_item, "region")
      field "id", jmes_path(col_item, "Id")
      field "label", jmes_path(col_item, "Label")
      field "values", jmes_path(col_item, "Values")
    end
  end
end

# Organize the CloudWatch data into a JavaScript object
datasource "ds_cloudwatch_data_sorted" do
  run_script $js_cloudwatch_data_sorted, $ds_cloudwatch_data
end

datasource "ds_billing_centers" do
  request do
    auth $auth_flexera
    host rs_optima_host
    path join(["/analytics/orgs/",rs_org_id,"/billing_centers"])
    header "Api-Version", "1.0"
    header "User-Agent", "RS Policies"
    query "view", "allocation_table"
    ignore_status [403]
  end
  result do
    encoding "json"
    collect jmes_path(response,"[*]") do
      field "href", jmes_path(col_item,"href")
      field "id", jmes_path(col_item,"id")
      field "name", jmes_path(col_item,"name")
      field "parent_id", jmes_path(col_item,"parent_id")
    end
  end
end

datasource "ds_top_level_billing_centers" do
  run_script $js_top_level_bc, $ds_billing_centers
end

# Build the request to send into the Optima API for cost data
datasource "ds_instances_costs_request" do
  run_script $js_instances_costs_request, $ds_aws_account, $ds_top_level_billing_centers
end

datasource "ds_instances_costs" do
  iterate $ds_instances_costs_request
  request do
    auth $auth_flexera
    host rs_optima_host
    verb "POST"
    path join(["/bill-analysis/orgs/", rs_org_id, "/costs/select"])
    header "Api-Version", "1.0"
    header "User-Agent", "RS Policies"
    ignore_status [400]
    body_field "dimensions", val(iter_item, "dimensions")
    body_field "granularity", val(iter_item, "granularity")
    body_field "start_at", val(iter_item, "start_at")
    body_field "end_at", val(iter_item, "end_at")
    body_field "metrics", val(iter_item, "metrics")
    body_field "billing_center_ids", val(iter_item, "billing_center_ids")
    body_field "limit", val(iter_item, "limit")
    body_field "filter", val(iter_item, "filter")
  end
  result do
    encoding "json"
    collect jmes_path(response,"rows[*]") do
      field "resource_id", jmes_path(col_item,"dimensions.resource_id")
      field "vendorAccountName", jmes_path(col_item, "dimensions.vendor_account_name")
      field "cost_nonamortized_unblended_adj", jmes_path(col_item,"metrics.cost_nonamortized_unblended_adj")
    end
  end
end

# Combine the list of instances with the CloudWatch data
datasource "ds_merged_metrics" do
  run_script $js_merged_metrics, $ds_cloudwatch_data_sorted, $ds_instances, $ds_aws_account, $ds_currency
end

# Create a final list of idle instances and incorporate cost data into it
datasource "ds_idle_instances" do
  run_script $js_idle_instances, $ds_merged_metrics, $ds_instances_costs, $param_avg_cpu, $param_avg_used_memory, $ds_currency, $param_check_both, $param_threshold_statistic
end

###############################################################################
# Scripts
###############################################################################

script "js_currency", type:"javascript" do
  parameters "ds_currency_reference", "ds_currency_code"
  result "result"
  code <<-EOS
  symbol = ""
  separator = ""
  if( ds_currency_code['value'] !== undefined ) {
    if (ds_currency_reference[ds_currency_code['value']] !== undefined ) {
      symbol = ds_currency_reference[ds_currency_code['value']]['symbol']
      if( ds_currency_reference[ds_currency_code['value']]['t_separator'] !== undefined ) {
        separator = ds_currency_reference[ds_currency_code['value']]['t_separator']
      }
    }
  } else {
    symbol = "$"
    separator = ","
  }
  result = {
    'symbol': symbol,
    'separator': separator
  }
EOS
end

script "js_aws_account", type:"javascript" do
  parameters "ds_get_caller_identity"
  result "result"
  code <<-EOS
  result = ds_get_caller_identity[0]['account']
EOS
end

script "js_regions", type:"javascript" do
  parameters "user_entered_regions", "all_regions", "regions_allow_or_deny"
  result "regions"
  code <<-EOS
  if (_.isEmpty(user_entered_regions)) {
    regions = all_regions
  } else {
    //Filter unique regions
    var uniqueRegions = _.uniq(user_entered_regions)
    var all_regions_list = []
    //Filter and remove denied regions from all_regions
    if (regions_allow_or_deny == "Deny"){
      var all_regions = all_regions.filter(function(obj){
        return user_entered_regions.indexOf(obj.region) === -1;
      });
    }
    all_regions.forEach(function(all_region){
      all_regions_list.push(all_region.region)
    })
    //Filter valid regions
    var valid_regions = []
    _.map(uniqueRegions, function(uniqueRegion){
      if(all_regions_list.indexOf(uniqueRegion) > -1){
        valid_regions.push({"region": uniqueRegion})
      }
    })
    //Throw an error if no valid regions found
    if (_.isEmpty(valid_regions)) {
      regions = all_regions
    }else{
      regions = valid_regions
    }
  }
EOS
end

script "js_instances", type: "javascript" do
  result "result"
  parameters "ds_instance_set", "param_exclusion_tag_key"
  code <<-EOS
  var tag_key = param_exclusion_tag_key.split(':')[0]
  var tag_value = param_exclusion_tag_key.split(':')[1]
  var result = []
  _.each(ds_instance_set, function(ds_item) {
    _.each(ds_item['instances_set'], function(instance) {
      var tags = instance.tags
      if (!(_.contains(_.pluck(tags,'key'), tag_key) && _.contains(_.pluck(tags,'value'), tag_value))) {
        result.push(instance)
      }
    })
  })
EOS
end

script "js_instances_queries", type: "javascript" do
  result "queries"
  parameters "ds_instances", "param_avg_cpu", "param_avg_used_memory"
  code <<-EOS
  // Create the various queries we're going to send to CloudWatch for each instance
  queries = {}
  _.each(ds_instances, function(instance) {
    // Make sure the queries object has an array for the region to push items to
    if (queries[instance['region']] == undefined || queries[instance['region']] == null) {
      queries[instance['region']] = []
    }
    //We want to collect each of these list of statistics we care about
    stats = ["Average", "Minimum", "Maximum", "p99", "p95", "p90"]
    // Only query for CPU usage if we're actually checking it
    if (param_avg_cpu != -1) {
      _.each(stats, function(stat) {
        query = {
          "Id": instance['instanceId'].replace('-', '_') + "_cpu" + stat,
          "MetricStat": {
            "Metric": {
              "Namespace": "AWS/EC2",
              "MetricName": "CPUUtilization",
              "Dimensions": [
                { "Name": "InstanceId", "Value": instance['instanceId'] }
              ]
            },
            "Period": 2592000,
            "Stat": stat
          },
          "ReturnData": true
        }
        queries[instance['region']].push(query)
      })
    }
    // Only query for MEM usage if we're actually checking it
    if (param_avg_used_memory != -1) {
      if (instance['platform'] == "Windows") {
        // If platform is Windows, we need to use the Windows custom metric
        mem_metricname = "Memory % Committed Bytes In Use"
        dimensions = [
          { "Name": "ImageId", "Value": instance['imageId'] },
          { "Name": "InstanceId", "Value": instance['instanceId'] },
          { "Name": "InstanceType", "Value": instance['resourceType'] },
          { "Name": "objectname", "Value": "Memory" }
        ]
      } else {
        // Else assume Platform is Linux, and use the Linux custom metric
        mem_metricname = "mem_used_percent"
        dimensions = [
          { "Name": "ImageId", "Value": instance['imageId'] },
          { "Name": "InstanceId", "Value": instance['instanceId'] },
          { "Name": "InstanceType", "Value": instance['resourceType'] }
        ]
      }
      _.each(stats, function(stat) {
        query = {
          "Id": instance['instanceId'].replace('-', '_') + "_mem" + stat,
          "MetricStat": {
            "Metric": {
              "Namespace": "CWAgent",
              "MetricName": mem_metricname,
              "Dimensions": dimensions
            },
            "Period": 2592000,
            "Stat": stat
          },
          "ReturnData": true
        }
        queries[instance['region']].push(query)
      })
    }
  })
EOS
end

script "js_instances_requests", type: "javascript" do
  result "result"
  parameters "queries"
  code <<-EOS
  // Organize the queries into discrete requests to send in.
  // Queries are first sorted by region and then split into 500 item blocks.
  result = []
  end_date = parseInt(new Date().getTime() / 1000)
  start_date = parseInt(new Date(new Date().setDate(new Date().getDate() - 30)).getTime() / 1000)
  query_block_size = 500
  _.each(Object.keys(queries), function(region) {
    for (i = 0; i < queries[region].length; i += query_block_size) {
      chunk = queries[region].slice(i, i + query_block_size)
      result.push({
        'body': { "StartTime": start_date, "EndTime": end_date, "MetricDataQueries": chunk },
        'region': region
      })
    }
  })
EOS
end

script "js_cloudwatch_data", type: "javascript" do
  result "results"
  parameters "region", "body", "api_wait"
  code <<-EOS
  // Slow down rate of requests to prevent throttling
  var now = new Date().getTime()
  while(new Date().getTime() < now + (api_wait * 1000)) { /* Do nothing */ }
  results = {
    "auth": "auth_aws",
    "host": 'monitoring.' + region + '.amazonaws.com',
    "verb": "POST",
    "path": "/",
    "headers": {
      "User-Agent": "RS Policies",
      "Content-Type": "application/json",
      "x-amz-target": "GraniteServiceVersion20100801.GetMetricData",
      "Accept": "application/json",
      "Content-Encoding": "amz-1.0"
    }
    "query_params": {
      'Action': 'GetMetricData',
      'Version': '2010-08-01'
    },
    body: JSON.stringify(body)
  }
EOS
end

script "js_cloudwatch_data_sorted", type: "javascript" do
  result "result"
  parameters "ds_cloudwatch_data"
  code <<-EOS
  // Sort the CloudWatch data into an object with keys for regions and instance names.
  // This eliminates the need to "double loop" later on to match it with our instances list.
  result = {}
  _.each(ds_cloudwatch_data, function(item) {
    region = item['region']
    instance_name = item['id'].split('_')[0] + '-' + item['id'].split('_')[1]
    metric = item['id'].split('_')[2]
    value = item['values'][0]
    if (result[region] == undefined) {
      result[region] = {}
    }
    if (result[region][instance_name] == undefined) {
      result[region][instance_name] = {}
    }
    result[region][instance_name][metric] = value
  })
EOS
end

script "js_top_level_bc", type: "javascript" do
  parameters "billing_centers"
  result "result"
  code <<-EOS
  result = []
  _.each(billing_centers, function(bc) {
    if (bc['parent_id'] == null || bc['parent_id'] == undefined) {
      result.push(bc)
    }
  })
EOS
end

script "js_instances_costs_request", type: "javascript" do
  parameters "aws_account", "billing_centers"
  result "result"
  code <<-EOS
  // returns date formatted as string: YYYY-mm-dd
  function getFormattedDailyDate(date) {
    var year = date.getFullYear()
    var month = (1 + date.getMonth()).toString()
    month = month.length > 1 ? month : '0' + month
    var day = date.getDate().toString()
    day = day.length > 1 ? day : '0' + day
    return year + '-' + month + '-' + day
  }
  start_date = getFormattedDailyDate(new Date(new Date().setDate(new Date().getDate() - 3)))
  end_date = getFormattedDailyDate(new Date(new Date().setDate(new Date().getDate() - 2)))
  result = [{
    "dimensions": ["resource_id", "vendor_account_name"],
    "granularity": "day",
    "start_at": start_date,
    "end_at": end_date,
    "metrics": ["cost_nonamortized_unblended_adj"],
    "billing_center_ids": _.compact(_.map(billing_centers, function(value){ return value.id })),
    "limit": 100000,
    // Speed up execution by filtering the result set for only what we need.
    "filter": {
      "expressions": [
        {
          "dimension": "service",
          "type": "equal",
          "value": "AmazonEC2"
        },
        {
          "dimension": "resource_type",
          "type": "equal",
          "value": "Compute Instance"
        },
        {
          "dimension": "vendor_account",
          "type": "equal",
          "value": aws_account
        }
      ],
      "type": "and"
    }
  }]
EOS
end

script "js_merged_metrics", type: "javascript" do
  result "result"
  parameters "cloudwatch_data", "ds_instances", "aws_account", "currency"
  code <<-EOS
  result = []
  //We want to collect each of these list of statistics we care about
  stats = ["Average", "Minimum", "Maximum", "p99", "p95", "p90"]

  _.each(ds_instances, function(instance) {
    region = instance['region']
    id = instance['instanceId']
    var resourceName = ""
    var tags = []
    _.each(instance['tags'], function(inst){
      if (inst.key == "Name") {
        resourceName = inst.value
      }
      tags.push(inst.key+'='+inst.value)
    })

    // Only proceed of the CloudWatch data actually has the region and instance id.
    // Otherwise, we have no usage data on the instance and thus dont include it in the results.
    if (cloudwatch_data[region] != undefined) {
      if (cloudwatch_data[region][id] != undefined) {
        r = {
          "region": instance['region'],
          "id": instance['instanceId'],
          "resourceID": instance['instanceId'],
          "platform": instance['platform'],
          "service": "EC2",
          "privateDnsName": instance['privateDnsName'],
          "launchTime": instance['launchTime'],
          "hostname": instance['privateDnsName'].split('.')[0],
          "tags": tags,
          "resourceName": resourceName,
          "resourceType": instance['resourceType'],
          "savings": null,
          "accountID": aws_account,
          "accountName": "",
          "savingsCurrency": currency['symbol'],
          "lookbackPeriod": '30 days',
        }
        // Grab usage data for the instance if it is present
        _.each(stats, function(stat) {
          _.each(["cpu", "mem"], function(metric) {
            statname = metric + stat
            //legacyStatName is the name of the attribute that was used in all versions up to version 4.X
            //We use this instead of statname to keep backwards compatability for the exported data
            legacyStatName = metric + "_" + stat.toLowerCase()
            r[legacyStatName] = null
            if (cloudwatch_data[region][id][statname] != undefined && cloudwatch_data[region][id][statname] != null) {
              r[legacyStatName] = Math.round(cloudwatch_data[region][id][statname]*1000)/1000
            }
          })
        })
        // Send the instance information with the CloudWatch data into the final result.
        // Also adds in the account ID and currency symbol since itll be needed for the incident.
        result.push(r)
      }
    }
  })
EOS
end

script "js_idle_instances", type:"javascript" do
  parameters "ds_merged_metrics", "ds_instances_costs", "param_avg_cpu", "param_avg_used_memory", "currency", "param_check_both", "param_threshold_statistic"
  result "result"
  code <<-EOS
  // Used for formatting numbers to look pretty
  function formatNumber(number, separator){
    var numString =number.toString()
    var values=numString.split(".")
    var result = ''
    while (values[0].length > 3){
      var chunk = values[0].substr(-3)
      values[0] = values[0].substr(0, values[0].length - 3)
      result = separator + chunk + result
    }
    if (values[0].length > 0){
      result = values[0] + result
    }
    if(values[1]==undefined){
      return result
    }
    return result+"."+values[1]
  }

  var accountName = ""
  if (_.size(ds_instances_costs) > 0) {
    accountName = ds_instances_costs[0].vendorAccountName
  }

  idle_instances = []
  total_savings = 0.00
  cost_data_found = false
  // The key name is lowercase, param value needs to be lowercase.
  // We use this to keep backwards compatability for the exported data.
  param_threshold_statistic = param_threshold_statistic.toLowerCase()
  // Only bother doing anything if we're checking at least one metric
  if (param_avg_cpu != -1 || param_avg_used_memory != -1) {
    _.each(ds_merged_metrics, function(instance) {
      // Do not include instance in the result set unless it meets the requirements.
      include_instance = false
      // If we're not checking memory and CPU usage is below threshold, include it.
      if (param_avg_used_memory == -1 && instance['cpu' + "_" + param_threshold_statistic] < param_avg_cpu) {
        include_instance = true
      }
      // If we're not checking CPU and memory usage is below threshold, include it.
      if (param_avg_cpu == -1 && instance['mem' + "_" + param_threshold_statistic] < param_avg_used_memory) {
        include_instance = true
      }
      // If we're checking both CPU and memory, look at the parameter to see whether the user
      // wants to do an AND comparison or an OR comparison.
      if (param_avg_cpu != -1 && param_avg_used_memory != -1) {
        if (param_check_both == "Both CPU and Memory") {
          if (instance['cpu' + "_" + param_threshold_statistic] < param_avg_cpu && instance['mem' + "_" + param_threshold_statistic] < param_avg_used_memory) {
            include_instance = true
          }
        } else {
          if (instance['cpu' + "_" + param_threshold_statistic] < param_avg_cpu || instance['mem' + "_" + param_threshold_statistic] < param_avg_used_memory) {
            include_instance = true
          }
        }
      }

      // Only find the cost data if we're including the instance in the result set.
      // This speeds up execution by not pointlessly gathering this data for instances
      // we wont be reporting on.
      if (include_instance) {
        _.each(ds_instances_costs, function(cost) {
          if (instance['id'] == cost['resource_id']) {
            if (isNaN(cost['cost_nonamortized_unblended_adj']) == false) {
              instance['savings'] = parseFloat(cost['cost_nonamortized_unblended_adj'] * 30).toFixed(2)
              instance['accountName'] = accountName
              cost_data_found = true
            }
          }
        })
        if (isNaN(instance['savings']) == false) {
          total_savings += parseFloat(instance['savings'])
        }
        instance['threshold'] = param_avg_cpu
        instance['memoryThreshold'] = param_avg_used_memory
        instance['thresholdType'] = param_threshold_statistic
        idle_instances.push(instance)
      }
    })
  }
  // Create the message to include in the incident output
  message = ''
  if (param_avg_cpu == -1 && param_avg_used_memory == -1) {
    message = "No results found because average CPU and average used memory parameters are both set to -1.\\n\\n"
    message += "Please set a valid threshold for at least one metric when using this policy."
  } else {
    if (idle_instances.length == 0) {
      message = "No idle instances found."
    }
  }
  if (idle_instances.length > 0 && cost_data_found == true) {
    pretty_savings = currency['symbol'] + ' ' + formatNumber(total_savings.toFixed(2), currency['separator'])
    message = "The total estimated monthly savings are " + pretty_savings + '.'
  }
  if (idle_instances.length > 0 && cost_data_found == false) {
    message = "No cost data found. Either the Flexera Optima system does not have any data to calculate savings for these resources, or you do not have the minimum required role of billing_center_viewer to view cost data."
  }
  // Create final result
  result = {
    'idle_instances': idle_instances,
    'message': message
  }
EOS
end

###############################################################################
# Policy
###############################################################################

policy "pol_utilization" do
  validate $ds_idle_instances do
    summary_template "AWS Account ID: {{with index data.idle_instances 0}}{{ .accountID }}{{end}} - {{ len data.idle_instances}} Idle AWS EC2 Instances Found"
    detail_template <<-EOS
{{data.message}}
EOS
    escalate $esc_email
    escalate $esc_terminate_resources
    check logic_or($ds_parent_policy_terminated,    eq(size(val(data, "idle_instances")), 0)    )
    export "idle_instances" do
      resource_level true
      field "accountID" do
        label "Account Id"
      end
      field "accountName" do
        label "Account Name"
      end
      field "resourceID" do
        label "Resource ID"
      end
      field "resourceName" do
        label "Resource Name"
      end
      field "region" do
        label "Region"
      end
      field "platform" do
        label "Platform"
      end
      field "hostname" do
        label "Hostname"
      end
      field "resourceType" do
        label "Resource Type"
      end
      field "savings" do
        label "Estimated Monthly Savings"
      end
      field "savingsCurrency" do
        label "Savings Currency"
      end
      field "privateDnsName" do
        label "Private DNS Name"
      end
      field "launchTime" do
        label "Launch Time"
      end
      field "cpuMaximum" do
        label "CPU Maximum %"
        path "cpu_maximum"
      end
      field "cpuMinimum" do
        label "CPU Minimum %"
        path "cpu_minimum"
      end
      field "cpuAverage" do
        label "CPU Average %"
        path "cpu_average"
      end
      field "cpuP99" do
        label "CPU p99"
        path "cpu_p99"
      end
      field "cpuP95" do
        label "CPU p95"
        path "cpu_p95"
      end
      field "cpuP90" do
        label "CPU p90"
        path "cpu_p90"
      end
      field "memMaximum" do
        label "Memory Maximum %"
        path "mem_maximum"
      end
      field "memMinimum" do
        label "Memory Minimum %"
        path "mem_minimum"
      end
      field "memAverage" do
        label "Memory Average %"
        path "mem_average"
      end
      field "memP99" do
        label "Memory p99"
        path "mem_p99"
      end
      field "memP95" do
        label "Memory p95"
        path "mem_p95"
      end
      field "memP90" do
        label "Memory p90"
        path "mem_p90"
      end
      field "tags" do
        label "Tags"
      end
      field "id" do
        label "ID"
        path "resourceID"
      end
      field "service" do
        label "Service"
      end
      field "lookbackPeriod" do
        label "Lookback Period"
      end
      field "threshold" do
        label "CPU Threshold"
      end
      field "memoryThreshold" do
        label "Memory Threshold"
      end
      field "thresholdType" do
        label "Threshold Type"
      end
    end
  end
end

###############################################################################
# Escalations
###############################################################################

escalation "esc_email" do
  automatic true
  label "Send Email"
  description "Send incident email"
  email $param_email
end

escalation "esc_terminate_resources" do
  automatic contains($param_automatic_action, "Terminate Instances")
  label "Terminate Instances"
  description "Approval to terminate all selected instances"
  run "terminate_resources", data, $param_log_to_cm_audit_entries, rs_optima_host
end

###############################################################################
# Cloud Workflow
###############################################################################

define terminate_resources($data,$param_log_to_cm_audit_entries, $$rs_optima_host) return $all_responses do
  $$debug = $param_log_to_cm_audit_entries == "Yes"
  $$log = []
  $all_responses = []
  $syslog_subject = "AWS Idle Compute: "
  call sys_log(join([$syslog_subject, "Identified Instances"]),to_s($data))
  foreach $item in $data do
    $response = http_request(
      auth: $$auth_aws,
      https: true,
      verb: "post",
      href: "/",
      host: "ec2."+$item["region"]+".amazonaws.com",
      query_strings: {
        "Action": "TerminateInstances",
        "Version": "2012-06-01",
        "InstanceId.1": $item["id"]
      }
    )
    $all_responses << $response
  end
  call sys_log(join([$syslog_subject, "Responses"]),to_s($all_responses))
end

define handle_error($response) do
  $status_code = $response["code"]
  $syslog_subject = "AWS Idle Compute Termination Error: "
  call sys_log(join([$syslog_subject, $status_code]),to_s($response))
  $_error_behavior = "skip"
end

define sys_log($subject, $detail) do
  # Create empty errors array if doesn't already exist
  if !$$errors
    $$errors = []
  end
  # Check if debug is enabled
  if $$debug
    # Append to global $$errors
    # This is the suggested way to capture errors
    $$errors << "Unexpected error for " + $subject + "\n  " + to_s($detail)
    # If Flexera NAM Zone, create audit_entries [to be deprecated]
    # This is the legacy method for capturing errors and only supported on Flexera NAM
    if $$rs_optima_host == "api.optima.flexeraeng.com"
      # skip_error_and_append is used to catch error if rs_cm.audit_entries.create fails unexpectedly
      $task_label = "Creating audit entry for " + $subject
      sub task_label: $task, on_error: skip_error_and_append($task) do
        rs_cm.audit_entries.create(
          notify: "None",
          audit_entry: {
            auditee_href: @@account,
            summary: $subject,
            detail: $detail
          }
        )
      end # End sub on_error
    end # End if rs_optima_host
  end # End if debug is enabled
end

define skip_error_and_append($subject) do
  $$errors << "Unexpected error for " + $subject + "\n  " + to_s($_error)
  $_error_behavior = "skip"
end


###############################################################################
# Meta Policy [alpha]
# Not intended to be modified or used by policy developers
###############################################################################

# If the meta_parent_policy_id is not set it will evaluate to an empty string and we will look for the policy itself,
# if it is set we will look for the parent policy.
datasource "ds_get_policy" do
  request do
    auth $auth_flexera
    host rs_governance_host
    ignore_status [404]
    path join(["/api/governance/projects/", rs_project_id, "/applied_policies/", switch(ne(meta_parent_policy_id,""), meta_parent_policy_id, policy_id) ])
    header "Api-Version", "1.0"
  end
  result do
    encoding "json"
    field "id", jmes_path(response, "id")
  end
end


datasource "ds_parent_policy_terminated" do
  run_script $js_decide_if_self_terminate, $ds_get_policy, policy_id, meta_parent_policy_id
end

# If the policy was applied by a meta_parent_policy we confirm it exists if it doesn't we confirm we are deleting
# This information is used in two places:
# - determining whether or not we make a delete call
# - determining if we should create an incident (we don't want to create an incident on the run where we terminate)
script "js_decide_if_self_terminate", type: "javascript" do
  parameters "found", "self_policy_id", "meta_parent_policy_id"
  result "result"
  code <<-EOS
  var result
  if (meta_parent_policy_id != "" && found.id == undefined) {
    result = true
  } else {
    result = false
  }
  EOS
end

# Two potentials ways to set this up:
# - this way and make a unneeded 'get' request when not deleting
# - make the delete request an interate and have it iterate over an empty array when not deleting and an array with one item when deleting
script "js_make_terminate_request", type: "javascript" do
  parameters "should_delete", "policy_id", "rs_project_id", "rs_governance_host"
  result "request"
  code <<-EOS

  var request = {
    auth:  'auth_flexera',
    host: rs_governance_host,
    path: "/api/governance/projects/" + rs_project_id + "/applied_policies/" + policy_id,
    headers: {
      "API-Version": "1.0",
      "Content-Type":"application/json"
    },
  }

  if (should_delete) {
    request.verb = 'DELETE'
  }
  EOS
end

datasource "ds_terminate_self" do
  request do
    run_script $js_make_terminate_request, $ds_parent_policy_terminated, policy_id, rs_project_id, rs_governance_host
  end
end

datasource "ds_is_deleted" do
  run_script $js_check_deleted, $ds_terminate_self
end

# This is just a way to have the check delete request connect to the farthest leaf from policy.
# We want the delete check to the first thing the policy does to avoid the policy erroring before it can decide whether or not it needs to self terminate
# Example a customer deletes a credential and then terminates the parent policy. We still want the children to self terminate
# The only way I could see this not happening is if the user who applied the parent_meta_policy was offboarded or lost policy access, the policies who are impersonating the user
# would not have access to self-terminate
# It may be useful for the backend to enable a mass terminate at some point for all meta_child_policies associated with an id.
script "js_check_deleted", type: "javascript" do
  parameters "response"
  result "result"
  code <<-EOS
  result = {"path":"/"}
  EOS
end
