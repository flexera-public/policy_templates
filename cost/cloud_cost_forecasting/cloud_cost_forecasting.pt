name "Cloud Cost Forecasting"
rs_pt_ver 20180301
type "policy"
short_description "Analyze all Billing Centers for a specified number of days and raise an incident if the percentage of spend (compared to the previous period of the same number of days) has surpassed the defined threshold. See the [README](https://github.com/rightscale/policy_templates/tree/master/cost/billing_center_cost_anomaly/) and [docs.flexera.com/flexera/EN/Automation](https://docs.flexera.com/flexera/EN/Automation/AutomationGS.htm) to learn more."
long_description ""
severity "high"
category "Cost"
tenancy "single"
default_frequency "daily"
info(
  version: "2.0",
  provider: "Flexera Optima",
  service: "",
  policy_set:""
)

###############################################################################
# Permissions
###############################################################################

###############################################################################
# Parameters
###############################################################################

parameter "param_billing_centers" do
  label "Billing Center Name"
  description "List of Billing Center Names to check"
  type "list"
  default []
end

parameter "param_cost_metric" do
  type "string"
  label "Cost Metric"
  allowed_values "Unamortized Unblended","Amortized Unblended","Unamortized Blended","Amortized Blended"
  default "Unamortized Unblended"
  description "Select the cost metric for your report.  See the README file for more details"
end

parameter "param_email" do
  label "Email addresses of the recipients you wish to notify"
  type "list"
end

###############################################################################
# Authentication
###############################################################################

auth "auth_rs", type: "rightscale"

###############################################################################
# Resources
###############################################################################

###############################################################################
# Datasources
###############################################################################

datasource "ds_currency_reference" do
  request do
    host "raw.githubusercontent.com"
    path "/rightscale/policy_templates/master/cost/scheduled_reports/currency_reference.json"
    header "User-Agent", "RS Policies"
  end
end

datasource "ds_currency_code" do
  request do
    auth $auth_rs
    host rs_optima_host
    path join(["/bill-analysis/orgs/",rs_org_id,"/settings/currency_code"])
    header "Api-Version", "0.1"
    header "User-Agent", "RS Policies"
  end
  result do
    encoding "json"
    field "id", jmes_path(response,"id")
    field "value", jmes_path(response,"value")
  end
end

datasource "ds_billing_centers" do
  request do
    auth $auth_rs
    host rs_optima_host
    path join(["/analytics/orgs/",rs_org_id,"/billing_centers"])
    header "Api-Version", "1.0"
    header "User-Agent", "RS Policies"
    query "view", "allocation_table"
  end
  result do
    encoding "json"
    collect jmes_path(response,"[*]") do
      field "href", jmes_path(col_item,"href")
      field "id", jmes_path(col_item,"id")
      field "name", jmes_path(col_item,"name")
      field "parent_id", jmes_path(col_item,"parent_id")
      field "ancestor_ids", jmes_path(col_item,"ancestor_ids")
      field "allocation_table", jmes_path(col_item,"allocation_table")
    end
  end
end

datasource "ds_past_month_list" do
  run_script $js_generate_past_month_list
end

datasource "ds_costs" do
  iterate $ds_past_month_list
  request do
    run_script $new_costs_request, rs_org_id, $ds_billing_centers, $param_cost_metric, $param_billing_centers, val(iter_item, 'start_date'), val(iter_item, 'end_date')
  end
  result do
    encoding "json"
    collect jmes_path(response,"rows[*]") do
      field "start_date", val(iter_item,"start_date")
      field "cost_amortized_unblended_adj", jmes_path(col_item,"metrics.cost_amortized_unblended_adj")
      field "cost_amortized_blended_adj", jmes_path(col_item,"metrics.cost_amortized_blended_adj")
      field "cost_nonamortized_unblended_adj", jmes_path(col_item,"metrics.cost_nonamortized_unblended_adj")
      field "cost_nonamortized_blended_adj", jmes_path(col_item,"metrics.cost_nonamortized_blended_adj")
      field "id", jmes_path(col_item,"dimensions.billing_center_id")
      field "timestamp", jmes_path(col_item,"timestamp")
    end
  end
end

###############################################################################
# Scripts
###############################################################################
script "js_generate_past_month_list", type: "javascript" do
  result "month_list"
  code <<-EOS
  var month_list = [];
  // format the date for the `daily` API
  // returns date formatted as string: YYYY-mm-dd
  function getFormattedDailyDate(date) {
    var year = date.getFullYear();
    var month = (1 + date.getMonth()).toString();
    month = month.length > 1 ? month : '0' + month;
    return year + '-' + month;
  }

  function getStartDate( date, month_counter ) {
    date.setMonth(date.getMonth() - month_counter);
    return date;
  }

  function getEndDate( date, month_counter ) {
    date.setMonth(date.getMonth() - (month_counter - 1));
    return date;
  }

  _.each([1,2,3,4,5,6], function (month_counter) {
    var start_date = getFormattedDailyDate(getStartDate(new Date(), month_counter));
    var end_date = getFormattedDailyDate(getEndDate(new Date(), month_counter));
    month_list.push({
      'start_date': start_date,
      'end_date': end_date,
    });
  });
EOS
end

script "new_costs_request", type: "javascript" do
  parameters "org_id", "ds_billing_centers", "param_cost_metric", "param_billing_centers", "start_at", "end_at"
  result "request"
  code <<-EOS
    var cost_metric = {
      "Unamortized Unblended":"cost_nonamortized_unblended_adj",
      "Amortized Unblended":"cost_amortized_unblended_adj",
      "Unamortized Blended": "cost_nonamortized_blended_adj",
      "Amortized Blended":"cost_amortized_blended_adj"
    }
    var billing_center_ids = []
    if (param_billing_centers.length === 0){
      var top_billing_centers = _.reject(ds_billing_centers, function(bc){ return bc.parent_id != null });
      billing_center_ids = _.map(top_billing_centers, function(value, key){ return value.id });
    } else {
      // get array of billing center id's that match the names in param_billing_centers.
      billing_center_names = _.map(param_billing_centers, function(name){ return name.toLowerCase(); });
      billing_center_ids = _.compact(_.map(ds_billing_centers, function(value){ if(_.contains(billing_center_names, value.name.toLowerCase())){return value.id} }));
    }

    var request = {
      auth: "auth_rs",
      verb: "POST",
      host: "optima.rightscale.com",
      path: "/bill-analysis/orgs/" + org_id + "/costs/aggregated",
      body_fields: {
        "dimensions": ["billing_center_id"],
        "granularity": "month",
        "metrics": [cost_metric[param_cost_metric]],
        "billing_center_ids": billing_center_ids,
        "start_at": start_at,
        "end_at": end_at
      },
      headers: {
        "Api-Version": "1.0",
        "User-Agent": "RS Policies",
      }
    }
  EOS
end

script "calculate_forecast", type: "javascript" do
  results "forecast"
  code <<-EOS
  var _ = require('underscore');
var ds_costs = require('./datasource_ds_costs.json');
var param_cost_metric = 'cost_nonamortized_unblended_adj';
class TimeSeries {
  constructor( data, options ) {
    this.options = _.extend({}, options);

    this.data = data;
    this.original = data.slice(0);
    this.buffer = [];
    this.saved = [];
    this.adapter = {};
    return this;
  }
  timeseries = function (data, options) {
    /*
      Data Format:
      [
        [Date Object, value],
        [Date Object, value]
      ]
    */
    this.options = _.extend({}, options);

    this.data = data;
    this.original = data.slice(0);
    this.buffer = [];
    this.saved = [];

    return this;
  };

  // Output the data
  output = function () {
    return this.data;
  };

  // Save the data
  save = function (name, options) {
    options = _.extend(
      {
        color: "AUTO",
      },
      options
    );

    this.saved.push({
      name: name,
      color: options.color,
      data: this.data.slice(0),
    });
    return this;
  };


  // Basic utilities: Array fill, data cloning...
  // Returns an array filled with the specified value.
  fill = function (value, n) {
    var array = [];
    var i;
    for (i = 0; i < n; i++) {
      array.push(value);
    }
    return array;
  };

  // Returns a clone of the data
  clone = function () {
    var buffer = _.map(this.data, function (point) {
      return [point[0], point[1] * 1];
    });
    return buffer;
  };

  // Reset the data to its original dataset
  reset = function () {
    this.data = this.original;
    return this;
  };

  // Convert the data to a 1D array
  toArray = function () {
    return _.map(this.data, function (datapoint) {
      return datapoint[1];
    });
  };

  // Stats: Min, Max, Mean, Stdev
  min = function () {
    var array = this.toArray();
    return _.min(array);
  };
  max = function () {
    var array = this.toArray();
    return _.max(array);
  };
  mean = function (data) {
    if (!data) {
      var data = this.data;
    }
    var sum = 0;
    var n = 0;
    _.each(data, function (datapoint) {
      sum += datapoint[1];
      n++;
    });
    return sum / n;
  };
  stdev = function (data) {
    if (!data) {
      var data = this.data;
    }
    var sum = 0;
    var n = 0;
    var mean = this.mean();
    _.each(data, function (datapoint) {
      sum += (datapoint[1] - mean) * (datapoint[1] - mean);
      n++;
    });
    return Math.sqrt(sum / n);
  };

  // Offet the data
  offset = function (value, data, ret) {
    if (!data) {
      var data = this.data;
    }
    var i;
    var j;
    var l = data.length;
    var sum = 0;

    // Reset the buffer
    this.buffer = data.slice(0);

    for (i = 0; i < l; i++) {
      this.buffer[i] = [this.buffer[i][0], this.buffer[i][1] + value];
    }
    if (!ret) {
      this.data = this.buffer;
      return this;
    } else {
      return this.buffer;
    }
  };

  // Moving Average
  ma = function (options) {
    options = _.extend(
      {
        period: 12,
      },
      options
    );
    var i;
    var j;
    var l = this.data.length;
    var sum = 0;

    // Reset the buffer
    this.buffer = [];

    // Leave the datapoints [0;period[ intact
    this.buffer = this.data.slice(0, options.period);

    for (i = options.period; i < l; i++) {
      sum = 0;
      for (j = options.period; j > 0; j--) {
        sum += this.data[i - j][1];
      }
      this.buffer[i] = [this.data[i][0], sum / options.period];
    }
    this.data = this.buffer;
    return this;
  };
  ema = function (options) {
    options = _.extend(
      {
        period: 12,
      },
      options
    );
    var i;
    var j;
    var l = this.data.length;
    var sum = 0;

    // Reset the buffer
    this.buffer = [];

    // Leave the datapoints [0;period[ intact
    this.buffer = this.data.slice(0, options.period);

    var m = 2 / (options.period + 1); // Multiplier

    for (i = options.period; i < l; i++) {
      this.buffer[i] = [
        this.data[i][0],
        (this.data[i][1] - this.data[i - 1][1]) * m + this.data[i - 1][1],
      ];
    }
    this.data = this.buffer;
    return this;
  };
  lwma = function (options) {
    options = _.extend(
      {
        period: 12,
      },
      options
    );
    var i;
    var j;
    var l = this.data.length;
    var sum = 0;
    var n = 0;

    // Reset the buffer
    this.buffer = [];

    // Leave the datapoints [0;period[ intact
    this.buffer = this.data.slice(0, options.period);

    for (i = options.period; i < l; i++) {
      sum = 0;
      n = 0;
      for (j = options.period; j > 0; j--) {
        sum += this.data[i - j][1] * j;
        n += j;
      }
      this.buffer[i] = [this.data[i][0], sum / n];
    }
    this.data = this.buffer;
    return this;
  };

  // DSL, iTrend
  dsp_itrend = function (options) {
    // By Ehler
    // http://www.davenewberg.com/Trading/TS_Code/Ehlers_Indicators/iTrend_Ind.html
    options = _.extend(
      {
        alpha: 0.7,
        use: "main",
      },
      options
    );
    var i;
    var j;
    var l = this.data.length;

    var trigger = [];

    // Reset the buffer
    this.buffer = [];

    // Leave the datapoints [0;period[ intact
    this.buffer = this.data.slice(0, 3);
    this.trigger = this.data.slice(0, 3);

    for (i = 3; i < l; i++) {
      this.buffer[i] = [
        this.data[i][0],
        (options.alpha - (options.alpha * options.alpha) / 4) * this.data[i][1] +
          0.5 * (options.alpha * options.alpha) * this.data[i - 1][1] -
          (options.alpha - 0.75 * (options.alpha * options.alpha)) *
            this.data[i - 2][1] +
          2 * (1 - options.alpha) * this.buffer[i - 1][1] -
          (1 - options.alpha) * (1 - options.alpha) * this.buffer[i - 2][1],
      ];
      this.trigger[i] = [
        this.data[i][0],
        2 * this.buffer[i][1] - this.buffer[i - 2][1],
      ];
    }
    if (options.use == "trigger") {
      this.data = this.trigger;
    } else {
      this.data = this.buffer;
    }

    return this;
  };

  // Pixelize - Domain reduction
  pixelize = function (options) {
    options = _.extend(
      {
        grid: 20,
      },
      options
    );

    // Calculate the grid values
    var min = this.min();
    var max = this.max();
    var tile = (max - min) / options.grid;

    this.buffer = _.map(this.data, function (datapoint) {
      datapoint[1] = Math.round(datapoint[1] / tile) * tile;
      return datapoint;
    });
    this.data = this.buffer;
    return this;
  };

  // Iterative Noise Removal
  smoother = function (options) {
    options = _.extend(
      {
        period: 1,
      },
      options
    );
    var i;
    var j;
    var l = this.data.length;
    var sum = 0;

    // Reset the buffer
    this.buffer = this.data.slice(0);

    for (j = 0; j < options.period; j++) {
      for (i = 3; i < l; i++) {
        this.buffer[i - 1] = [
          this.buffer[i - 1][0],
          (this.buffer[i - 2][1] + this.buffer[i][1]) / 2,
        ];
      }
    }
    this.data = this.buffer;
    return this;
  };

  // Extract the noise out of the data
  noiseData = function () {
    var i;
    var j;
    var l = this.data.length;
    var sum = 0;

    // Reset the buffer
    this.buffer = [];

    for (i = 0; i < l; i++) {
      this.buffer[i] = [this.data[i][0], this.original[i][1] - this.data[i][1]];
    }
    this.data = this.buffer;
    return this;
  };

  // Oscillator function
  osc = function () {
    var i;
    var j;
    var l = this.data.length;
    var sum = 0;

    // Reset the buffer
    this.buffer = [];

    for (i = 0; i < l; i++) {
      if (i <= 1) {
        this.buffer[i] = [this.data[i][0], 0];
      } else {
        this.buffer[i] = [this.data[i][0], this.data[i][1] - this.data[i - 1][1]];
      }
    }
    this.data = this.buffer;
    return this;
  };

  // Find the supports and resistances. Wrong algorithm.
  supports = function (options) {
    options = _.extend(
      {
        grid: 40,
        threshold: 10,
      },
      options
    );

    // Calculate the grid values
    var min = this.min();
    var max = this.max();
    var tile = (max - min) / options.grid;

    var prices = {};

    _.each(this.data, function (datapoint) {
      var val = Math.round(datapoint[1] / tile) * tile;
      if (!prices[val]) {
        prices[val] = 0;
      }
      prices[val]++;
    });

    var ordered = [];
    var i;
    for (i in prices) {
      ordered.push({
        price: i,
        count: prices[i],
      });
    }
    ordered = ordered.sort(function (a, b) {
      return b.count - a.count;
    });
    ordered = _.filter(ordered, function (support) {
      return support.count >= options.threshold;
    });
    if (options.stats) {
      return ordered;
    }

    return _.map(ordered, function (support) {
      return support.price;
    });
  };

  // Standardize the data
  standardize = function (options) {
    options = _.extend({}, options);

    var stdev = this.stdev();
    var mean = this.mean();

    this.data = _.map(this.data, function (datapoint) {
      datapoint[1] = (datapoint[1] - mean) / stdev;
      return datapoint;
    });

    return this;
  };

  // Slice the data
  slice = function (from, to) {
    if (!from) {
      from = 0;
    }
    if (!to) {
      to = this.data.length - 1;
    }

    this.data = this.data.splice(from, to);

    return this;
  };

  // Find the cycle in the data
  cycle = function (options) {
    options = _.extend(
      {
        period: 10,
        forecast: false,
        forecast_length: 20,
      },
      options
    );

    // Smooth the data
    this.smoother(options);

    // Copy the data
    var buffer = [];
    var buffer_forecast = [];

    var i;
    var j;
    var l = this.data.length;
    for (i = 0; i < 2; i++) {
      buffer[i] = [this.data[i][0], this.data[i][1]];
      buffer_forecast[i] = [this.data[i][0], this.data[i][1]];
    }
    for (i = 2; i < l; i++) {
      // We find the ratio
      var d1 = this.data[i][1] - this.data[i - 1][1];
      var d2 = this.data[i][1] - this.data[i - 2][1];
      var ratio = d1 / d2;
      console.log("ratio", ratio, d1, d2);
      buffer[i] = [this.data[i][0], this.data[i][1]];

      buffer_forecast[i] = [
        this.data[i][0],
        this.data[i][1],
        ratio,
        d1 > 0,
        d2 > 0,
      ];
    }

    if (options.forecast) {
      for (i = 2; i < l; i++) {
        if (options.forecast == i) {
          // Generate a two cycles sin wave
          var sin = [];
          for (j = 0; j < 720; j++) {
            sin.push(Math.sin((j * Math.PI) / 180));
          }
          console.log("sin", sin);

          // Find the closest sin wave
          var MSE = [];
          var minMSE = 10000000;
          var pos;
          for (j = 2; j < 720; j++) {
            var d1 = sin[j] - sin[j - 1];
            var d2 = sin[j] - sin[j - 2];
            var ratio = d1 / d2;
            var mse =
              (ratio - buffer_forecast[i][2]) * (ratio - buffer_forecast[i][2]);
            if (
              mse <= minMSE &&
              d1 > 0 == buffer_forecast[i][3] &&
              d2 > 0 == buffer_forecast[i][3]
            ) {
              minMSE = mse;
              pos = j;
            }
          }
          console.log("minMSE", minMSE, pos);

          for (j = 0; j <= options.forecast_length; j++) {
            buffer_forecast[i + j][1] = Math.sin(((pos + j) * Math.PI) / 180);

            //buffer_forecast[i+j][1] = sin[pos+j];

            console.log(
              "buffer_forecast[" + (i + j) + "]",
              pos + j,
              buffer_forecast[i + j][1]
            );
          }

          break;
        }
      }
      this.data = buffer_forecast;
    } else {
      this.data = buffer;
    }

    return this;
  };

  // Get the outliers from the dataset
  outliers = function (options) {
    // Original code by Professor Hossein Arsham - http://home.ubalt.edu/ntsbarsh/Business-stat/otherapplets/Outlier.htm
    // Re-written for timeseries-analysis.

    options = _.extend(
      {
        threshold: 2.5,
      },
      options
    );

    // Create a copy of the data;
    this.buffer = this.data.slice(0);

    // standardize the data
    this.standardize();

    var outliers = [];

    _.each(this.data, function (datapoint) {
      if (Math.abs(datapoint[1]) > options.threshold) {
        outliers.push(datapoint);
      }
    });

    // restore the data
    this.data = this.buffer.slice(0);
    delete this.buffer;

    return outliers;
  };

  /* EXPERIMENTAL - AutoRegression Analysis */

  regression_forecast = function (options) {
    options = _.extend(
      {
        method: "ARMaxEntropy", // ARMaxEntropy | ARLeastSquare
        // How many sample data points to train,
        // must option.sample < option.start and option.sample >= 3.
        // If growthSampleMode option is true, then it only as starting train sample
        // because it will growth from 0 to last trained data point to be used as sample.
        sample: null,
        // Where data points to start, must option.start > option.sample
        start: null,
        // How many points to forecast.
        n: null,
        // How many degree, must option.n >= 1.
        degree: 5,
        // Is the training only use last x sample data points or up to entire data points?
        growthSampleMode: false,
        // Real data to be used.
        data: this.data,
      },
      options
    );

    var l = this.data.length;

    // Configure default options.
    options.sample =
      options.sample === null ? Math.round(l * 0.2) : options.sample;
    options.start = options.start === null ? options.sample + 1 : options.start;
    options.n = options.n === null ? l - options.sample : options.n;

    // Remove the mean.
    var mean = this.mean(options.data);
    options.data = this.offset(-mean, options.data, true);

    // Temporary working datasets.
    var buffer = _.map(options.data, function (item) {
      return [item[0], item[1] * 1];
    });

    // MSE atributtes.
    var knownValue = NaN;
    var dataCountMSE = 0;
    var MSE = 0;

    // Get different interval of time attribute from dataset.
    var timeDiff = Math.abs(
      new Date(buffer[1][0]).getTime() - new Date(buffer[0][0]).getTime()
    );

    for (var i = options.start - 1; i < options.start + options.n - 1; i++) {
      // Get sample as training dataset.
      var sample = options.growthSampleMode
        ? buffer.slice(i - options.sample - (i - (options.start - 1)), i)
        : buffer.slice(i - options.sample, i);

      // Get the AR coeffs from current sample dataset.
      var coeffs = this[options.method]({ degree: options.degree, data: sample });

      // console.log({i, buffer: buffer.map(val=>[val[0], val[1]+mean]), coeffs, data: this.data.map(val=>[val[0], val[1]+mean])})

      // Preparing the datapoint to be forecasted.
      if (i < l) {
        knownValue = buffer[i][1] * 1;
        buffer[i][1] = 0;
      } else {
        buffer.push([
          new Date(new Date(buffer[i - 1][0]).getTime() + timeDiff),
          0,
        ]);
      }

      // Get forecasted datapoint.
      for (var j = 0; j < coeffs.length; j++) {
        if (options.method == "ARMaxEntropy") {
          buffer[i][1] -= buffer[i - 1 - j][1] * coeffs[j];
        } else {
          buffer[i][1] += buffer[i - 1 - j][1] * coeffs[j];
        }
      }

      // Calculate squared error for MSE.
      // Only based the real observed data initially given.
      // If trained dataset used and got trained again, then it will not truly valid.
      if (i < l) {
        MSE += (knownValue - buffer[i][1]) * (knownValue - buffer[i][1]);
        dataCountMSE += 1;
        // console.log({knownValue, buffer: buffer[i][1], MSE});
      }
    }

    // Calculate mean for MSE.
    MSE /= dataCountMSE;

    // Replace the current model dataset to trained dataset.
    this.data = buffer;

    // Rollback the mean.
    this.offset(mean);

    // Get MSE.
    return MSE;
  };

  regression_forecast_optimize = function (options) {
    options = _.extend(
      {
        data: this.data,
        maxPct: 0.2,
        maxSampleSize: false,
      },
      options
    );

    var l = options.data.length;

    var maxSampleSize = Math.round(l * options.maxPct);
    if (options.maxSampleSize) {
      maxSampleSize = Math.min(maxSampleSize, options.maxSampleSize);
    }

    var maxDegree = Math.round(maxSampleSize);
    var methods = ["ARMaxEntropy", "ARLeastSquare"];
    var ss; // sample size
    var deg; // degree
    var MSEData = [];
    var i;
    for (i = 0; i < methods.length; i++) {
      for (ss = 3; ss <= maxSampleSize; ss++) {
        for (deg = 1; deg <= maxDegree; deg++) {
          if (deg <= ss) {
            var mse = this.regression_forecast_mse({
              method: methods[i],
              sample: ss,
              degree: deg,
              data: options.data,
            });
            // console.log("Trying method("+methods[i]+") degree("+deg+") sample("+ss+")\t"+mse);
            if (!isNaN(mse)) {
              MSEData.push({
                MSE: mse,
                method: methods[i],
                degree: deg,
                sample: ss,
              });
            }
          } else {
            break;
          }
        }
      }
    }

    // Now we sort by MSE
    MSEData = MSEData.sort(function (a, b) {
      return a.MSE - b.MSE;
    });

    // console.log("Best Settings: ",MSEData[0]);

    // Return the best settings
    return MSEData[0];
  };
  // Calculate the MSE for a forecast, for a set of parameters
  regression_forecast_mse = function (options) {
    options = _.extend(
      {
        method: "ARMaxEntropy", // ARMaxEntropy | ARLeastSquare
        sample: 50,
        degree: 5,
        data: this.data,
      },
      options
    );

    var i;
    var j;
    var l = options.data.length;

    var mean = this.mean(options.data);
    options.data = this.offset(-mean, options.data, true);

    var backup = _.map(options.data, function (item) {
      return [item[0], item[1] * 1];
    });
    var buffer = _.map(options.data, function (item) {
      return [item[0], item[1] * 1];
    });

    var MSE = 0;
    var n = 0;
    for (i = options.sample; i < l; i++) {
      var sample = buffer.slice(i - options.sample, i);
      // Get the AR coeffs
      var coeffs = this[options.method]({ degree: options.degree, data: sample });
      var knownValue = buffer[i][1] * 1;
      buffer[i][1] = 0;
      for (j = 0; j < coeffs.length; j++) {
        if (options.method == "ARMaxEntropy") {
          buffer[i][1] -= backup[i - 1 - j][1] * coeffs[j];
        } else {
          buffer[i][1] += backup[i - 1 - j][1] * coeffs[j];
        }
      }

      MSE += (knownValue - buffer[i][1]) * (knownValue - buffer[i][1]);
      n++;
    }

    MSE /= n;

    //this.data = buffer;

    // Put back the mean
    //this.offset(mean);

    return MSE;
  };
  sliding_regression_forecast = function (options) {
    options = _.extend(
      {
        method: "ARMaxEntropy", // ARMaxEntropy | ARLeastSquare
        sample: 50,
        degree: 5,
      },
      options
    );

    var i;
    var j;
    var l = this.data.length;

    var mean = this.mean();
    this.offset(-mean);
    var backup = this.clone();
    var buffer = this.clone();

    for (i = options.sample; i < l; i++) {
      var sample = buffer.slice(i - options.sample, i);
      // console.log(sample)
      // The current data to process is only a sample of the real data.
      this.data = sample;
      // Get the AR coeffs
      var coeffs = this[options.method]({ degree: options.degree });
      // console.log("coeffs", coeffs)
      buffer[i][1] = 0; //backup[i][1]*1;
      for (j = 0; j < coeffs.length; j++) {
        if (options.method == "ARMaxEntropy") {
          buffer[i][1] -= backup[i - 1 - j][1] * coeffs[j];
        } else {
          buffer[i][1] += backup[i - 1 - j][1] * coeffs[j];
        }
      }
      //buffer[i][1] -
    }

    this.data = buffer;

    // Put back the mean
    this.offset(mean);

    return this;
  };

  // Autoregression method: MaxEntropy
  ARMaxEntropy = function (options) {
    // Credits to Alex Sergejew, Nick Hawthorn, Rainer Hegger (1998)
    // Zero-Indexed arrays modification by Paul Sanders (the arrays were One-indexed, FORTRAN style)
    // Ported to Javascript by Julien Loutre for timeseries-analysis, from Paul Bourke's C code.

    options = _.extend(
      {
        degree: 5,
        data: this.data,
        intermediates: false, // Generates and returns the intermediates, a 2D array, instead of the coefficients.
      },
      options
    );

    var scope = this;
    var i;
    var length = options.data.length;
    var pef = this.fill(0, length);
    var per = this.fill(0, length);
    var ar = this.fill([], options.degree + 1);
    ar = _.map(ar, function (d1) {
      return scope.fill(0, options.degree + 1);
    });
    var h = this.fill(0, length);
    var g = this.fill(0, options.degree + 2);

    var t1, t2;
    var n;

    var coef = [];

    for (n = 1; n <= options.degree; n++) {
      var sn = 0.0;
      var sd = 0.0;
      var j;
      var jj = length - n;

      for (j = 0; j < jj; j++) {
        t1 = options.data[j + n][1] + pef[j];
        t2 = options.data[j][1] + per[j];
        sn -= 2.0 * t1 * t2;
        sd += t1 * t1 + t2 * t2;
      }

      t1 = g[n] = sn / sd;
      if (n != 1) {
        for (j = 1; j < n; j++) {
          h[j] = g[j] + t1 * g[n - j];
        }
        for (j = 1; j < n; j++) {
          g[j] = h[j];
        }
        jj--;
      }

      for (j = 0; j < jj; j++) {
        per[j] += t1 * pef[j] + t1 * options.data[j + n][1];
        pef[j] = pef[j + 1] + t1 * per[j + 1] + t1 * options.data[j + 1][1];
      }

      if (options.intermediates) {
        for (j = 0; j < n; j++) {
          ar[n][j] = g[j + 1];
        }
      }
    }
    if (!options.intermediates) {
      for (n = 0; n < options.degree; n++) {
        coef[n] = g[n + 1];
      }
      return coef;
    } else {
      return ar;
    }
  };

  // Autoregression method: Least Square
  ARLeastSquare = function (options) {
    // Credits to Rainer Hegger (1998)
    // Ported to Javascript by Julien Loutre for timeseries-analysis, from Paul Bourke's C code.
    var scope = this;

    options = _.extend(
      {
        degree: 5,
        data: this.data,
      },
      options
    );

    var i, j, k, hj, hi;
    var coefficients = [];

    var length = options.data.length;
    var mat = this.fill([], options.degree);
    mat = _.map(mat, function (d1) {
      return scope.fill(0, options.degree);
    });

    for (i = 0; i < options.degree; i++) {
      coefficients[i] = 0.0;
      for (j = 0; j < options.degree; j++) {
        mat[i][j] = 0.0;
      }
    }
    for (i = options.degree - 1; i < length - 1; i++) {
      hi = i + 1;
      for (j = 0; j < options.degree; j++) {
        hj = i - j;
        coefficients[j] += options.data[hi][1] * options.data[hj][1];
        for (k = j; k < options.degree; k++) {
          mat[j][k] += options.data[hj][1] * options.data[i - k][1];
        }
      }
    }
    for (i = 0; i < options.degree; i++) {
      coefficients[i] /= length - options.degree;
      for (j = i; j < options.degree; j++) {
        mat[i][j] /= length - options.degree;
        mat[j][i] = mat[i][j];
      }
    }

    var solved = this.SolveLE(mat, coefficients, options.degree);

    return coefficients;
  };

  SolveLE = function (mat, vec, n) {
    // Gaussian elimination solver.
    // Use the coefficients from the Least Square method and make it into the real AR coefficients.
    // Original code by Rainer Hegger (1998). Modified by Paul Bourke.
    // Ported to Javascript by Julien Loutre for timeseries-analysis, from Paul Bourke's C code.

    var i, j, k, maxi;
    var vswap = [];
    var mswap = [];
    var hvec = [];
    var max, h, pivot, q;

    for (i = 0; i < n - 1; i++) {
      max = Math.abs(mat[i][i]);
      maxi = i;
      for (j = i + 1; j < n; j++) {
        if ((h = Math.abs(mat[j][i])) > max) {
          max = h;
          maxi = j;
        }
      }
      if (maxi != i) {
        mswap = mat[i];
        mat[i] = mat[maxi];
        mat[maxi] = mswap;
        vswap = vec[i];
        vec[i] = vec[maxi];
        vec[maxi] = vswap;
      }

      hvec = mat[i];
      pivot = hvec[i];
      if (Math.abs(pivot) == 0.0) {
        // console.log("Singular matrix - fatal!");
        return false;
      }
      for (j = i + 1; j < n; j++) {
        q = -mat[j][i] / pivot;
        mat[j][i] = 0.0;
        for (k = i + 1; k < n; k++) {
          mat[j][k] += q * hvec[k];
        }
        vec[j] += q * vec[i];
      }
    }
    vec[n - 1] /= mat[n - 1][n - 1];
    for (i = n - 2; i >= 0; i--) {
      hvec = mat[i];
      for (j = n - 1; j > i; j--) {
        vec[i] -= hvec[j] * vec[j];
      }
      vec[i] /= hvec[i];
    }

    return vec;
  };

  // Regression analysis. Will most likely be re-written in the future.
  regression_analysis = function (options) {
    // Original code by Professor Hossein Arsham - http://home.ubalt.edu/ntsbarsh/Business-stat/otherapplets/Trend.htm
    // Re-written for timeseries-analysis.

    options = _.extend(
      {
        threshold: 2.5,
      },
      options
    );

    var output = {};

    var i;
    var j;
    var E = this.data.length; //total number of input spaces
    var N = 0;
    var N1 = 0;
    var N2 = 0;
    var SUM = 0.0;
    var R = 1;
    var Median = 0;
    var theList = new Array();
    var cval = new Array();
    // Run through all the input, add those that have valid values
    var a = 0;
    for (i = 0; i < E; i++) {
      SUM += this.data[i][1];
      theList[a] = this.data[i][1];
      cval[a] = this.data[i][1];
      N++;
      a++;
    }
    //check for insufficient data
    if (N <= 10) {
      console.log("Insufficient data (min 10)");
      return false;
    }
    //sort the list
    for (i = 0; i < theList.length - 1; i++) {
      for (j = i + 1; j < theList.length; j++) {
        if (theList[j] < theList[i]) {
          var temp = theList[i];
          theList[i] = theList[j];
          theList[j] = temp;
        }
      }
    }
    //calculate Median
    var aux = 0;
    if (N % 2 == 1) {
      aux = Math.floor(N / 2);
      Median = theList[aux];
    } else {
      Median = (theList[N / 2] + theList[N / 2 - 1]) / 2;
    }

    // Do the math
    var x = Median;
    var y = Math.round(100000 * x);
    var z = y / 100000;
    // run through each value and compare it with mean
    for (i = 0; i < E; i++) {
      //check if a value is present and discard the ties
      if (this.data[i][1] != x) {
        //check if it is greater than mean then adds one
        if (this.data[i][1] > x) {
          N1++;
          a = i;
          while (a > 0) {
            a--;
            if (this.data[a][1] != x) {
              break;
            }
          }
          if (this.data[a][1] < x) {
            R++;
          }
        }
        //if it is less than mean
        else if (this.data[i][1] < x) {
          N2++;
          a = i;
          while (a > 0) {
            a--;
            if (this.data[a][1] != x) {
              break;
            }
          }
          if (this.data[a][1] > x) {
            R++;
          }
        }
      }
    }
    //form.NR.value = R;     //value of x or "Scores"
    // What is the runs' statistic? I don't know...
    // Is it http://en.wikipedia.org/wiki/Wald%E2%80%93Wolfowitz_runs_test ?
    output.runs = R;

    //compute the expected mean and variance of R
    var EM = 1 + (2 * N1 * N2) / (N1 + N2); //Mean "Mu"
    var SD1 = [2 * N1 * N2 * (2 * N1 * N2 - N1 - N2)];
    var SD2 = Math.pow(N1 + N2, 2);
    var SD3 = N1 + N2 - 1;
    var SD4 = SD1 / (SD2 * SD3); //Standard deviation "Sigma"
    var SD = Math.sqrt(SD4);
    //calculating P value MStyle
    var z1 = (R - EM) / SD;
    var z2 = Math.abs(z1);
    var z = z2;

    /* Thanks to Jan de Leeuw for the following function */
    var t = z > 0 ? z : -z;
    var P1 = Math.pow(
      1 +
        t *
          (0.049867347 +
            t *
              (0.0211410061 +
                t *
                  (0.0032776263 +
                    t * (0.0000380036 + t * (0.0000488906 + t * 0.000005383))))),
      -16
    );
    var p = 1 - P1 / 2;
    var t = 1 - (z > 0 ? p : 1 - p); //this is P-value

    //rounding the value
    var t1 = Math.round(100000 * t);
    var t2 = t1 / 100000; //this is P-value too
    //form.PV.value = t2;

    //determine the conclusion
    // Encoding the trend value from 0 (no trend) to 3 (strong strend evidence)
    if (t2 < 0.01) {
      //form.CON.value = "Strong evidence for trend";
      output.trend = 3;
    } else if (t2 < 0.05 && t2 >= 0.01) {
      //form.CON.value = "Moderate evidence for trend";
      output.trend = 2;
    } else if (t2 < 0.1 && t2 >= 0.05) {
      //form.CON.value = "Suggestive evidence for trend";
      output.trend = 1;
    } else if (t2 >= 0.1) {
      //form.CON.value = "Little or no real evidences for trend";
      output.trend = 0;
    } else {
      //form.CON.value = "Strong evidence for trend";
      output.trend = 3;
    }

    //AUTO CORRELATION
    var DWNN = 0;
    var DWND = cval[0] * cval[0];
    for (i = 1; i < cval.length; i++) {
      DWNN = DWNN + (cval[i] - cval[i - 1]) * (cval[i] - cval[i - 1]);
      DWND = DWND + cval[i] * cval[i];
    }
    var DW = DWNN / DWND;
    DW = Math.round(DW * 100000) / 100000;
    //form.DW.value = DW;
    output.durbinWatson = DW;

    var Q01 = 2 - 4.6527 / Math.sqrt(N + 2);
    var Q05 = 2 - 3.2897 / Math.sqrt(N + 2);

    //determine the conclusion
    // Encode the correlation between 1 and 3
    if (DW >= Q01 || DW <= 4 - Q01) {
      //form.COND.value = "Moderate evidence againt autocorrelation";
      output.autocorrelation = 2;
    } else if (DW >= Q05 && DW <= 4 - Q05) {
      //form.COND.value = "Strong evidences against autocorrelation";
      output.autocorrelation = 3;
    } else {
      //form.COND.value = "Suggestive evidences for autocorrelation";
      output.autocorrelation = 1;
    }

    return output;
  };

  // Get the Durbin-Watson statistic
  // http://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic
  durbinWatson = function () {
    return this.regression_analysis().durbinWatson;
  };

}

var mapped_costs = _.groupBy(ds_costs, function (value) {
  return value.start_date;
});
var unsorted_results = _.map(mapped_costs, function (group) {
  var counter = 0;
  for (var i = 0; i < group.length; i++) {
    var item = group[i];
    if (item[param_cost_metric] == 0) {
      counter = counter + 1;
    } else {
      break;
    }
  }
  var arr_new_sum = _.pluck(group, param_cost_metric);
  var summed = _.reduce(arr_new_sum, function (memo, num) { return memo + num; }, 0);
  return {
    start_date: group[0].start_date,
    cost: summed,
  };
});
var costs = [];
_.each(unsorted_results, function (item) {
  costs.push([
    item.start_date,
    item.cost,
  ]);
});
var t = new TimeSeries(costs.reverse())
EOS

###############################################################################
# Escalations
###############################################################################

escalation "esc_budget_alert" do
  automatic true
  label "Send Email"
  description "Send incident email"
  email $param_email
end

###############################################################################
# Policy
###############################################################################

policy "budget_alert" do
  validate_each $ds_costs do
    summary_template "Cost Anomaly Detected"
    detail_template <<-EOS
    EOS
    escalate $esc_budget_alert
    check eq(1,0)
    export do
      resource_level true
      field "name" do
        label "Billing Center Name"
        path "name"
      end
      field "new_sum" do
        label "Latest Period"
        path "new_sum"
      end
      field "old_sum" do
        label "Previous Period"
        path "old_sum"
      end
      field "per_change" do
        label "Percent Change"
        path "per_change"
      end
      field "id" do
        label "Billing Center ID"
        path "id"
      end
    end
  end
end

###############################################################################
# Cloud Workflow
###############################################################################
